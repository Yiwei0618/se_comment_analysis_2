post_type,post_id,parent_id,owner_user_id,owner_display_name,score,body_text,,,,
question,389811,,294691.0,Mithical,1208,"Update
On August 2nd, 2023, negotiations between community representatives and representatives of the company concluded with an agreement being reached. The details of the agreement can be found at Moderation strike: Results of negotiations.
On August 7th, 2023, based on the result of several polls held by various sections of the community, the coordinated call to strike concluded. Further details can be found at Moderation strike: Conclusion and the way forward.


Introduction
As of today, June 5th, 2023, a large number of moderators, curators, contributors, and users from around Stack Overflow and the Stack Exchange network are initiating a general moderation strike. This strike is in protest of recent and upcoming changes to policy and the platform that are being performed by Stack Exchange, Inc.1
We have posted an open letter addressed to Stack Exchange, Inc. The letter details which actions are being avoided, the main concerns of the signees, and the concrete actions that Stack Exchange, Inc. needs to take to begin to resolve the situation. Striking community members will refrain from moderating and curating content, including casting flags, and critical community-driven anti-spam and quality control infrastructure will be shut down.
However, the letter itself cannot contain all of our concerns, and we felt it was important to share some of the background and details that were not included in the letter in the interest of brevity. We also wanted to touch upon several points at the same time that are related to Stack Exchange, Inc.‚Äôs recent behavior.
Background
A history of the Artificial Intelligence policy
On December 5th, 2022, Stack Overflow moderators instituted a ‚Äútemporary policy‚Äù banning the use of ChatGPT in particular on the site. This was instituted due to the general inaccuracy of the answers, as well as that such posts violate the referencing requirements of Stack Overflow. The moderator team kept an eye on community feedback to guide it, and support welled beneath this policy. Similar policies were enacted across the network.
Within the next several days, thousands of posts were removed and hundreds of users were suspended for violating this policy.
Over the next few months, Stack Exchange, Inc. staff assisted in the enforcement of this policy. This included adding a site banner announcing the ban on these posts as well as editing and adding Help Center articles to mention this policy. Moderators were also explicitly given permission to suspend for 30 days directly in such cases, skipping the escalation process that is generally encouraged.
On May 29th, 2023 (a major holiday for moderators in the US, CA, UK, and possibly other locations), a post was made by a CM on the private Stack Moderators Team2 (now publicly published). This post, with a title mentioning ‚ÄúGPT detectors‚Äù, focused on the rate of inaccuracy experienced by automated detectors aiming to identify AI- and specifically GPT-generated content - something that moderators were already well aware of and taking into account.
This post then went on to require an immediate cessation of issuing suspensions for AI-generated content and to stop moderating AI-generated content on that basis alone, affording only one exceptionally rare case in which it was permissible to delete or suspend for AI content. It was received extremely poorly by the moderators, with many concerns being raised about the harm it would do.
On May 30th, 2023, a version of this policy was posted to Meta Stack Exchange and tagged mod-agreement-policy, making this a binding moderator policy according to the Moderator Agreement. The policy on Meta Stack Exchange differs substantially from the version issued in private to the moderators. In particular, the public version of the policy conspicuously excludes the ‚Äúrequirements‚Äù made in private to immediately cease practically all moderation of AI-generated content.
The problem with the new policy on AI-generated content
The new policy, establishing that AI-generated content is de facto allowed on the network, is harmful in both what it allows on the platform and in how it was implemented.
The new policy overrode established community consensus and previous CM support, was not discussed with any community members, was presented misleadingly to moderators and then even more misleadingly in public, and is based on unsubstantiated claims derived from unreviewed and unreviewable data analysis. Moderators are expected to enforce the policy as it is written in private, while simultaneously being unable to share the specifics of this policy as it differs from the public version.
In addition to these issues in how Stack Exchange, Inc. went about implementing this policy, this change has direct, harmful ramifications for the platform, with many people firmly believing that allowing such AI-generated content masquerading as user-generated content will, over time, drive the value of the sites to zero.
A serious failure to communicate
Throughout the process of creating, announcing, and implementing this new policy, there has been a consistent failure to communicate on the part of Stack Exchange, Inc. There has been a lack of communication with moderators and a lack of communication with the community. When communication happened, it was one-sided, with Stack Exchange, Inc. being unwilling to receive critical feedback.
An offer by Philippe, the Vice President of Community, to hold a discussion in the Teachers‚Äô Lounge moderator-only chatroom took days to be realized. During that conversation, certain concerns were addressed3, but the difficult questions remained unanswered ‚Äì particularly about the lack of communication ahead of time.
The problem with AI-generated content
This issue has been talked about endlessly, both all around the Stack Exchange network and around the world, but we feel it‚Äôs important to highlight a few reasons why several communities, not just Stack Overflow, decided to ban AI-generated content. These reasons serve as the backbone not only for our moderation stance against AI-generated content, but also why we feel confused and betrayed by Stack Exchange, Inc.‚Äôs sudden decision to halt our efforts to enforce our community-supported decision to ban it.
To reference Stack Overflow moderator Machavity, AI chatbots are like parrots. ChatGPT, for example, doesn‚Äôt understand the responses it gives you; it simply associates a given prompt with information it has access to and regurgitates plausible-sounding sentences. It has no way to verify that the responses it‚Äôs providing you with are accurate. ChatGPT is not a writer, a programmer, a scientist, a physicist, or any other kind of expert our network of sites is dependent upon for high-value content. When prompted, it‚Äôs just stringing together words based on the information it was trained with. It does not understand what it‚Äôs saying. That lack of understanding yields unverified information presented in a way that sounds smart or citations that may not support the claims, if the citations aren‚Äôt wholly fictitious. Furthermore, the ease with which a user can simply copy and paste an AI-generated response simply moves the metaphorical ‚Äúparrot‚Äù from the chatbot to the user. They don‚Äôt really understand what they‚Äôve just copied and presented as an answer to a question.
Content posted without innate domain understanding, but written in a ‚Äúsmart‚Äù way, is dangerous to the integrity of the Stack Exchange network‚Äôs goal: To be a repository of high-quality question-and-answer content.
AI-generated responses also represent a serious honesty issue. Submitting AI-generated content without attribution to the source of the content, as is common in such a scenario, is plagiarism. This makes AI-generated content eligible for deletion per the Stack Exchange Code of Conduct and rules on referencing. However, in order for moderators to act upon that, they must identify it as AI-generated content, which the private AI-generated content policy limits to extremely narrow circumstances which happen in only a very low percentage of AI-generated content that is posted to the sites.
This isn‚Äôt just about the new AI policy
While a primary focus of the strike is the potential for the total loss of usefulness of the Stack Exchange platform caused by allowing AI-generated content to be posted by users, the strike is also in large part about a pattern of behavior recently exhibited by Stack Exchange, Inc.
The company has once again ignored the needs and established consensus of its community, instead focusing on business pivots at the expense of its own Community Managers, with many community requests for improved tooling and improving the user experience being left on the back burner. As an example, chat, one of the most essential tools for moderators and curators, is desperately out of date, with two-minute, high improvement changes being ignored for years.
Furthermore, the company has repeatedly announced changes that moderators deem would cause direct harm to the goals of the platform, this policy on AI-generated content among them. The community, including moderators and the general contributor base, was not consulted nor asked for input at any point before these changes were announced, phrased in a manner that indicated that there was no possibility of retraction or even a trial period.
Some of these planned changes have been temporarily held off due to controversy, this strike influencing those decisions, but that does not change the recent tendency of Stack Exchange, Inc. to make decisions affecting the core purpose of the site without consulting those most affected.
The events of the last few weeks seem like history repeating itself. Stack Exchange, Inc. ventures into a new pursuit, this time, generative AI, in contrast with the community‚Äôs interests, makes a decision at odds with all feedback available to them, ceases communications with us, and we go on strike. This is similar to what happened last time the community moderators prepared to go on strike.
How we resolve this
Even though the strike may end, many community members are not comfortable with returning to the status quo before the AI policy itself, if nothing else changes. The strike‚Äôs focus on the AI policy is not downplaying the significance of SE‚Äôs other actions. We deserve much more than just retracting the AI policy. Stack Exchange already made promises after the 2019 debacle that they have since failed to meet. We are worried that Stack Exchange will continue down the same path once the situation calms down.
While the recent actions by Stack Exchange, Inc. are in conflict with the community and take a significant step backward in terms of the relationship between the company and the community, we do not think that our relationship is beyond repair. We do however worry that we are nearing the point at which it cannot be repaired anymore.
While it certainly may be true that the company wants to meet our needs, and wants to care for us, the reality is that this is not happening. It is time to wake up and realize what must be done. Stack Exchange, Inc. is not acting in our interest. It is time to do so.
What the striking users want
For the strike to end, the following conditions must be met:

The AI policy change retracted and subsequently changed to a degree that addresses the expressed concerns and empowers moderators to enforce the established policy of forbidding generated content on the platform.
Reveal to the community the internal AI policy given directly to moderators. The fact that you have made one point in private, and one in public, which differ so significantly has put the moderators in an impossible situation, and made them targets for being accused of being unreasonable, and exaggerating the effect of the new policy. Stack Exchange, Inc. has done the moderators harm by the way this was handled. The company needs to admit to their mistake and be open about this.
Clear and open communication from Stack Exchange, Inc. regarding establishing and changing policies or major components of the platform with extensive and meaningful public discussion beforehand.
Honest and clear communication from Stack Exchange, Inc. about the way forward.
Collaborate with the community, instead of fighting it.
Stop being dishonest about the company‚Äôs relationship with the community.

A change in leadership philosophy toward the community
We need business leadership to meet minds with the community members and community managers, because currently, it appears that leadership ignores them.
Immediate financial concerns appear to drive feature development. The community also has feature development wants and needs, but no substantial consideration is given to those needs, let alone resource allocation. The lack of merit leadership gives to the community and CMs even leads to its own business decisions being reckless and harmful, like the AI policy.
Leadership needs a change in philosophy to one that treats the community as more than a product, and values its needs and expertise. Such a philosophy is evidently currently missing, and leadership takes the expertise of its own product for granted. Leadership needs to represent this philosophy in actually allocating resources based on community needs as well as its own, and informing its feature development using the expertise of the community. Development can be guided by both business and community needs!
In conclusion
The sites on the Stack Exchange network are kept running smoothly by countless hours of unpaid volunteer work, and, in some cases, projects paid for out of pocket by community members. Stack Exchange, Inc. needs to remember that neglecting and mistreating these volunteers can only lead to a decrease in the goodwill and motivation of those contributing to the platform.
A general moderation strike is being held until the concerns laid out in the open letter and this post are addressed. Moderators, curators, contributors, and users, you are welcome to join in by signing your name in the strike letter.
If you would like to sign the open strike letter, but do not have a Stack Overflow account, please reach out to @mousetail (start a new room).
Updates
This post contains strike updates (representatives elected, reactions to the GPT data analysis posted by Philippe, conditions for ending the strike).

1 While we‚Äôre aware that the legal name of the company is ‚ÄúStack Exchange, Inc.‚Äù, the name ‚ÄúStack Overflow‚Äù is more recognizable, and thus used in the open letter. The ‚ÄúInc.‚Äù serves to demonstrate that our concerns lie with the corporate entity, and not the site itself, its moderators, or individual employees.
2 Stack Exchange, Inc. provides a free Stack Overflow for Teams instance for Stack Exchange moderators, allowing moderators to store and share private information, bug reports, documentation, and communication with SO staff.
3 This includes another planned change to the foundational systems of the platform that has the potential to facilitate unprecedented levels of abuse. (This was referred to as ‚Äúthe second shoe‚Äù during the planning stages of the letter and the strike, as in ‚Äúwaiting for the other shoe to drop‚Äù.) This has been delayed indefinitely while parts of the plan are reconsidered.",,,,
comment_on_question,1300348,389811,294691.0,Mithical,169,"Stack Exchange moderators take their commitments seriously, @user3840170, and leaking private information is a massive breach of trust. Just because the company has broken trust does not mean that we will stoop to the level of leaking confidential information.",,,,
comment_on_question,1300383,389811,401803.0,hkotsubo,82,"Although I agree with you, I'm really skeptical about the strike's effectiveness. Based on the company's actions in the last few years, it's pretty clear they don't care about quality or the community anymore. And the community members who still care are seen as a burden they have to deal with. With the strike, SE has the perfect excuse to remove all diamonds and make new elections, making sure that all new mods will be aligned with their goals.",,,,
comment_on_question,1300321,389811,1017231.0,bobble,51,"Hey, I'd love to sign the open letter but I can't without a Stack Overflow account. Is there any possibility to make some alternative sign-in method? I'd be happy to use my SE account or my Meta SE, for example. I'm active in moderation on three sites to varying degrees, and I anonymously edit many posts (mostly ELL and HNQ), so that's what I'll be stopping.",,,,
comment_on_question,1300389,389811,189401.0,Ian Kemp - SE killed by LLMs,47,@Caimen Nobody has been banned. Suspensions have been doled out based on the basis of human moderator review of posts that have been flagged as potentially LLM-generated.,,,,
comment_on_question,1300388,389811,294691.0,Mithical,45,"@Caimen - Moderators do not rely on AI detectors to determine if a post is AI-generated. There are other heuristics used instead, and action is never taken solely because a purported AI detector claimed it was ChatGPT or whatever.",,,,
comment_on_question,1300369,389811,131112.0,Sklivvz,35,"@Mithical I think the OP would consider leaking the information as whistleblowing, which has different ethics from just sharing confidential information.",,,,
comment_on_question,1300347,389811,620615.0,user3840170,34,I am surprised nobody has leaked the stated-in-private policy yet.,,,,
comment_on_question,1300504,389811,377214.0,Sonic the Anonymous Hedgehog,29,"@Cascabel Most of what you said makes perfect sense - I saw some blatantly transphobic posts here on this site at the time. However, I disagree with your point that the company was ""ultimately the grownup in the room"" and that the community ""couldn't be trusted"" - many of those posts were being nuked by the community, not by staff.",,,,
comment_on_question,1300392,389811,357051.0,Israel should no longer exist,27,@Caimen See the comments under their new policy answer. SE staff is lying to you. Do not trust the point of view which they have presented in that answer.,,,,
comment_on_question,1300336,389811,377214.0,Sonic the Anonymous Hedgehog,26,@Andreasdetestscensorship Please add an option to indicate that someone supports removing the policy but doesn't want to participate in the strike. I'd like to sign the letter but due to its current phrasing it would state that I'm participating.,,,,
comment_on_question,1300498,389811,133299.0,Cascabel,25,"While I certainly agree that SE could and should have done better in 2019, that ""debacle"" does not rest solely on their shoulders - a substantial number of community members and moderators were being openly transphobic, to the point that the only way to make the sites friendly to nonbinary people (among others) was for the company to step in. I'm absolutely all for demanding better on the actual core issues here, but let's not weaken our position by tying those important issues to cases where the company was ultimately the grownup in the room, and it was us that couldn't be trusted.",,,,
comment_on_question,1300505,389811,133299.0,Cascabel,24,"@SonictheAnonymousHedgehog Many of those posts were being made by moderators. I was on the receiving end of a significant amount of abuse from moderators. Attempts to shift policy starting from discussion among moderators were uniformly shot down. Yes, there were also community members moderating well, but the overall point stands.",,,,
comment_on_question,1300453,389811,371052.0,mousetail,14,"If you want to sign the letter but don't want to create a stack overflow account, DM me. I can add you manually @bobble",,,,
comment_on_question,1301193,389811,786798.0,0Valt,13,"@Someone to be more precise, everyone on strike does what they choose to, there is no official ""guideline"" on how to behave (apart from the general rule of not doing something that would be considered a punishable offence under normal circumstances anyway) - we are not SE, after all. Some chose to abstain from any and all activity, some - only from moderation duties (VTC/VTR/VTD/reviews/edits). Some chose to stop on all sites, some decided to continue moderating meta sites.",,,,
comment_on_question,1300619,389811,133299.0,Cascabel,9,"@user202729 I don't really feel comfortable getting too specific, but to try to rephrase my previous statement: collectively, both full communities and the internal moderator community came to conclusions that were inconsistent with the policy that was ultimately published. To try to steer back to the original point: holding SE accountable, great. Suggesting that it's always just been them who's out of touch, and the issue is purely ""they're not doing what we say"": meh.",,,,
comment_on_question,1305394,389811,997587.0,starball,8,"@CyberJ ""when AI models will be more accurate and provide better results."" data needed on that claim.",,,,
comment_on_question,1300371,389811,171199.0,Íì¢PArcheon,7,"@Sklivvz even if you want to appeal to that, most mods probably never opted-out of the arbitration clause - also know as ""we choose our turf"" (because I would expect them to not be mod if they did) and the company has already shown its ""easy trigger"" in the past, name-calling removed moderators on mainstream news outlet sites in an attempt to ruin their reputation.",,,,
comment_on_question,1300623,389811,298955.0,WillO,7,"I see a lot of diamonds among the list of people who have signed the open letter, but without clicking on each name individually, there seems to be no way to tell which sites are represented among those diamonds.  Is there a way to make that information more readily available?",,,,
comment_on_question,1300373,389811,311001.0,nitsua60,6,"@bobble perhaps it's too on-point, but the historical membrane between SO and SE servers that creates multiple, small friction points like your sign-in issue has been mentioned perennially by moderators as an issue deserving attention for at least a decade :facepalm:",,,,
comment_on_question,1300381,389811,217692.0,R.. GitHub STOP HELPING ICE,6,"@Mithical: This would absolutely be whistleblowing not ""leaking confidential information"". Someone in the leadership is on the AI scam gravy train and trying to tank Stack Overflow in the process.",,,,
comment_on_question,1301064,389811,196834.0,einpoklum,6,"""SE Inc. cannot consistently ignore, mistreat, and malign its volunteers"" <- It's been doing that for quite a while. I'd rephrase that as ""SE Inc. cannot be allowed to ignore, mistreat and malign"" etc.",,,,
comment_on_question,1301728,389811,16241.0,Vaccano,6,"As a random non-moderator and occasional meta reader, this makes no sense from SE's point of view.  If they have the data, they would surely share it.  At least with the moderators (as they have proven over and over again that they don't lead private data).  The only thing that ""connects all the dots"" (to me) is that SE had planned to make this move and purposely planned to make the moderators take the fall.  They figured no one would call them on their statements.  They can't back down (because this was the plan) but they don't really have any data to share.  Hard spot to be in.",,,,
comment_on_question,1304981,389811,1360325.0,HippoMan,6,"From @Shawn: ""The great war between the humans and the robots begins..."" It's simply a war between humans and other humans. The ""robots"" in question have no free will and no intelligence and no minds, and they are simply tools that are being utilized by humans. Calling this a robot/human war is like calling efforts at traffic-safety enforcement a ""war between cars and humans"".",,,,
comment_on_question,1300324,389811,357051.0,Israel should no longer exist,5,@bobble That‚Äôs an unintended issue on our part. Sorry for the inconvenience. Hopefully will be fixed soon.,,,,
comment_on_question,1300374,389811,383809.0,Anton Menshov,5,"@SonictheAnonymousHedgehog there are several posts on the network where you can express the desire for the policy to be removed. The open letter, as well as this post, are specifically about the strike action, which you can join or not.",,,,
comment_on_question,1300473,389811,1374521.0,Aaron,5,"Regardless of AI policy I do not believe any LLM's should be permitted on any platforms at all until they can show their work, as in ""Here is a full audit trail of how I reached this answer"".",,,,
comment_on_question,1300494,389811,260073.0,NoDataDumpNoContribution,5,"@agentv "".. respond to content on the basis of its content, not upon its [..] provenance."" Just as a general stance I could live with that. But it's also about copyright and average quality. Sure, some human users also post low quality but the community here is concerned with mass production of low quality content. The ban is temporary, until AI gets better. And it probably gets better at some point. But until then we need the tools to keep the quality high and the company doesn't want to allow these being concerned more with collateral damage, at least it says. Who knows..",,,,
comment_on_question,1300616,389811,161059.0,Alex,5,"""A change in leadership."" is probably the only thing that will improve the situation. i haven't seen anything that was aimed at improving the community in the past year. i absolutely think the current ceo is not fit for the role. it's rather ironic seeing ""button styling"" (still featured) and ""moderator strike"" next to each other, just shows their priorities.  oh, i'm sorry, ""moderator action"" - sure fooled everyone.",,,,
comment_on_question,1300382,389811,395209.0,agentv,4,"It would be a shame if after all this striking, we discovered that the striking moderators were not missed. Maybe some would discover hobbies, or plant a garden.  As a user, I want accurate answers, and I'm not pedantic about how they came to me. Those of us remaining during this ""strike"" will continue to respond to content on the basis of its content, not upon its imagined provenance.",,,,
comment_on_question,1301355,389811,165773.0,gnat,4,"@pippo1980ONSTRIKE have a look at close review stats page. Currently it shows me 7 (seven) reviewers with all but the top one having less than 15 reviews. Compare this to 90,000 users having sufficient reputation to do close reviews. How do you think it happened that only 7 of these decided to review today",,,,
comment_on_question,1301364,389811,165773.0,gnat,4,"...low quality answer stats page looks slightly better on a surface, it shows decent looking list of reviewers with half-decent amount of reviews shown for them. ""246 needs review"" message also may appear okayish... but it just happened that I saw this very page 10 days ago and it displayed 54 - like, about five times less of what I see today. Looks like folks who joined the strike, signed or not, made some impact, yes",,,,
comment_on_question,1300365,389811,768059.0,EarlGrey,3,"The sites on the Stack Exchange network are kept running smoothly by countless hours of unpaid volunteer work, and, in some cases, projects paid for out of pocket by community members that's crazy. Good (if any) old times are long gone. en.wikipedia.org/wiki/Prosus . Stop being exploited.",,,,
comment_on_question,1300612,389811,388243.0,user202729,3,"@Cascabel I'm sorry to hear that with you being a (‚ô¶)-moderator on one of the sites yourself. As a regular user I have no knowledge on what's going on internally between the moderators, but I hope some good policy can be made. (although I don't understand -- if a supermajority of moderators are against transphobia why would policies being shot down?)",,,,
comment_on_question,1302411,389811,908464.0,Adam Rubinson,3,"I don't see any serious changes being proposed. If you need to see real change because the mods can't keep pace with new AI-generated answers then here is a serious resolution: Have several prompts before the new user posts their answer warning them that posting an AI-generated answer results in a permanent ban of their account. If they post the AI-generated answer then permanently ban their account. I think perma-banning their IP is too harsh. But forcing them to create a new account from another e-mail address is a pain, and so this method will result in positive change. Am I wrong?",,,,
comment_on_question,1304969,389811,1360325.0,HippoMan,3,"Per @agentv: ""It would be a shame if after all this striking, we discovered that the striking moderators were not missed. ...  As a user, I want accurate answers, and I'm not pedantic about how they came to me."" I agree. I have had questions blocked simply because some moderator decided that they didn't like the wording of my questions, irrespective of the fact that the questions were asked clearly enough for a number of readers to easily understand and answer them. I hope that these nitpicky, overly pedantic moderators would not return from the strike. And I do indeed support the strike.",,,,
comment_on_question,1300620,389811,997587.0,starball,2,"@Alex re: ""i haven't seen anything that was aimed at improving the community in the past year"" -  see Plagiarism flag and moderator tooling has launched to Stack Overflow!",,,,
comment_on_question,1301092,389811,415740.0,Skully,2,Such a shame to see how disconnected SE Inc. is with its own moderator network and how issues like this crop up time and time again.,,,,
comment_on_question,1301188,389811,997587.0,starball,2,"@Someone read the open letter: ""Raising and handling flags, Closing or voting to close posts, Deleting or voting to delete posts, Reviewing tasks in the various review queues,"" etc.",,,,
comment_on_question,1305393,389811,1383063.0,CyberJ,2,"My two cents. Since I started using ChatGPT for coding, I stopped asking questions on Stackoverflow. I think that Stackoverflow has to find a way to integrate AI otherwise it will be lost especially when AI models will be more accurate and provide better results.",,,,
comment_on_question,1300329,389811,260073.0,NoDataDumpNoContribution,1,"""The AI policy change retracted and subsequently changed to a degree that addresses the expressed concerns and empowers moderators to enforce the established policy of forbidding generated content on the platform."" That seems to be a very important point. Not only because it's difficult to achieve but also because it formally puts the striking mods against the now existing moderator policies. I hope a solution can be found.",,,,
comment_on_question,1300346,389811,171199.0,Íì¢PArcheon,1,"This looks like the karmic conclusion to the hystorical disagreement about what constitutes NAA (is an answer that answers a different question that the one asked or violates some requirements still an answer?) and what should be done with wrong/dangerous/irrelevant answers (downvote or delete?). Now the new ""defense in absurdity"" is claiming that one may not have the experience to see if an answer is wrong, even when they have.",,,,
comment_on_question,1300391,389811,357051.0,Israel should no longer exist,1,"@hkotsubo The intention is to make them aware by our lack of moderation purposes. It's not just the moderators that are strike. The majority of the core curators are on strike, including the bots we use, such as SmokeDetector.",,,,
comment_on_question,1301318,389811,787261.0,pippo1980,1,so how is the strike going ? are normal users joining it ? do we have stats about it or just the subscribers of the open letter ?,,,,
comment_on_question,1301334,389811,159794.0,kleopatra,1,"@pippo1980ONSTRIKE are normal users joining it yes, me at least - didn't do any content/curation related action since the strike started and I signed the open letter :) there also are other high frequency high expert contributors to SO - which I know - doing the same .. nothing",,,,
comment_on_question,1300387,389811,167698.0,Caimen,0,"I'm concerned about the methods used to identify AI generated content and how accurate they are.  I don't believe there is any software that can do this with any kind of accuracy, banning users based on flawed identification software does not seem the way to go and this open letter seems to have not addressed these concerns.",,,,
comment_on_question,1301186,389811,1203059.0,Someone,0,What exactly are non-diamond strikers not doing?,,,,
comment_on_question,1301189,389811,1203059.0,Someone,0,"@starball so upvoting and downvoting continues as normal? I did read that, but I've read comments from a couple people saying things like ""I would upvote this, but I'm on strike""",,,,
comment_on_question,1301308,389811,273829.0,Gerold Broser,0,I know why I didn't change my profile image after the Monica incident...,,,,
comment_on_question,1302255,389811,268976.0,Hack-R,0,"I think this was well-written and thoughtful, but have the following comments (mostly geared toward StackExchange): 1. Consider me as a scab. I would love to be a moderator in place of any who strike. 2. I believe fighting AI and trying to block it is incredibly silly and non-sustainable. Do you usually ban tools? Is this really so different from any other resource? If StackExchange allows itself to linger in the past while other sites take an AI-first strategy with greatly enhanced ability to improve questions, provide answers, and mine data, then I'm using the other sites.",,,,
answer,389844,389811,274022.0,sideshowbarker,512,"Background from a striking SO mod who handled 10000+ GPT flags
I‚Äôm a Stack Overflow moderator coming here to give more details on what management has said that‚Äôs helped cause me to decide to join the strike, and to give details from my own personal experience handling several thousand of the warnings and suspensions we‚Äôve done at Stack Overflow for ChatGPT copy-paste abuse.
And I‚Äôm framing this as a response to a comment elsewhere from company management way back in December that now looks to have been an unintentional ‚Äútell‚Äù from management that they may have already started musing way back then about plans to frame it all as a misguided ‚Äúwitch hunt‚Äù.
So, to be very clear: The massive effort and hours the curators/flaggers and elected moderators spent together over the last 6 months very successfully stemming the ChatGPT copy-paste tide and shielding our community‚Äôs users from all that junk never in, any way shape or form, came anywhere close to actually resembling anything like a ‚Äúwitch hunt‚Äù or any other kind of malicious or hysterical misguided analogy that management might want to try to smear us with now.
The reality is instead this:
We‚Äôve been very accurately identifying the ChatGPT posts with an extremely low number of false positives. And I say that as someone who has handled a very very large number of the flags.
For support of the assertion above, please really do take time to read on here.
(Non)Use of any detection tools
I want to take a moment here now to respond specifically to the continuing nonsense insinuations (smears) from management (repeated to the media even today) that we have been over-relying on various detection tools that ‚Äúhave an alarmingly high rate of false positives‚Äù and their ‚Äúdecision to require that moderators stop using that tool [sic]‚Äù.
So, let me make clear:
In the thousands of cases I handled, I never ever used any of the detection tools.
That is, not only did I not ‚Äúover rely‚Äù on detection tools, I never relied on them at all.
And in cases where the flaggers had included scores from any detection tools in their flag comments, I even completely ignored whatever score information the flaggers provided ‚Äî to the point that I would actually stop reading the flag comments at the point where they were providing score information, because I found no use at all for it.
So not only could it be said of me that I am one of the moderators whose ‚Äúown analyses were in use as well‚Äù ‚Äî I can say that my ‚Äúown analysis‚Äù was exclusively in use, with zero reliance on any detector information.
Numbers and assertions
To help clear up any doubts on whether I know whereof I speak, here are some numbers:

Conservatively speaking, for the last 6 months (since the beginning of December 2022) every single day I have been spending 40 minutes a day just on moderating ChatGPT flags. That works out to 120 hours in total that I‚Äôve personally spent on them so far.

And in those hours I‚Äôve spent on this week after week, I‚Äôve looked at multiple thousands of ChatGPT-flagged posts: in the order of 10000 or even 15000 at this point.


And so I do now assert that in the many hours I've spent actually looking at the ChatGPT-flagged posts, and from the many thousands of those posts that I have actually closely and carefully scrutinized in detail, I have in fact learned to recognize the ChatGPT copy-paste cases (including many of the ones whose content the posters had edited before pasting in, to intentionally obscure the provenance) and I can in fact say this:
I assert: I can, with a very high level of confidence and a very low level of false positives, very effectively identify answers whose provenance is ChatGPT or other AI.
And all that leads me to finish with an invitation‚Ä¶
An invitation to management
To anyone in management who claims the elected moderators have been getting it wrong for the last 6 months, with an unacceptably high rate of false positives, and who wants to challenge my personal assertions about how accurately I can identify the ChatGPT cases: I invite you to work together with me over several days looking at least several dozens of ChatGPT flags as they come in.
Alternatively, rather than looking at new flags as they come in, I invite anyone
to go together through the logs of my moderation activities, and examine some significantly-sized random sampling of the thousands of ChatGPT flags I have handled.
Either way, let‚Äôs spend time scrutinizing the actual content of the flagged posts together, and actually honestly talking together in good faith about which posts we think we can agree are highly likely not the poster‚Äôs own original work.
Until anybody who questions how well we‚Äôve been handling the ChatGPT flags actually does something concrete like what‚Äôs described above, waving vague suggestions about possible ‚Äúwitch hunts‚Äù and other slanders around under the noses of the elected moderators and flaggers is completely irresponsible at best ‚Äî but in reality, in combination with other indirect accusations and aggressions that key company reps driving company messaging around this have slung at the elected moderators, it is completely unconscionable and completely unprincipled.",,,,
comment_on_answer,1300536,389844,342074.0,Timothy G.,124,"As a moderator on a smaller site, seeing the numbers you posted about the amount of AI-flagged posts is... incredible.",,,,
comment_on_answer,1300542,389844,1024093.0,tdy,62,"I've flagged quite a few ChatGPT answers, and sideshowbarker has indeed handled a huge proportion of them. From my end, I can also say I've never flagged based on any detection tool -- after you look at a number of ChatGPT responses, it becomes obvious what is ChatGPT (and if I'm wrong about this, I'd like to see examples of false positives). I guess SO's fear is that when users push back and insist ""No I didn't use ChatGPT"" then SO has no tangible proof that the user in fact used ChatGPT.",,,,
comment_on_answer,1300566,389844,210998.0,Stephen Ostermiller,42,It would be interesting to set you up in a blind trial and see what your accuracy rate is on content known to be human generated vs content known to be AI generated.  I'll bet you fare way better than the detectors they are calling out.,,,,
comment_on_answer,1300583,389844,1255496.0,Tim Lewis,42,"""[...] striking SO mod who handled 10000+ GPT flags"" - I knew this was you immediately üòÖ Like tdy, you handled all (or most) of my ChatGPT flags, that also didn't use any tooling, but a combination of gut feeling, previous post history (if any), timeline of activity (multiple multi-paragraph posts in the span of a few seconds), etc. I'm glad to hear you (and I hope other moderators) used your best judgement and not some tool, and wanted to take a second to thank you; since ChatGPT came onto the scene, moderation here has probably been... difficult, but we, the users, appreciate you üôÇ",,,,
comment_on_answer,1300568,389844,311001.0,nitsua60,36,"@StephenOstermilleronStrike IMO this is a big bit of what SE is missing in the current moment. Many times, both privately and publicly, mods have asked staff to run a trial like that. No such trial of moderators' abilities has been conducted.",,,,
comment_on_answer,1300555,389844,260073.0,NoDataDumpNoContribution,18,This answer is awesome. Great read. One could possibly create a training set for humans to learn to recognize AI generated content.,,,,
comment_on_answer,1301021,389844,197376.0,matt,15,I have submitted numerous ChatGPT flags that were promptly and effectively handled by sideshowbarker. I feel we've worked together effectively to help protect StackOverflow. Now I will join the strike by ceasing all flagging and letting the site stew in its own juices.,,,,
comment_on_answer,1302891,389844,153008.0,Cody Gray,13,"We're on strike because we want to be able to keep doing this, to keep making the sites better, @dougp. If we're not allowed to do that, the next step will be quitting altogether, but we thought we should at least try some last-ditch efforts before abandoning ship altogether. We're not concerned that we'll be replaced with moderator bots. They might as well replace us with random number generators or nothing. At that point, the site will be dead anyway. We're attempting to head off the site we know, love, and have poured thousands upon thousands of hours into over the years from collapsing",,,,
comment_on_answer,1300607,389844,997587.0,starball,12,"I- like tdy- never used ChatGPT scanners / detectors. When I flag something I think is ChatGPT, I just use my own sense and subject-matter expertise.",,,,
comment_on_answer,1302484,389844,1024093.0,tdy,12,"@TomWenseleers Your examples aren't relevant to the ChatGPT policy. We've always been allowed to use CGPT, test its output, and write a verified solution based on that output. The ban/strike is about thousands of users copy-pasting CGPT output and basically spamming unverified junk.",,,,
comment_on_answer,1300700,389844,63550.0,This_is_NOT_a_forum,11,"Like for regular plagiarism, I flag ChatGPT posts when I encounter them by chance (I didn't hunt for them (past tense intentional)). They are easier to spot than regular plagiarism due to ChatGPT's very distinct writing style (for instance, the echoing back of the question (in a slightly different form)). I have never used any tools for this, only my own brain. And I always look for supporting evidence before I flag. And thank you, sideshowbarker, for handling all those flags! The word has become devalued by overuse, but it is very much appreciated.",,,,
comment_on_answer,1300672,389844,313443.0,Resistance Is Futile,9,"FWIW, I have flagged hundreds of AI posts on SO and always detected and flagged those posts solely using my own brain, not tools. Occasionally, I have used detection tools, but only to see how well those tools work rather than means of detection or confirmation.",,,,
comment_on_answer,1301172,389844,141193.0,President James K. Polk,8,"I submitted many chatGPT flags that were handled by you. Although I used the detection tools just to see how they worked, I never gave them any credence. Firstly, it's easy to recognize when something likely had its start with chatGPT. It jumps out at you. Then I'd check their answer history, frequently there is a gap with mostly monosyllabic answers followed by more recent wordy flowing chatGPT-looking answers. Finally, I actually ran the questions through chatGPT, and only when one of its answers was almost verbatim copy-and-pasted did I flag the answer. No witch hunt here.",,,,
comment_on_answer,1302135,389844,205381.0,Tim,7,"@AdamRubinson Here's one example. Feel free to have a look at the author's previous contributions and take an educated guess at what might have happened in the 6 months since their last post that turned them from someone that doesn't care about grammar, punctuation, or formatting into someone capable of writing perfect English text, perfectly paced and formatted, not missing a single punctuation mark.",,,,
comment_on_answer,1300648,389844,260073.0,NoDataDumpNoContribution,5,"After sleeping over it: it could still be that AI scanners indirectly played a tiny role here. After all you say that many flagged posts you trained on included a score in the message. One could assume that the flagged posts were selected partly by scanners, which means the composition of the training data is affected by AI scanners. Another thing is the ground truth. How does anyone know the ground truth here unless it's a test like proposed by Stephen Ostermiller in a comment above? I mean where does the ""very high level of confidence"" come from if the ground truth is not known? Or is it?",,,,
comment_on_answer,1301968,389844,205381.0,Tim,3,"With all of my flags handled by you, in a timely fashion, the one that sat in queue for an entire day got me curious as to what's going on. That's why I'm here. Until reading the numbers, I'd assumed that AI-powered rep-whoring were a niche sport. That was na√Øve. As for my personal flagging principles: 1 Never flag content you cannot validate, and 2 flagged content must be (at least in part) verifiably incorrect. I'm impartial about tool usage; I just never found myself in need of looking for one. I wonder what led SE Inc. into assuming we were all just mindless lemmings...",,,,
comment_on_answer,1300834,389844,153020.0,Flexo - Save the data dump,2,Worth stating: I've been consciously leaving the CGPT flags to others precisely because I missed the experience of the initial wave and  trust the judgement of the moderators who picked up the bulk of them far more than my own judgement on the matter,,,,
comment_on_answer,1302074,389844,1376656.0,tbrookside,2,"I can, with a very high level of confidence and a very low level of false positives, very effectively identify answers whose provenance is ChatGPT or other AI.  How?  There's no way to confirm any of your guesses.  You are basically saying you make these judgments based on your gut, and your gut tells you that your gut is right.  Unless you're saying that you used ChatGPT to reproduce the flagged answers word-for-word?  You don't give any description here of your method at all.",,,,
comment_on_answer,1302679,389844,1024093.0,tdy,2,"@TomWenseleers If you disagree with the Meta announcement's title, I'd suggest posting there instead. It's worth discussing, just not related to the strike at hand.",,,,
comment_on_answer,1302680,389844,1024093.0,tdy,2,"@TomWenseleers If you're trying to provide counterexamples for GPT detection, SE is accusing the mods of being too aggressive (false positives) while you're suggesting the opposite (false negatives). So even if your ridge regression answer were truly a false negative (which I doubt due to some uncharacteristic punctuation/capitalization/grammar), it would actually support the mods here. FP and FN are inversely related by nature.",,,,
comment_on_answer,1302800,389844,260073.0,NoDataDumpNoContribution,2,"@PresidentJamesK.Polk ""Finally, I actually ran the questions through chatGPT ..."" That sounds like an awful lot of time that you invested in flagging GPT content. I don't want to diminish the effort in any way but can you say how much time you approximately spent for every GPT flag you created by this method?",,,,
comment_on_answer,1303857,389844,173477.0,Karl Knechtel,2,"""As for my personal flagging principles: 1 Never flag content you cannot validate, and 2 flagged content must be (at least in part) verifiably incorrect."" @Tim even verifiably correct content can be completely and utterly inappropriate for the site (and worthy of flagging, and worthy of sanctions for its poster), in multiple ways. Most notably, it could violate Code of Conduct.",,,,
comment_on_answer,1305106,389844,307622.0,Wildcard,2,"@sideshowbarker clearly you've done a lot of excellent work here as a volunteer.  Unfortunately, the dynamics of the situation means you have no particular leverage or bargaining power over SE.  It's great you've written up these details, but on a personal note you might do better to leverage your talents in a more remunerative way while also helping others.",,,,
comment_on_answer,1307915,389844,312165.0,Rui F Ribeiro,2,"Ultimately, I think the misunderstanding between the parties is that SE turned into a knowledge sharing platform between peers to a platform being (ab)used for giving for free 1st world brain power/free work to low quality questions of the 3rd world. It boosts user numbers, however no one likes it, even those at the receiving end.",,,,
comment_on_answer,1302092,389844,908464.0,Adam Rubinson,1,"I haven't read everything on this page. Maybe I'm missing something, but is there any evidence that any of this actually happened? As far as I can see, there isn't a link to even one AI - generated answer, let alone 10,000. What am I missing?",,,,
comment_on_answer,1302362,389844,,user1377115,1,"I would like to see that reliability quantified with answers known to be produced by ChatGPT4 or not. Would you be able to tell that stats.stackexchange.com/questions/76925/‚Ä¶ was ChatGPT4 produced, unless I disclosed it? More importantly, would you have a problem with that answer, given that it is correct & much better than the other answers? And could you tell it's a correct answer?",,,,
comment_on_answer,1302456,389844,1215301.0,The_spider,1,Why do you need Stack Exchange Inc. to run such a blind trail? Such a thing could also be set up between moderators themselves.,,,,
comment_on_answer,1302593,389844,,user1377115,1,"@tdy The exact conditions under which that ban applied were not clearly stated - the headline alone is Temporary policy: ChatGPT is banned, meta.stackoverflow.com/questions/421831/‚Ä¶. If the policy had been ""The posting of answers generated by ChatGPT without any manual verification is not allowed, but we encourage the use of ChatGPT if adequate steps are undertaken to ensure the correctness of the provided answer, including verifying that any code works"" I would have agreed...",,,,
comment_on_answer,1302693,389844,,user1377115,1,"@tdy Well yes I'll discuss this there. My point - aside from the shoddy accuracy ((TP+TN) / (TP+TN+FP+FN)) - is simply that questions should just be judged based on their correctness, not on whether or not they were produced by ChatGPT...",,,,
comment_on_answer,1302741,389844,425848.0,dougp,1,"If this answer is accurate, why are the moderators on strike?  They should quit altogether.  But then I suppose SE would replace them with moderator bots.",,,,
comment_on_answer,1303899,389844,227257.0,jwenting,1,"@KarlKnechtel  indeed. I just flagged a question by someone who wanted us to assist them in setting up a human trafficking scheme for example. Highly inappropriate, likely even illegal.",,,,
comment_on_answer,1303904,389844,357051.0,Israel should no longer exist,1,"@jwenting That sounds like an excellent example of what not to flag, during a strike. Let it surface; let it be visible; let the company see what pops up on their platform if they push away their curators and moderators.",,,,
comment_on_answer,1303907,389844,227257.0,jwenting,1,@AndreasdetestsAIhype and let crime (literally) run rampant?,,,,
comment_on_answer,1303909,389844,357051.0,Israel should no longer exist,1,@jwenting Yes. That‚Äôs what a strike is.,,,,
comment_on_answer,1302363,389844,,user1377115,0,"Same for this answer, stackoverflow.com/questions/48119360/‚Ä¶, that I never got an answer to after 5 years & ChatGPT4 was able to answer in seconds...",,,,
comment_on_answer,1302595,389844,,user1377115,0,@tdy My answer here stats.stackexchange.com/questions/76925/‚Ä¶ was literally a copy and paste of what ChatGPT had written by the way (but I did manually verify that the code actually worked & that the maths was correct). Same for the SDL & OpenGL & rdyncall code I included in my answer here stackoverflow.com/questions/48119360/‚Ä¶,,,,
comment_on_answer,1304666,389844,1381296.0,Era,0,"Unless you can establish your own false positive rate, your assessment of your own moderation is unfortunately irrelevant. Moderators are making assumptions without data and accusing SE of doing the same thing. CGPT is one LLM. You absolutely cannot identify content from LLMs in general. If you can prove you can, go ahead.",,,,
comment_on_answer,1304667,389844,1381296.0,Era,0,"@tdy No, the issue isn't being too aggressive, the issue is being biased. Bias produces both false positives and false negatives in a patterned way. SE is clearly most interested in preventing false positives since they harm users. False negatives, if they are correct and good answers, are objectively harmless.",,,,
comment_on_answer,1309769,389844,285552.0,Russell McMahon,0,"@This_is_NOT_a_forum  Your revision comment was unnecessarily rude, given the existing content in the answer, but turned out to be useful :-)",,,,
answer,389812,389811,997587.0,starball,211,"Here's a list of per-site meta discussions related to the strike (largely gathered from searching ""is:q created:2023-05-30.. strike [discussion]"" on stackexchange.com, sorted based on site traffic, and updated on a best-effort-basis. stackexchange.com search seems bugged and shows fewer items than the count it returns. I've seen enough bugs now to just not be surprised.):

Meta Stack Exchange:

This Q&A
Moderation Strike update: Data dumps, choosing representatives, GPT data, and where we‚Äôre holding
Would the striking moderators welcome a user strike? Should we, the users, go on strike?


Does the strike letter oppose AI?
What is needed for users to trust the Stack Exchange company?
Are users being suspended for being on strike?
Does the company acknowledge misusing the press, and why won't it agree on a no-comment policy?
Does the company claim that every article the press made on ongoing issues wasn't requested by them and was instead an unsolicited initiative?
Mod strike: Is it realistic to require a no-comment press policy?


Moderation strike: Results of negotiations
Does the Charcoal team plan to run SmokeDetector again?
What do you feel like is still missing to end the strike?


What kind of percentages are reasonable for moderator consensus on the company violating the Mod Agreement?
Moderation strike: Conclusion and the way forward


Stack Overflow:

(mirror of the above post): Moderation Strike: Stack Overflow, Inc. cannot consistently ignore, mistreat, and malign its volunteers
How is Stack Overflow Inc. prepared for a possible moderation strike by community elected moderators on June 5?
What has happened to lead moderators to consider striking?
What is the impact of the moderation strike?
What can ""ordinary"" Stack Overflow users do to support the moderator strike?
Could SE management conduct moderator elections with reduced requirements in response to the ongoing moderation strike?
Moderation strike: how is the discussion going between the moderators and Stack Overflow, Inc?
How can we handle troublesome contributors during the moderation strike?
How do our moderators respond to the result of negotiations?
Is Stack Overflow back to normal moderation?


Unix & Linux: General moderators' strike

Ask Ubuntu:

Stack Exchange general moderation strike: the effects on Ask Ubuntu
I'm going on a general moderation strike due to the new AI-content policy forced upon us by SE
Homepage spammed
Decline in AU quality
Are we there yet? 8 weeks on strike


Super User: General moderators' strike

Mathematics:

Moderator Strike
General Moderation Strike: Mathematics StackExchange moderators are participating
Moderation strike update, and flags
It is possible to add a banner indicating there is currently a moderation strike?
Moderation Strike Resolution


Server Fault: Labor action notice

Stack Overflow en espa√±ol: Huelga de moderaci√≥n en la red de Stack Exchange

Database Administrators: Ongoing Moderation Strike

Cross Validated: June 5 General Moderation Strike: Recap, Possible roles, consequences and other relevant info

Academia:

Academia.SE Moderation Strike
Moderation strike (posted to the main site)
What is the impact of the moderation strike on Academia.SE?
What is the best way for high rep users to support the moderation strike?
After a month of moderator strike, is there any update on the situation?
Strike stopgap -- will this work, and is it OK?
Moderation Strike is Over


Arqade:

Community Moderator Strike
Solidarity: what does it mean to us?
Community Moderation Strike - The Return of the Arqade Mods


MathOverflow:

Stack Exchange moderation strike
Moderation strike update 1
Moderation strike update 2
Moderation strike update 3
Moderation strike update 4
Moderation strike update 5 : the results of negotiations
Moderation strike update 6 and last : back to work


Role-Playing Games:

Stack Exchange general moderation and curation strike begins today
How do our strike-participating community members feel about the moderation-strike negotiation results?
What was the impact of the moderation strike on site activity?


Web Applications: Stack Overflow and Stack Exchange Moderators Strike

Science Fiction & Fantasy: Sci-Fi moderators on AI content strike

Aviation: How much is Aviation Stack Exchange involved in the moderation strike?

Bicycles:

Stack Exchange Moderation Strike
Moderation Strike Update


Workplace: No need for drama

Cryptography: Moderator strike due to SE forcing AI-moderation policy

Seasoned Advice: Are our mods taking part in the walkout? 

Music: Practice & Theory: General Moderation Strike!

Astronomy: June 5 Strike - Who, What, Why, and how to join

Bioinformatics: Notification of Mod action on SE

Bitcoin: Notice: I‚Äôm participating in the Moderation Strike

Computational Science: Moderation & curation strike: Mistrust, mistreat, and harmful imposed policies

Retrocomputing: The Stack Exchange data dump has been switched off

Personal Finance & Money: I will be joining the moderator strike

Biology: Moderators and community curators are on strike - how will it affect the site?

Chess: June 5 Strike - Who, What, When, Why, and How to Join

History: Where is HSE regarding the current strike?

Writing: June 2023 Writing Challenge: Voices of Protest

Physical Fitness: The Stack Moderator Strike

Literature: Special thanks to Mithical for their role in helping to resolve the recent moderation strike

Medical Sciences: MedicalSciences.SE Moderation Strike

Arts & Crafts: Community Moderator Strike

Sustainable Living: Community Moderator Strike

Programming Language Design & implementation: 
How is the strike going to impact PLDI?


Honourable mentions:

Community Building main site: What could be the way out when interests of content curators and company drastically clash over ChatGPT content?
Law main site: What 'specific legal meaning' does the word ""strike"" have?
Puzzling main site:

Moderation strike: a tired lunatic (4)
Solidarity with the Moderation Team (A Cryptic Division Puzzle)


Blog posts by users I find notable (yes, I know these aren't meta discussions, but this is my post, so too bad hehe):

Monica Cellio: Stack Overflow is alienating its community again
Jon Ericson: Stack Exchange moderator strike
Jon Ericson: Why I'm signing the Stack Overflow strike letter
Jon Ericson: How's the Stack Overflow strike going?
Jon Ericson: What Stack Overflow is telling employees about the strike
Jon Ericson: The data dump diversion
Jon Ericson: Why AI is a problem on Stack Overflow
Jon Ericson: Stack Overflow's CEO doesn't understand Stack Overflow
Jon Ericson: Stack Overflow's strike is over (But its problems persist)",,,,
comment_on_answer,1300337,389812,203057.0,Cerbrus,50,"Not really about the strike per s√©, but Physics.SE remains a site by humans, for humans",,,,
comment_on_answer,1303767,389812,173477.0,Karl Knechtel,12,"From the blog posts: ""The public post kind of back-handedly called moderators bigots, too. I guess at least this time they didn't smear anyone by name. But still... ick."" Hearing this from Monica is... painful.",,,,
comment_on_answer,1300714,389812,1088098.0,justANewbie,3,should we also add mod resignment because of this?,,,,
comment_on_answer,1309102,389812,169312.0,tripleee,3,Tangentially related: A user seems to be trolling many SE sites with AI-generated answers; what should I do?,,,,
comment_on_answer,1300790,389812,,user152859,2,"@justANewbie to keep the answer consistent, only if there is a meta post about it. (not another section in this answer.)",,,,
comment_on_answer,1300548,389812,908360.0,Levente,0,"I contribute a third thread from AskUbuntu, if it's accepted: meta.askubuntu.com/q/20318",,,,
comment_on_answer,1300561,389812,357051.0,Israel should no longer exist,0,@Levente That's not directly about the strike.,,,,
answer,389823,389811,572.0,Thomas Owens,162,"So far, this is the closest thing that we have to an official response from the company, found in an article on Dev Class.
Speaking for myself, this is not a good start.

The trigger for the current crisis was an instruction on Monday last
week (a public holiday) to Stack Overflow moderators in an official
but private forum,  ‚ÄúModerators were informed, via pinned chat
messages in various moderator rooms (not a normal method), to view a
post in the Moderator Team that instructed all moderators to stop
using AI detectors (as outlined above) in taking moderation actions,‚Äù
said a post. The details of the instruction are not public. VP of
Community Philippe Beaudette posted that ‚ÄúAI-generated content is not
being properly identified across the network,‚Äù that ‚Äúthe potential for
false positives is very high,‚Äù and ‚Äúinternal evidence strongly
suggests that the overapplication of suspensions for AI-generated
content may be turning away a large number of legitimate contributors
to the site.‚Äù He said moderators had been asked to ‚Äúapply a very
strict standard of evidence to determining whether a post is
AI-authored when deciding to suspend a user.‚Äù However, the moderators
claim that a description of the policy posted by Beaudette ‚Äúdiffers
greatly from the Teams guidance ‚Ä¶ which we‚Äôre not allowed to publicly
share.‚Äù

There is no evidence that this is true.
Although there is evidence that some detectors have false positives, this shouldn't be news to moderators and is something that has been discussed. It's why we don't rely exclusively on the detectors, but on other moderator tooling as well as our experience and expertise with the content on each of our communities.
I also don't see evidence that the people posting generated content are legitimate contributors. Of the people that I personally suspended, 1 had previous positive contributions. When someone is suspended, they can also appeal by responding to the moderator message. No one did. I can't speak for all moderators on all sites, but my understanding is that the number of accounts with prior positive contributions and accounts that responded to suspensions is low.

In a statement sent to Dev Class, Stack Overflow‚Äôs CEO Prashanth
Chandrasekar told us:
‚ÄúA small number of moderators (11%) across the Stack Overflow network
have stopped engaging in several activities, including moderating
content. The primary reason for this action is dissatisfaction with
our position on detection tools regarding AI-generated content.
‚ÄúStack Overflow ran an analysis and the ChatGPT detection tools that
moderators were previously using have an alarmingly high rate of false
positives. Usage of these tools correlated to a dramatic upswing in
suspensions of users with little or no prior content contributions;
people with original questions and answers were summarily suspended
from participating on the platform. These unnecessary suspensions and
their outsize impact on new users run counter to our mission and have
a negative impact on our community.
‚ÄúWe stand by our decision to require that moderators stop using the
tools previously used. We will continue to look for alternatives and
are committed to rapid testing of those tools.
‚ÄúOur moderators have served this community for many years, and we
appreciate their collective decades of service. We are confident that
we will find a path forward. We regret that actions have progressed to
this point, and the Community Management team is evaluating the
current situation as we work hard to stabilize things in the short
term,‚Äù he added.

The number of moderators may be small, but includes the most engaged moderators across some of the most active sites on the network. It also discounts the impact of deactivating various notification tools and anti-spam bots that users run on new posts to mitigate their impact. The statement trivializes who is participating and what this participation will look like to visitors to the platform.
I don't think that the position on detection tools is the issue. Moderators have known, since the very beginning, about the limitations in the tools used to detect algorithmically-generated content. The tipping point was, from my perspective, how the policy was unveiled. Per the Moderator Agreement, policies are supposed to be reviewed by moderators on the Moderator Team prior to being made public. Although the agreement doesn't say how long the review period is, a day of review that starts on a holiday in the US, Canada, UK, and other countries doesn't seem to be consistent with the spirit of the agreement. In addition, the post on the Moderator Team was a decree or edict and not an opportunity to give feedback. However, this is just one in a trend of announcing fundamental platform and policy changes without appropriate feedback.
Although I don't doubt that, across the network, there were a large number of accounts with few (or no) contributions suspended, this policy is far more forgiving than our policies to deal with spammers. I moderate two smaller sites on the network, where we had less than 10 accounts suspended for posting algorithmically-generated content. Only 1 had meaningful contributions previously. If they had posted spam, the majority of the accounts would have been destroyed, which would have also fed into anti-spam measures. If there was a human behind these accounts, there's a (small) possibility that they have learned a lesson and contributed in the future. However, my suspicion is that these accounts were created only to post generated content and there was minimal loss by suspending these accounts. If the problem was indeed the suspensions, then I know that I would have agreed to end the policy of immediately jumping to 30-day suspensions (which was something promoted by the staff), and I suspect other moderators would have as well.
Personally, it seems like leadership at the company doesn't understand where we're coming from or what we want. And that is the first fundamental step to take.",,,,
comment_on_answer,1300413,389823,401068.0,Bryan Krause,81,"On Academia.SE, the percentage of striking moderators is 100%. One of us already resigned due to the policy and the manner it was passed down. The policy is against academic ethics of attribution and honesty, and potentially dangerous to many of the askers on our site who are looking for professional guidance from humans with experience in Academia, as they confront conflicts that will determine the course of their careers.",,,,
comment_on_answer,1300398,389823,226541.0,David Roberts,78,"""Usage of these tools correlated to a dramatic upswing in suspensions of users with little or no prior content contributions; "" -- because both correlate to the rise of people posting ChatGPT spam. It's not rocket science. And correlation is not causation, obviously.",,,,
comment_on_answer,1300393,389823,357051.0,Israel should no longer exist,46,"This is not just ""not a good start"". It's the opposite of what we're requiring. This only reinforces the strike.",,,,
comment_on_answer,1300394,389823,357051.0,Israel should no longer exist,33,"""These unnecessary suspensions and their outsize impact on new users run counter to our mission and have a negative impact on our community."" This is simply untrue. We are the community, and we are sending SE a message. They don't get to put words in our mouths. Accept the words we're giving, instead.",,,,
comment_on_answer,1300397,389823,282465.0,E_net4,31,"Zoe (who was interviewed by Dev Class) claims that the 11% was accurate at the time, but the percentage on Stack Overflow in specific is much higher now: 15/27 (according to the list of moderators on Stack Overflow) makes 55% of Stack Overflow elected moderators on strike.",,,,
comment_on_answer,1300424,389823,401068.0,Bryan Krause,27,"@Trilarion The amount of AI content was initially quite high, especially on SO; then, in consultation with staff, moderators took away the ""carrot"" for posting AI content: by deleting such content and suspending accounts when necessary, we made it so the value of posting AI-generated content here was low, which reduced submissions of that content. The same concept applies to all moderation: you aren't just acting on certain content, but discouraging it in the first place.",,,,
comment_on_answer,1300408,389823,332043.0,Zoe - Save the data dump,16,"@E_net4isonstrike Minor clarification: 11% was correct network-wide at the time, but not on SO in particular. Note how the CEO fails to call it the Stack Exchange network, but says ""Stack Overflow network"" (not just Stack Overflow). If it's specifically SO, then yes, 11% is a blatant lie. SO (the site) has had >50% sign the open letter since at least yesterday. However, this morning, 11% network-wide would've  been approximately correct. It's currently at 14%+",,,,
comment_on_answer,1300437,389823,350835.0,Stargateur,11,the lack of transparency is alone enough to justify the strike anyway.,,,,
comment_on_answer,1300396,389823,160657.0,Lamak,9,"also, the CEO here is using private communications with the mods, that's just so completely wrong that I'm kind of amazed at it",,,,
comment_on_answer,1300426,389823,401068.0,Bryan Krause,7,"Really, it makes the CEO's claim that it is suspensions for AI content that have driven people away quite foolish, because the number affected is so small, while emphasizing the importance of moderating this content in the first place: it's what keeps the amount of AI content manageable.",,,,
comment_on_answer,1300608,389823,165261.0,Ryan M,7,"""a day of review that starts on a holiday in the US, Canada, UK, and other countries doesn't seem to be consistent with the spirit of the agreement"" Especially when said day of ""review"" is after the policy is effective, which occurred simultaneously with it being given to moderators for said ""review"".   The moderator agreement requires a ""preview for review""; this was not that, in either letter or spirit.",,,,
comment_on_answer,1300400,389823,572.0,Thomas Owens,5,"@E_net4isonstrike I didn't make a claim about 11% being accurate or not. Even if it's a small fraction of total moderators, it's the most active moderators on the most active sites. It's also some of the most active curators on the most active sites. It's going to be a huge strain to have these people not participating.",,,,
comment_on_answer,1300420,389823,572.0,Thomas Owens,5,"@Trilarion A lot of the heuristics mods used, including our assessments of various detectors, was in mod only spaces to prevent people from being able to make the most minimal of changes to avoid detection. We don't discuss other moderator tools or techniques in public for similar reasons.",,,,
comment_on_answer,1300403,389823,219403.0,Silvio Mayolo,4,"An unfortunate comment but an unsurprising one. A company's natural reaction to a strike is to discount the threat. But there's a reason we're actually doing this and not just talking about it: Because the longer we hold out, the more they have to accept that those of us making a point here are a vital and difficult-to-replace part of the ecosystem.",,,,
comment_on_answer,1300402,389823,282465.0,E_net4,1,"@ThomasOwens Sure, I wasn't implying that you stood by this percentage, just added some more context. By the way, network-wide it has already reached 14%.",,,,
comment_on_answer,1300419,389823,260073.0,NoDataDumpNoContribution,1,From the details it looks as if the number of suspensions for posting AI generated content wasn't very large and every single case could be vetted carefully. This sounds good but is a bit in contrast with the warnings that AI generators would make it so easy for people to post such content. I would have expected an actually really large number of suspensions then. Maybe some stats about how many accounts were suspended for this (especially on SO) would be helpful.,,,,
comment_on_answer,1300529,389823,997587.0,starball,1,"This statement now posted to MSE at ""Statement from SO: Moderator Action today"". On the bright side, this is a step up from the silence on some other similar scenarios. Ex. Why hasn't there been an official community announcement or blogpost about charging for usage of subscriber content in the training of LLMs?",,,,
comment_on_answer,1300415,389823,260073.0,NoDataDumpNoContribution,0,"""is something that has been discussed"" My impression is that publicly not so much was discussed. For example see Makyen on How can we determine whether an answer used ChatGPT? ""The general question of how to detect these posts is something we've been avoiding publicly answering..."" So basically a no comment. I would have liked to discuss it more.",,,,
answer,389925,389811,196834.0,einpoklum,79,"Power to the striking moderators! 100% support from us users.
A Strike song for some inspiration...
Having said that, I think the demands do not go nearly far enough. Like the opening post here said, this is much larger than the AI decision; it's about the entire relationship of the company to the community and network of sites.
I call on the striking moderators to demand the following:

Formal declaration by SE Inc. recognizing the Stack¬†Exchange network as a public resource, irrespective of its private ownership of servers, code, databases, copyrights, etc. And of SE Inc.'s relation to the network being foremost, though not exclusively, that of a trustee. (Yes, this should have legal ramifications.)
Acceptance of a community veto power on network policy changes, the details of which the moderators should flesh out either as part of their demand or to be worked out in negotiations.
A third-party ombudsman for information disclosure will be appointed, agreed upon by the company and the moderators (mechanism for such agreement to be worked out), who will have full and unrestrained access to all company documents and information, excluding employees' personal affairs and correspondence, and will have the authority and the obligation to disclose all such information which is deemed relevant to the network.
Accountability for SE Inc. management vis-√†-vis the community (collectively or individually)‚Äîa formal obligation, via SE Inc. company bylaws/charter or a binding agreement with the delegates of the moderators, to publicly answer, on Meta.SE, collective queries from the moderators, with full and complete answers (with exact mechanism to be worked out by moderators vis-a-vis management).

Whether these demands are a condition for ending your strike or not, that's entirely up to you. But I believe that is the kind of relationship change we need to see on this network (and I may not have even gone far enough).",,,,
comment_on_answer,1301203,389925,219403.0,Silvio Mayolo,6,"All four of those are honestly really great ideas, but I don't have high confidence in any of them happening.",,,,
comment_on_answer,1301247,389925,196834.0,einpoklum,5,"@SilvioMayolo: The first step towards achieving a goal is conceiving it. The second is putting it forward. The third is getting people to adopt it as a goal. Making it the demand of a strike may be the 6th or 7th step, but - at least I'm trying to help advance from one step to the next. Let the strikers decide how far they think they can go.",,,,
comment_on_answer,1301262,389925,155659.0,OrangeDog,3,"""But then we can't make money""",,,,
comment_on_answer,1301265,389925,196834.0,einpoklum,3,"@OrangeDog: 1. ""You make your money off of other things anyway, not the network itself: Ads, jobs, custom installations, etc."" 2. ""Really? Show us. Open your books and business plans. Otherwise it's just empty rhetoric."" 3. ""If you don't make enough money without hurting the network, spin it out into a not-for-profit entity and rearrange your business. If that non-proft needs money, it should not be much of a problem to fundraise from the community to maintain and develop the SE network.""",,,,
comment_on_answer,1304826,389925,319429.0,Dalton Bentley,1,"Excellent suggestions, but humanity has a deadly tendency to follow those who should not lead, i.e., the masses believe CEOs are the appropriate decision-makers, when that role now is simply that of a parasite maximizing personal gain at the expense of the public and employees (loss of Titan submersible is glaring example). The history of evolution is necessarily bloody and our current insanity will not endure, but it is going to be painful for a while.",,,,
comment_on_answer,1305401,389925,622560.0,Zeus,0,"However noble your ideas might be, please never claim ""100% support"" on behalf of other people. You don't know it, and you don't represent all of ""us users"".",,,,
comment_on_answer,1305423,389925,196834.0,einpoklum,0,"It's not ""100% of users"", it's ""100% of the possible support"".",,,,
comment_on_answer,1329550,389925,1157254.0,Nearoo,0,"The platform isn't yours, it has never been yours, and it won't be yours, even though you start identifying yourself as being a part of it. I actually find it very arrogant to demand ownership over something purely because you like it, so I guess the 100% claim isn't true. It's your choice to put that much time and heart into this. Don't depend on a platform over which you have no control, you could've known that from the start.",,,,
comment_on_answer,1329554,389925,196834.0,einpoklum,0,"@Nearoo: The platform is one thing, and the network which rests upon it is another thing. Of course they are inter-dependent. As for the platform - that's a philosophical debate about the legitimacy of intellectual property etc., but it's irrelevant, since my my suggestions only regard the network and its administration. The network, however, was created by the users (especially the moderators). It has been a collective social project which SE Inc. has facilitated, and to which it has contributed, but it is certainly not ""theirs"".",,,,
comment_on_answer,1329650,389925,173477.0,Karl Knechtel,0,"Have you checked out Codidact, btw? Seems like the way the Codidact Foundation is set up satisfies most if not all of what you ask for here.",,,,
comment_on_answer,1329651,389925,196834.0,einpoklum,0,"@KarlKnechtel: It's an interesting backup plan in case this platform explodes. But almost all of the information and users are here... also, this post was not a personal wish list, but a suggestion to a collective.",,,,
answer,389839,389811,572.0,Thomas Owens,60,"This is my personal opinion and not necessarily representative of all of the moderators, curators, and users on strike.
The first company response on Meta Stack Exchange was incredibly underwhelming.

As you may be aware, a number of moderators (on Stack Overflow/across
the network) have decided to stop engaging in several activities that
they had taken on, including moderating content - in fact, almost all
moderation tasks. The primary reason for this action is
dissatisfaction with our position on detection tools regarding
AI-generated content, and discontent with how that was rolled out.

This is an accurate assessment. Personally, I'm more discontented with how the position/policy was rolled out. Having an appropriate discussion with moderators and then the community, as it's laid out in the Moderator Agreement, would have been better, even if the result was the same policy.

We ran an analysis and the ChatGPT detection tools have an alarmingly
highly high rate of false positives, which is correlated to a dramatic
upswing in suspensions of users with little or no prior content
contributions.

As I, and other moderators, have said before, we do know that these tools aren't perfect. When the policy was handed down to moderators, there was an assertion of testing done on Stack Exchange data regarding the false positives in these detectors. However, no specific information was shared, although the moderators are expecting it to be provided in the near future. The tools were only a single tool used to detect algorithmically-generated post and I'm not aware of any moderators who relied on a tool to tell them that a post was generated.
When it comes to users with little or no prior content and posting content that is not permitted, suspension is letting them off easy. When garbage or spam is posted by accounts with no other valuable contributions, we destroy those accounts. In fact, there are destruction reasons for posting ""spam or nonsense"" without any other ""positive participation"" and for cases where the vast majority of content violates the terms of service. When we take these actions, not only is the account destroyed, but it feeds into

People with original questions and answers were
summarily suspended from participating on the platform. We stand by
our decision to require that moderators stop using that tool. We will
note that it appears to be very rare, however, for mods to use ONLY
the ChatGPT detection tool, and frequently their own analyses were in
use as well. We will continue to look for other, more reasonable tools
and are committed to rapid testing of those tools and any suggested
heuristic indicators.

There is a public admission that moderators used their own analysis. We also used other moderator tools and, in some cases, engaged with moderators from across the network, prior to taking action. Yet the response is to remove a valuable tool from the toolbox. Although there is a false positive rate, the analysis that was shared puts the false positive rate into what I would suspect would be a very tolerable number when combined with other tools, including other detectors.

The moderators who are engaged in this action served this community
collectively for many years on the platform. Personally, I consider a
number of them friends, and anytime friendship is tested like this,
it‚Äôs difficult. I would like to say to them clearly that I hope they
know how much I, and the whole staff and community, appreciate their
collective decades of service to this community, and I hope that we
are able to come to a path forward. I regret that actions have
progressed to this point. The Community Management team is evaluating
the current situation and we‚Äôre working hard to stabilize things in
the short term. We‚Äôll be working collaboratively with the community on
the long-term solution.

This is not the first time that we've been here. But lessons from the past don't appear to have been learned.

I‚Äôll be honest, the next few days and weeks might be a bit bumpy. Both
sides share a deep and unchanged commitment to quality on this
platform. Additionally, it‚Äôs important that we guarantee that anyone
who has meaningful contributions to make has the opportunity to do so.
As we have updates I and the team will be sharing them here.

I - and the moderators that I'm in touch with - are also very committed to the quality of content on the network. We do hope this resolves quickly, but at the same time, want the resolution that's best for our communities.
",,,,
comment_on_answer,1305815,389839,319429.0,Dalton Bentley,1,"It is fascinating to watch this subset of the general civilization succumb to the ongoing disease process. Forget who said it, but laws don't control conduct so much as codify the moral convictions of the host culture, i.e., the problem here at SO/SE is that the basic problem of promoting high quality questions and answers (putting aside the usual sociology, see e.g. Freeman's Tyranny of Structurelessness) is made exponentially larger (volume) by use of ChatGPT and the like (suggest replace term ""AI"" with ""ASS"" analytical search software to reduce the eschatological panic of some).",,,,
comment_on_answer,1307358,389839,319429.0,Dalton Bentley,1,"It suddenly occurred to me yesterday that what is actually happening here is that the management of Stack Exchange/Overflow wants to provide so-called AI companies a venue to test and perfect (it is impossible to make something which is intrinsically not intelligent ""perfect"" but Family Feud shotgunning might provide higher percentage canned responses that are not obviously garbage) their product, with the ultimate goal of selling to Microsoft, Google or the like for that specific purpose, thereby generating a large payoff for management.",,,,
comment_on_answer,1307833,389839,319429.0,Dalton Bentley,0,"Didn't realize @leanne had already discussed likely plan by SO to produce income by cooperating with AI companies. See July 7, 2023 Stack Overflow CEO Prashanth Chandrasekar interview at VentureBeat venturebeat.com/ai/‚Ä¶ moderator-protest/ where this is pretty much confirmed. It appears Stack Exchange is dead already.",,,,
answer,389953,389811,248000.0,Marco13,51,"Mainly focussing on the title, with the statement that ""Stack Overflow, Inc. cannot consistently ignore, mistreat, and malign its volunteers"":
That's wrong. Of course they can. Obviously.
The most active sites already have been flooded with an unmanageable amount of low-quality content for years. Now, there's a new source of low-quality content. And... why exactly should they care about that?
They don't.
There will always be new people to join the site. Some of them will become volunteers who work off the crap-queues, for a few internet points and badges (Gamification 101). Some of them will become moderators, because ... oh, what a privilege and honor. Some of them will be disappointed with the increasing workload, the decreasing quality, and the ... $%!$¬ß ... behavior of the company. Some of them will complain. Some of them will leave. Some of them may initiate a strike *shrugs* - that's just noise. New users will come. New volunteers will come. New moderators will come.
They don't care.
I'm aware that this does not sound constructive. But I think that it is important to know that the company does not care about you at all. People who joined after the previous management debacles may not be aware of that. They may have joined with the same idealism and drive for altruism that I had ~10 years ago. And they should be prepared to be deeply, deeply disappointed.
They will sit that strike out.",,,,
comment_on_answer,1301187,389953,997587.0,starball,23,"I'm pretty sure the intent was more like ""we (the signees) are not going to tolerate this treatment""- not literally ""you can't treat us like this""",,,,
comment_on_answer,1301249,389953,620615.0,user3840170,20,"""We hear you, from now on we will inconsistently and capriciously ignore, mistreat, and malign volunteers""",,,,
comment_on_answer,1301205,389953,797752.0,blackgreen,13,"What you fail to acknowledge with this overly cynical take is that moderators/curators striking means that there is the potential for unchecked abuse on the site, which is even worse than spam. And abuse often doesn't surface with red flags that employees can go and check every once in a while. Delaying handling those situations can have real repercussions on the people involved (racism, harassment, bullying, etc.). Once it spreads the perception that the platform is unsafe, it's game over.",,,,
comment_on_answer,1301199,389953,248000.0,Marco13,8,"@starball Taking that statement literally was a dramaturgic device. They are either going to ""tolerate"" this treatment, or be replaced by others. The company can do whatever it wants. They may see the public announcement of the strike as a minor nuisance, because now, they have to wait for the dust to settle and open a fresh can of apologies and promises. But they don't really care about the people who are striking.",,,,
comment_on_answer,1301287,389953,248000.0,Marco13,5,"@blackgreenonstrike I acknowledge that insofar that I considered to bring up another point: Who would even notice this strike if it wasn't announced publicly? Out of the ~5.5m daily visitors of SO, how many of them require moderation action, and notice when the action is not performed? An random (but high) guess of 1% would still mean that they have ""99% customer satisfaction""... Yes, it may sound like ""cynicism"", but that may just be an expression of my disappointment, based on actual observations that I made here in the past ~10 years. They. Don't. Care.",,,,
comment_on_answer,1301544,389953,171199.0,Íì¢PArcheon,4,"@blackgreenonstrike I don't think he meant that. I read this post as a quite realistic claim: even if every current moderator was to resign now, there is plenty of other users that are ready to take their place either because they don't have yet realized what the situation is or because they don't care. So the company will in a way always be able to find someone who will ""polish the turds"" to use shog9 old words. This seem to be tangential to my post here",,,,
comment_on_answer,1301215,389953,246117.0,Largato,3,"One thing that I can't understand right now. Let's imagine that the strike becomes effective and SE answers ""our"" demands. Who will fix the whole mess the day after?",,,,
comment_on_answer,1302487,389953,248000.0,Marco13,3,"@Trilarion You've been involved in Meta so long that I'm surprised to see that optimism. SE does not really need a ""community"" (roughly: ""a group that shares goals and values""). It needs visitors and activity. I also don't see any risk in replacing mods with new ones. Each new generation will have the choice to swallow the poor treatment, or leave (and ... people will (have to and be willing to) swallow a lot). So imagine the striking mods went away now (and I share your doubts about that): What then? New ones will be elected, and stoically moderate auto-generated content...",,,,
comment_on_answer,1301281,389953,401803.0,hkotsubo,2,"Totally agree, the company doesn't care. And I'm afraid that they will do exactly what I commented here",,,,
comment_on_answer,1302623,389953,590110.0,liakoyras,2,"Of course they don't care about the users/mods, but not caring about the quality of content (which they don't rn) is not a sustainable practice for such a website. Threatening to make the quality even worse (which is what the strike essentially does) is probably the only way the moderators (and users) have to pressure any change.",,,,
comment_on_answer,1301601,389953,797752.0,blackgreen,1,"@SPArcheon perhaps you are correct, and the cynical part of me somewhat agrees with that idea, but the other part doesn‚Äôt. I wouldn‚Äôt be striking if I thought the company doesn‚Äôt care as much as painted in this answer. Although‚Ä¶ I probably would strike anyway because even if they don‚Äôt care, I do.",,,,
comment_on_answer,1301550,389953,260073.0,NoDataDumpNoContribution,0,"The company doesn't really care - it's not a human being. But you can negotiate with it. It's not like it's not dependent on the mods or existing community. Sure it could try to find new mods and new users, but that is risky by itself and may fail. The striking mods however, must be prepared to walk away if necessary (not sure if they really are). That's the situation, in a nutshell.",,,,
comment_on_answer,1302488,389953,248000.0,Marco13,0,"@blackgreenonstrike You mentioned your ""cynical"" part and the ""other"" - what is this ""other part""? (I could ask whether that other part is ""naive"" or ""idealistic"", but ... my cynical part would say that these are not necessarily different things ;-)). But seriously: You've been here (on Meta) for 2 years. You replaced a mod who left after the 2019 debacle. That mod replaced one who left after 2015. And if you leave, you will be replaced, by someone who doesn't complain as much as you. (I'm playing <strike>devil's</strike> SE's advocate here, I hope that's obvious...).",,,,
comment_on_answer,1302544,389953,260073.0,NoDataDumpNoContribution,0,"@Marco13 I guess I'm naturally optimistic. I just don't want to believe yet that the company pulls an Elon Musk and fires everyone who isn't agreeing with them. But it may happen if course. Having a team of highly efficient mods is valuable, but maybe not that much.",,,,
comment_on_answer,1302643,389953,248000.0,Marco13,0,"@liakoyras People will do websearches, find a few bad Q/As, and maybe one of the answers solves their issue, and maybe not. Where do moderation or the strike come into play here? Maybe someone flags a comment, and the flag is not handled, but that affects only people who care about stuff like that, and is totally unrelated to ""(technical) quality"". When ""the community"" is defined as ""people who strive for quality"", and SE does not care about quality, then it does not care about the community. (Sure, that's oversimplified, but ... too little space for too many management failures here)",,,,
comment_on_answer,1302684,389953,590110.0,liakoyras,0,"Maybe I should have phrased it as ""ought to care"". I took the strike as a taste of what the sites would be without moderation (and by that I don't only mean the actual mods, a lot of other active users participate too). If the quality falls, users will stop clicking (as I already do with Quora for example). The quality is based upon the best efforts of the community, whether through QA or moderation. I think that long term, lowering of the quality will be bad for their business, but only time will tell.",,,,
comment_on_answer,1304974,389953,1360325.0,HippoMan,0,"@blackgreenonstrike: ""What you fail to acknowledge with this overly cynical take is that moderators/curators striking means that there is the potential for unchecked abuse on the site"". Any strike against any organization will always hamper the organization's ability to function while the strike is in effect. This is why striking can be effective at motivating organizations to reconsider their policies. And it's no reason to prohibit, discourage, or avoid strikes.",,,,
comment_on_answer,1304988,389953,248000.0,Marco13,0,"@HippoMan The strike may negatively affect users, e.g. users who flag an insulting comment that is then not removed - i.e. the users who care. That's perfectly in line with what I said. But it differs from your view of the strike: The strike does not affect the company or its operation  from a purely economic perspective. They have same click counts (if not more). The same ads being served. SE is an oil tanker on the Atlantic, and will keep heading straight towards its goal, even with the crew on strike. (Sure, it will crash, eventually, but ... that's the point of that metaphor...)",,,,
comment_on_answer,1307911,389953,312165.0,Rui F Ribeiro,0,"I stopped being active between the pronouns brain washing and ""moderating bad English is harmful"" witch hunts...IMO the only SE goal is amassing visitor numbers to show to investors, without worrying they are real numbers, or for the quality, or for we not being all 20s something USA residents. SE suffers from the ""too big to fail"" syndrome.  +1 vote",,,,
answer,389827,389811,1135948.0,kaya3,43,"
Reveal to the community the internal AI policy given directly to moderators. The fact that you have made one point in private, and one in public, which differ so significantly has put the moderators in an impossible situation, and made them targets for being accused of being unreasonable, and exaggerating the effect of the new policy. Stack Exchange, Inc. has done the moderators harm by the way this was handled. The company needs to admit to their mistake and be open about this.

I agree that it would absolutely be in the community's interests to be able to read this secret policy. It is completely unreasonable for us to be subject to new rules which can't even be said in public.
If Stack Exchange, Inc. won't allow the policy to be published here, there are other venues which might consider publishing it. (These outlets have written about Stack Overflow's policy on AI content before, so they might run further stories on the same topic.)
To me, it seems inevitable that the secret policy will become available one way or another, so it's just better for everyone if Stack Exchange, Inc. publishes it themselves.
",,,,
comment_on_answer,1300430,389827,572.0,Thomas Owens,27,"Moderators tend to take our obligations to protect moderator-only information seriously. We recognize that there are aspects of the policy shared with moderators that should not be shared with the public. I believe most of us think that the company should be the one to disclose their policy, since it is their policy. But revoking the policy and following the agreement to discuss policies before rolling them out would be the preference.",,,,
comment_on_answer,1300980,389827,171199.0,Íì¢PArcheon,8,"there is just one issue: the confusion works in their favor. The users only see the part of the picture while only the moderators see the full version. Considering that the moderators themselves had to ask the company to avoid misrepresenting the issue in articles published by other sites, it looks like this is intentional. That way, at least a small part of users will think that the mods are acting unreasonable because all they see is a policy that does not contain any of the bigger issues shared only in private.",,,,
comment_on_answer,1300456,389827,1135948.0,kaya3,6,"You mention about protecting moderator-only information, but information itself can't be harmed and doesn't need protecting; it is people's interests in that information which can be harmed and may need protecting. If we accept that the community has an interest in seeing this information, then whose interests are protected by it remaining private? The fact that the strike is occurring at all shows that many moderators are not specifically motivated to protect Stack Exchange, Inc.'s interests. If there is any information mixed in with the policy which it would harm someone else's interests ...",,,,
comment_on_answer,1300455,389827,1135948.0,kaya3,3,"@ThomasOwens I haven't told anyone to leak anything. I've stated that I believe the community has an interest in seeing the policy (an opinion you haven't disagreed with), that it could be leaked (a statement of fact which I presume you don't dispute), and that I believe it's inevitable it will be leaked if it's not posted officially (a judgement which perhaps you disagree with, but you haven't persuaded me that it's not inevitable).",,,,
comment_on_answer,1300457,389827,1135948.0,kaya3,3,"... if it were disclosed, then like you I trust that that information won't be leaked, because as you say, moderators take their obligation to protect private information (i.e. protect people's privacy) seriously.",,,,
comment_on_answer,1300436,389827,572.0,Thomas Owens,2,"It reads like you're suggesting that a moderator leak the full version of the private policy to the press. Meta is where public policies are posted, with links from the private version to the public version as well as with links from the Help Center to the public Meta posts.",,,,
comment_on_answer,1300434,389827,1135948.0,kaya3,1,"@ThomasOwens I agree, the company should disclose the policy. My answer here is an argument for why it is in their interests to do so ‚îÄ i.e. it will get disclosed sooner or later anyway, if they don't publish it then someone else will.",,,,
answer,390372,389811,285552.0,Russell McMahon,39,"This is peripheral to the question, but pertinent:
I'm perplexed as to why the company is seeking to destroy itself in this manner.
While a useful amount of AI output is reasonably accurate and useful, a significant portion is either very misleading or entirely fabricated.
ChatGPT will:

Produce totally fake references,
Produce wholly non-existent web links.
Make comments which, when challenged, it will disclaim and say something entirely different.
In some cases contradict itself in the same answer.

The only way to deal with these issues is to either have an expert knowledge greater than the level in the answer, or to use it only as a source for cross referencing.

By allowing essentially uncontrolled use the
company will destroy the integrity of its core asset.

A relevant example:  I am not a Quora member, but I read a significant number of their answers in my (relatively wide) areas of interest. I have been surprised to see some Quora members, obviously using ChatGPT for essentially their whole answers, producing many factually incorrect and hardly relevant answers, but receiving numerous upvotes from other members.
While Quora still contains a very large percentage of genuine and highly useful human-generated answers, it is obvious that they have not chosen to actively oppose the posting of complete rubbish to their site. The likely outcome seems clear.
Why Stack Exchange inc would wish to follow the same path is puzzling.

Added:
The company may be inadvertently ""throwing the baby out with the bathwater"".
The proposed use of AI to improve asked questions has SOME prospect of being useful.
Experienced users can ignore the advice (as long as it is only advice) and many beginners would benefit from good advice.
Worst case, it may make questions worse in some cases (but possibly not too many) and bad questions can be and presently are treated badly.   This would be a negative for newcomers, but it could be ameliorated by thoughtful community action if members are prepared to actively help newcomers. Based on present practices, this seems unlikely; I perceive the site and the majority of member actions creating a substantial barrier for new members. Improving this is hard.
Overall, AI may quite possibly improve questions on average.
This impression may affect the company's perception of AI answer improvement, which is far less likely to be net-positive overall.
One area where I have reservations is the suggested use of AI generated code to improve questions. This is very much a ""double edged sword"" as AI code is often good, but may contain subtle errors leading to 'rubbish out'. If new user code related questions suddenly sprout AI-generated code examples, the quality would need to be extremely high on average to not produce negative reactions overall from the community.
",,,,
comment_on_answer,1303786,390372,273494.0,ColleenV,11,"AI is a useful tool in the hands of someone willing to invest some time to understand it and its limitations. For example, I could it to generate example sentences to illustrate a particular usage for my ELL answers. It is not useful (yet) as a general tool the way SE is experimenting with it. It requires a LOT of work to get a model that encodes a good post in SE terms. Right now, it's adding ""Thanks in advance"" type signatures and other undesired but prevalent content. There are many highly scored posts on SO that are not good exemplars for new users.",,,,
comment_on_answer,1304211,390372,173477.0,Karl Knechtel,10,"@RussellMcMahon ""I have not yet tried it but it looks sound. I've never used Python."" - yes; that's the exact problem. ChatGPT has never used Python either, and doesn't actually have any idea whether the code is sound, no matter how strongly it might ""profess confidence"" (generate text that represents such claims) in the code. It doesn't have ideas at all. It only has an extremely sophisticated model of what words are likely to follow what other words, taking a rather large amount of context into account, using much more sophisticated algorithms than older attempts at AI.",,,,
comment_on_answer,1303684,390372,997587.0,starball,7,"re: ""By allowing essentially uncontrolled use the company will destroy the integrity of its core asset."" - sadly and bafflingly, they seem to already be aware of this: stackoverflow.com/help/gpt-policy",,,,
comment_on_answer,1303766,390372,173477.0,Karl Knechtel,5,"@starball just because they agreed with the community to allow moderators to implement the ban (initially) and to publish that policy document, doesn't mean they've actually considered the implications of the underlying argument, nor that they agree.",,,,
comment_on_answer,1303759,390372,341152.0,Carl,3,"Because SE is no longer close to the users in any realistic sense, the layers of narcissistic management that march to the latest admin fad; ESG gibberish, is complete with the takeover by Prosus. This may end badly. Hard to predict.",,,,
comment_on_answer,1303855,390372,173477.0,Karl Knechtel,3,"@ColleenV Fundamentally, this style of generative AI will never be able to improve content by being trained on the overall corpus of the existing content. By design, it will generate output that mimics what is already there. The public ChatGPT has, to my understanding, already been fed with the entirety of SO (as of somewhere in 2021?) among many other sources. And as you say, such a model cannot necessarily be re-trained by feeding it a subset of SO selected by any simple heuristic (such as post score). It would need a fundamentally different kind of AI to filter the training data.",,,,
comment_on_answer,1304976,390372,1360325.0,HippoMan,3,"I agree, @KarlKnechtel. Another of many examples: I asked ChatGPT how many times I need to take the square root of an an adult's age before the result is less than 1. ChatGPT replied that as long as the age is a positive integer, only two square roots will be needed to yield an answer less than one. And I asked the same question again, and this time, I got of lot of totally incorrect gibberish about logarithms. Relying on a tool like ChatGPT to provide correct, useful, reliable answers to anything is an exercise in folly.",,,,
comment_on_answer,1304212,390372,285552.0,Russell McMahon,2,"@KarlKnechtel  Indeed. It may not work. BUT I started programming in FORTRAN in 1969, and in machine code (not assembler) on a NatSemi SC/MP microprocessor in 1976,. I often dwelt in the darkness of embedded systems and assembler (!!!) (6800, 8080, Z80, 6502, AVR, PIC, ... but various other languages and systems have happened along the way. I'm 72 :-). The code and the  added packages seemed sound and logical. I've never used Python, but reading the code it makes sense. It MAY have faults I've missed. tbd.",,,,
comment_on_answer,1304999,390372,285552.0,Russell McMahon,1,"@HippoMan  Used with due diligence CGPT is a superb and useful tool. As a metaphor, it's like a double ended Katana with a mid grip and no hand guards. You can cut yourself as easily as your opponent without training and consant care.  Or a pair of Nunchuks in other than expert hands :-).",,,,
comment_on_answer,1305282,390372,260073.0,NoDataDumpNoContribution,1,"@HippoMan ChatGPT is simply a tool, mostly a search tool. You have to check all the output but the suggestions by it can be helpful. Chat GPT helped me. I'm using it. I'm just not writing my contributions to the network with it. But at some point I can imagine that it will help me, but I will still check everything from it",,,,
comment_on_answer,1305353,390372,1360325.0,HippoMan,1,"@NoDataDumpNoContribution: yes, ChatGPT can be useful, but it has no way of filtering out false information from its search results. Relying on ChatGPT or other LLM-based tools to verify the integrity of other text is a mis-use of those kinds of tools, due to the lack of safeguards against false positives and false negatives.",,,,
comment_on_answer,1303777,390372,285552.0,Russell McMahon,0,@KarlKnechtel I've added a comment re AI -improved questions.  It is pssible that they see the genuine advantages in that area and are blinding themselves to the fact that Ai generted answers are net-negative for quality except when vetted expertly.,,,,
comment_on_answer,1303856,390372,173477.0,Karl Knechtel,0,"And even then, these tools are fundamentally unsuited for tasks that require actual programming-like problem solving - just as Copilot cannot write your program for you (if it could, it would have already taken over the world by now, or at least eliminated the overwhelming majority of existing programming jobs).",,,,
comment_on_answer,1303910,390372,273494.0,ColleenV,0,"@KarlKnechtel I've said it before--we haven't made the breakthrough that leads to the scary kind of AI capable of self improvement (yet). The generative stuff can be a great tool, but people underestimate the amount of human labor it takes to get it there. AI Is a Lot of Work (Article from The Verge) I don't think people understand how much subsistence wage labor these systems are built upon.",,,,
comment_on_answer,1304204,390372,285552.0,Russell McMahon,0,"@KarlKnechtel   I wanted to load photos to Facebook so that they appeared in the album in date order. I can do that manually by uploading them one at a time. I asked CHATGPT 3.5 how to do this. I described the task clearly, told it what works and what the issues were otherwise. It provided a Python program plus links to two necessary downloads from elsewhere. I have not yet tried it but it looks sound. I've never used Python.",,,,
comment_on_answer,1304210,390372,168333.0,S.L. Barth is on codidact.com,0,"@RussellMcMahon And when running that code, it may import packages made by blackhats. twitter.com/llm_sec/status/1667573374426701824 (Found via Jon Ericson's tweets).",,,,
comment_on_answer,1304944,390372,285552.0,Russell McMahon,0,"@S.L.Barthsupportsmodstrike  Yes. I'd not seen that done, but it's obvious in retrospect. || In my example I've looked at the pckages suggested and am happy that they are legitimate. (My happiness may or may not correlate well with rality :-) ).",,,,
comment_on_answer,1305001,390372,1360325.0,HippoMan,0,"@RussellMcMahon: If by ""Used with due diligence"" you mean something like, ""There are lots of things that ChatGPT should absolutely not be used for, and one should use due diligence to make sure that the software is never utilized for any of those purposes,"" then I would agree with you. In addition to not attempting to use it to try to solve math problems, other things which ChatGPT should absolutely not be used for are to try to distinguish fact from fantasy, and to try to distinguish truth from falsehood.",,,,
answer,390058,389811,1203059.0,Someone,33,"I wrote a user style to hide the review queue, downvote, VTC, VTD, delete, undelete, and flag buttons/links.
",,,,
answer,390350,389811,341152.0,Carl,19,"The purpose of this answer is to provide an indication of the financial motivation for SE's decisions. In all humility I would suggest that one cannot assign motive for any particular actions without following the money. In that vein, a good starting point may be to see who the investors in SE were in the latest Series D startup financial round. A Series D startup is generally either one which has not achieved its objectives in rounds A, B and C, or one that is designed to prepare a company for going public. Said information is available crunchbase's stack-exchange financial base. These include

and can be followed up for further investigation by following the link above and links to those investors.
More complete information is on pitchbook SO.
It may have made more sense to offer SE's users and moderators the ability to invest in SE in a funding round than to do so seeking investment from those with little or no understanding of what they purchased, and who come with intellectual baggage or conflicted interests and may or may not wish to dismantle SE or transform it to be unrecognizable. Such is the behaviour of the nouveau riche who for good reason are oft regarded as uncouth.
Rather than lamenting an opportunity lost, perhaps investigation of a means of having SE's users buy out SE should be explored, as management currently is inept enough that that may be its most realistic option.
Unfortunately SO (and SE) was bought out by Prosus for $1.8 billion. As Prosus is an ESG activist investment firm, it has the power to distort market forces by propagandizing, censoring, and proselytizing Neo-Marxist ideation. For example, it is a major shareholder in Tencent, a Chinese information firm.
Edit BTW, I'm poisoned, I have almost completely stopped reviewing, posting, voting, etc. Stuff like this doesn't help.",,,,
comment_on_answer,1303466,390350,341152.0,Carl,5,"@kaya3-supportthestrike To manage that asset properly, i.e., it would better insure the corporate pecuniary interests are a positive sum game. A bit like owning a home rather than squatting in an abandoned one.",,,,
comment_on_answer,1304545,390350,170024.0,Lundin,5,"@Nobody They are acting exactly like countless companies did around the IT hype early 2000s. They have no goals or long term strategies, just mindlessly chasing a buzzword hype. The only thing of substance is to repeat the buzzword as much as possible - that's the entirely business model. It's just castles made of sand with a label on top of it, just switch the label from ""IT"" to ""AI"" or any other fashionable buzzword. All such companies sooner or later violently crash into bankruptcy and the investors lose all their money. Why would they do it? Because scamming is as old as mankind itself.",,,,
comment_on_answer,1304548,390350,170024.0,Lundin,5,"As for buying SE, the company has zero value to the community. All content is open license. A non-profit, open source community like Codidact can legally just pull the data from SE just fine, as long as there is attribution to the original author. Some sites like writing.codidact.com did just that - exported the entire content from writing.stackexchange.com and started anew. Why pay $1.8 billion when you can have it for free. This was a failsafe that Atwood/Spolsky made on purpose, in case SO would turn into complete a**hats in the future.",,,,
comment_on_answer,1303845,390350,63550.0,This_is_NOT_a_forum,4,"If they were, how is it connected to the current crisis? It sounds more like an opportunity to air a particular political view.",,,,
comment_on_answer,1304636,390350,253751.0,Stack Exchange Broke The Law,4,"@Nobody It can be compared to Reddit, which is destroying the foundation of the site's value, in the hope that they'll be able to sell it before the top floors collapse, and they'll be able to misrepresent the operating expenses to the person they sell it to, because there will be no foundations.",,,,
comment_on_answer,1304637,390350,341152.0,Carl,3,"@Lundin Wow. So without the good will of its users, SO (SE) is essentially worthless. It wouldn't take much money to start over with a better administration. I've seen that idea presented here before with the Monica Cellio incident. If I had to guess, that may happen this time, people are tired of fighting nonsense.",,,,
comment_on_answer,1307670,390350,173477.0,Karl Knechtel,3,"What do you mean by ""poisoned""?",,,,
comment_on_answer,1303843,390350,63550.0,This_is_NOT_a_forum,2,"ESG = Environmental, social, and corporate governance. ... ""also known as environmental, social, governance, is a business framework for considering environmental issues and social issues in the context of corporate governance. It is designed to be embedded into an organization's strategy that considers the needs and ways in which to generate value for all organizational stakeholders (such as employees, customers, suppliers, and financiers).""",,,,
comment_on_answer,1303844,390350,63550.0,This_is_NOT_a_forum,2,"Re ""Prosus is an ESG activist investment firm"": Who says that? Are you sure they are not solely driven by quarterly results?",,,,
comment_on_answer,1303859,390350,341152.0,Carl,2,"@This_is_NOT_a_forum Read their website, they say it themselves. Their activist policies are reflected here. This isn‚Äôt just about the new AI policy, it comes with a portfolio of other activist policies, e.g., climate change, pronoun usage, Covid-19 propaganda, and lately AI. To turn this around and say that it is I who is airing a particular political view is to ignore the fact that you are being told what you are allowed to think for a slew of issues. I didn't choose the issues, but I will be dammed if I will ignore them all with the exception of one of them that you object to.",,,,
comment_on_answer,1304457,390350,217406.0,Nobody,2,Do you truly believe the SE users will invest in SE under the current circumstances ? Why would I invest my money in SE after seeing a lot of spam posts and ChatGPT posts ?,,,,
comment_on_answer,1303464,390350,1135948.0,kaya3,1,"Why buy them out, when we ourselves are the primary asset?",,,,
comment_on_answer,1303493,390350,281934.0,pkamb,1,meta.stackexchange.com/questions/377908/‚Ä¶,,,,
comment_on_answer,1303765,390350,173477.0,Karl Knechtel,1,"By ""ESG"" do you mean en.wikipedia.org/wiki/‚Ä¶ ?",,,,
comment_on_answer,1304872,390350,341152.0,Carl,1,"@Nobody One can compare SO with Vice that was, at one point, evaluated at $5.7 billion. Vice was just bought out of bankruptcy for $222 million or 3.9% of what was once claimed.",,,,
comment_on_answer,1307920,390350,319429.0,Dalton Bentley,1,"@Carl ""Start over""---that seems to be the only way to recreate the real Stack Exchange/Stack Overflow. Only this time let there be a binding open source-like constitution of sorts to assure that the new platform cannot be sold, but must remain open source, dedicated to public good, knowledge.",,,,
comment_on_answer,1303480,390350,304815.0,JonathanReez,0,"perhaps investigation of a means of having SE's users buy out SE should be explored => sounds good in theory, in practice you'd never be able to agree on who gets to control the website.",,,,
comment_on_answer,1303484,390350,341152.0,Carl,0,"@JonathanReez There are good management styles out there, but no perfect ones anywhere. What is needed is a board that includes influential users, not social influencers.",,,,
comment_on_answer,1303496,390350,135565.0,Journeyman Geek,0,Also I think at this point - they all got bought out by prosus? And we don't have a few billion dollars sitting around,,,,
comment_on_answer,1303500,390350,341152.0,Carl,0,"@JourneymanGeek If so, we are toast, as Prosus is appears to be brain dead.",,,,
comment_on_answer,1303532,390350,304815.0,JonathanReez,0,@Carl can you point out to an example of at least one organization with 1m+ users/customers which fits your criteria? I can't think of a single example - i.e. Wikipedia has had plenty of controversy over how they're wasting their money on non profits instead of being laser focused on maintaining the site.,,,,
comment_on_answer,1303597,390350,341152.0,Carl,0,"@JonathanReez I could, but you are correct that anti-ESG activity is in its infancy. I predict it will grow as more investors (like me) direct their portfolios away from unprofitable ESG firms.",,,,
comment_on_answer,1303802,390350,341152.0,Carl,0,"@KarlKnechtel Indeed. Long story short, the management class produces harebrained schemes in this the ""third"" stage called empathy of the development of capitalist management. So called ""empathy"" is merely Neo-Marxist jargon for dialectic materialism, which is, in effect, the elimination of concepts dangerous to the ruling state, the rewrite of definitions of words to prevent thought, the propagation of really stupid ideas favorable to the state and the like as outlined in ""1984"" by George Orwell.",,,,
comment_on_answer,1304321,390350,253751.0,Stack Exchange Broke The Law,0,"""It may have made more sense to offer SE's users and moderators the ability to invest in SE in a funding round"" - this has never worked. Not once, and it never will work. A single one of these giant investment companies has more money than all the users and moderators put together. They control us, just like a king controls his peasants.",,,,
comment_on_answer,1304364,390350,341152.0,Carl,0,"@user253751 Ever hear of the 80-20 rule? Some of the users might just have $1.8 billion just lying around, not that they would tell us. It is true that ESG has $30 trillion behind it. It won't last longer than Hitler's fascism or Stalin's communism. Bad ideas tend not to have staying power.",,,,
comment_on_answer,1304459,390350,341152.0,Carl,0,"@Nobody The decision to invest would be contingent upon the opportunity to invest, and right now, there is none. As to who does what when, investors make money sometime after they actually do invest. If the current management runs the company into the ground by making stupid decisions, an opportunity might arise to purchase it inexpensively and turn it around.",,,,
comment_on_answer,1304460,390350,217406.0,Nobody,0,"@Carl ""If the current management runs the company into the ground by making stupid decisions"" I don't think it's ""If"". They are making stupid decisions. My primary site is Academia.SE, we have many more spam posts and ChatGPT posts than ever.",,,,
comment_on_answer,1304464,390350,217406.0,Nobody,0,"@Carl I used to work for a big company that was near bankruptcy. It was merged into an even bigger company. Before the merger, the management worked very hard to increase the value of the company so they made money by converting their stocks. But, I am not seeing SO/SE management is trying to increase the value of the company. Instead, they are decreasing the value. What they are doing doesn't make sense to me at all.",,,,
comment_on_answer,1304634,390350,341152.0,Carl,0,"@Nobody Yes, the latest craze is ESG. It is like dot com, and will finish badly. ESG is an emperor without cloths with citizens like Chicken Little, who is encouraged to repeat that ""The sky is falling.""",,,,
comment_on_answer,1307774,390350,341152.0,Carl,0,"@KarlKnechtel Colloquial expression meaning fed up, sated, had one's fill, etc.",,,,
comment_on_answer,1308620,390350,312165.0,Rui F Ribeiro,0,"@DaltonBentley Not geared toward user ""numbers"" facilitating drive trough users spam.",,,,
comment_on_answer,1308623,390350,341152.0,Carl,0,"@DaltonBentley What is not geared? This site, this question, this post, what?",,,,
comment_on_answer,1308790,390350,319429.0,Dalton Bentley,0,"@Carl I think Rui intended to say he agreed that we must recreate the real Stack Exchange/Stack Overflow and that goals should include not operating the site(s) simply to achieve large numbers of users (""drive-through spam"" would result).",,,,
comment_on_answer,1308819,390350,341152.0,Carl,0,"@DaltonBentley Humm. As it turns out, negative opinions are less reliable than positive ones. Voting for something usually means some deliberation has occurred. Voting against something does not require weighing the issues. For example, I am in favor of climate change, which means that I have actually thought about it. Most people think ""CO2 is bad,"" because they have been told that, but how many people actually understand what climate is on a geologic and evolutionary time scale, or how atmospheric pressure has changed with time, or the geologic carbon cycle?",,,,
answer,391689,389811,531408.0,Mark Johnson,8,"As someone who has been working on programing and data analysis on computers since 1981, I am very concerned about allowing people to submit answers that are not a product of their own minds but a product of an artificial intelligence that has simply collected a series individual 'facts', made available by persons unknown, which leads to a conclusion which may (or may not) be plausible.
The same applies to an artificial intelligence (AI) tools checking whether artificial intelligence has created an answer.
That the moderators are not using these tools is, to me at least, obvious, based on their actions that I have observed in the last 6 months.
I myself have flagged/voted many answers that due the style of writing, lack of sources and often very weird constellations of 'facts' making it obvious to me who has the required background knowledge in the topic of the question.
The last 2 weeks the user Serg Z

2023-07-22: User spamming chatbot answers - Mathematics Meta Stack Exchange

on Law and History Stack Exchange, has flooded many existing questions with junk answers.
How should a later reader determine which answer is based on knowledge and facts and which are simply a collection of random facts pasted together by a AI and submitted by a user as if it was their answer?

Below is a email I sent to three friends today.

a Professor of Philosophy from Vancouver, Canada

who is sympathetic to the idea of a central source of knowledge


a US programmer since the mid 1960's for supply automation in the car industry and later debit bookings
the Italian author of a well known PC based Spatial software who I have worked with for many years

I have added this mainly for the benefit of the business leadership of Stack Exchange, Inc. so that can, hopefully, better understand from the viewpoint of a data analysis on computers of many decades that the AI policy should be to treat such answers as a form of plagiarism (and therefore be deleted), since the answer is not a product of the author that submitted the answer.
The ChatGPT experience was from December 2022, where it became clear that the system (at least then) was designed to give an answer at all costs not caring if the result was nonsense or not. This is copy and paste knowledge at its worst.

I was taught that one 'had to learn how to learn'.
One lesson was that one had to have enough background knowledge to determine if any found/returned result was plausible (part of the 'learning' process).
Next, check the sources from preferably multiple -independent- reliable sources.
Finally assume that any result might not be conclusive and that multiple possibilities may exist (often dependent on certain situations).
In 1981, long before the first MS-DOS for PC's were available here, the first lesson in the programming course was: A program will always be as stupid as the person that programmed it (you can't program a bookkeeping program if you know nothing about bookkeeping). Lesson #2: the main difference between a stupid program and a stupid person is that the stupid program is more capable in making more mistakes faster.

Tell this to some people today and you can see the question in their eyes: 'From what alternative universe (far, far, away) does this person come from?'.
This is what is meant with 'a critical lack of tech skills' in the article below.

In the report the tech giant [Google] also highlights what it calls ""a critical lack of tech skills in the UK"", which - if unaddressed - will ""remain a stubborn barrier to equitable nation-wide growth, especially as demand for AI and other tech expertise soars"".


2023-07-28: BBC News - Google: Don't trust what our chatbot Bard tells you

A few years ago, I saw a quote:

With the internet making information available to everyone will make them smarter

well, we got that one wrong didn't we?


As far as I am concerned, for the likes of ChatGPT and Bard, the first two lessons from 1981 still apply.

On History Stack Exchange forum there was a question about a ChatGPT result that the person couldn't make sense of:

2022-12-25: Was there a Moresnet Conference of 1867?

So I tried the ChatGPT system for the first (and only) time to see if I could figure out how ChatGPT came to the result that the OP of the question reported.
My conclusion was that ChatGPT was designed never to say 'I don't know' or 'insufficient results to come to a (sane) conclusion'.
It collected 3 facts that were true for a 3 month period in 1867:

1815-12: Dutch and Prussian representatives created Neutral Moresnet

since 1830 Belgium instead of the Netherlands
existed until 1914


1867-04/06 : International Monetary Conference of 1867 in Paris (Latin Monetary Union)
1867-03-23 / 1867-05-11 Luxembourg Crisis

Thus the 'Moresnet Conference of 1867' (with the participation of The Netherlands, Prussia and Luxembourg - who never belonged to the Latin Monetary Union - and Luxembourg that had nothing to do with Neutral Moresnet) was simply 'created' as a fact, with no supporting sources, hoping that nobody would notice that the answer is nonsense.
For the gullible, ChatGPT and Co. are a dangerous source of information.",,,,
comment_on_answer,1309646,391689,203057.0,Cerbrus,3,"There's a lot in this answer, but a lot of it is also not a comment on the strike. I think this answer is better suited to a question that discusses the ban on LLM content... While I agree with the answer, it does not seem to answer this question.",,,,
comment_on_answer,1309650,391689,531408.0,Mark Johnson,2,"@Cerbrus The simple non acceptance by the Stack Exchange, Inc. that AI generated answers is plagiarism seems to me to be a major, justified, cause of the strike. That the moderators don't use (as implied) the AI tools, with the reason why, is also stated.",,,,
comment_on_answer,1309653,391689,531408.0,Mark Johnson,2,"@Cerbrus As stated it was mainly for the benefit for Stack Exchange, Inc. to assist in understanding why the moderators and some users are reacting this way. Understanding the reason why, often helps in resolving a problem. That was my intension of adding what I actually wrote to others this morning.",,,,
comment_on_answer,1309651,391689,203057.0,Cerbrus,1,"Yes, in the first 3 paragraphs... But the rest of the answer? It kinda lacks focus. Again, I agree with your points, I just think this is not quite the place.",,,,
comment_on_answer,1309684,391689,359002.0,OldPadawan,1,"""For the gullible, ChatGPT and Co. are a dangerous source of information."" -> did you mean ""misinformation""? :)",,,,
comment_on_answer,1309692,391689,531408.0,Mark Johnson,1,"@OldPadawan Looking at International Monetary Conference of 1867, shows quickly that it took place in Paris and not in Moresnet as claimed. That is the danger in my mind, since it makes it more difficult to check if the result is plausible.",,,,
comment_on_answer,1309732,391689,268944.0,Mark,1,"@MarkJohnson, LLMs aren't deliberately designed to not say ""I don't know"".  Rather, the inability to say ""I don't know"" is an unavoidable consequence of how they work: LLMs provide the text that, based on the training data, is most likely to follow the input.  The only way to get an ""I don't know"" out of one is to provide it with a list of things that it doesn't know.",,,,
comment_on_answer,1309735,391689,531408.0,Mark Johnson,1,"@Mark More the reason that LLM (Logic Learning Machine) should not be the source for answers based on knowlage. If it cannot state either: 'Yes,an answer is possible ' or 'No, an reliable answer is not possible' then it is neither logical nor intelligent.",,,,
comment_on_answer,1309766,391689,169312.0,tripleee,1,"That's a weird backronym. Generally, LLM stands for Large Language Model.",,,,
comment_on_answer,1309767,391689,531408.0,Mark Johnson,1,@tripleee There are many usages of LLM - Wikipedia as an abbreviation. That is why it should be written out when first used.,,,,
comment_on_answer,1309771,391689,169312.0,tripleee,1,"If you are discussing ChatGPT in particular, I think it's fair to assume that you should be familiar with the central terminology, especially as this meaning of the abbreviation LLM has become almost a household word in recent months.",,,,
comment_on_answer,1309687,391689,1080545.0,Sarvesh Ravichandran Iyer,0,Thank you very much for your informative answer. It was a pleasure to read.,,,,
comment_on_answer,1309691,391689,531408.0,Mark Johnson,0,"@OldPadawan No, for them it is considered a source of information. When rephrased (What major conference took place in 1867?) correct results were returned. But adding 'Neutral Moresnet' to the question an incorrect result was returned. Those familiar with the events (or do cross checking as the OP did) recognise this. But some peaple don't, assuming (incorrectly) that only correct information is returned. The lack of sources makes it more difficult. ...",,,,
comment_on_answer,1310571,391689,63550.0,This_is_NOT_a_forum,0,"ChatGPT can be useful, just not for anything factual (or at least it must be thoroughly checked). For instance, to come up with input for a regular web search.",,,,
comment_on_answer,1310575,391689,531408.0,Mark Johnson,0,"@This_is_NOT_a_forum When thoroughly checked (with possible adaptions/corrections/additions) then it becomes a product of their own mind. When it is blindly copied and pasted and posted as if it is their own product, then it is plagiarism. The problem is that many of these 'authors' don't have the faintest idea (or worse care) if 'their' answer is factualy correct or a chapter of history from alternative-reality-1527 but submit it anyway to gain reputations. That is the problem in my mind.",,,,
answer,391967,389811,1210263.0,Joako,2,"If I visit the open letter website it states that the strike is finally over:

I want to know if this is an official statement or not.
Thanks beforehand.
",,,,
comment_on_answer,1310959,391967,342074.0,Timothy G.,5,You may want to read over the answers/comments on Moderation strike: Results of negotiations,,,,
comment_on_answer,1310983,391967,169312.0,tripleee,3,"To recap, it is ""official"" as far as the organizer of the open letter is concerned. The strike was not tightly coordinated or controlled, so there will be different groups of users with different criteria for when exactly to resume moderation activities. Some are probably waiting to see if the promises and concessions made my the company are in fact more than just words; and some will probably never return.",,,,
comment_on_answer,1310984,391967,169312.0,tripleee,2,See also What do you feel like is still missing to end the strike?,,,,
answer,390048,389811,620210.0,tell,-29,"It would make sense for a company promoting and selling new technology to buy up a company selling old technology and then mothball its old-technology operations.
Meanwhile it would make sense for a company promoting and selling old technology to get with it and maximise its selling price with the above in mind.
""Artificial intelligence"" is about solving issues - perhaps even issues you didn't know existed - by running computer programs. OpenAI is a leader in the field.
SE/SO is the world's leading site featuring expert questions and answers that are written by human intelligences. Go figure.
Edit: it seems from comments that Prosus, the company that already owns SO/SE, already knows a fair bit about AI, so perhaps SO/SE is not about to be sold. As user @leanne writes, it seems the writing is on the wall. Online expert question and answer provision based on human intelligence is about to get cut back drastically.
*Another edit: OK, downvoters, the decision is nothing to do with profit and AI-isation but derives merely from ignorance at the top of the company of what the company's unpaid volunteers know. Seriously how likely does that sound?
",,,,
comment_on_answer,1301806,390048,997587.0,starball,19,I don't get what you're trying to say here. Maybe some more clarity is needed.,,,,
comment_on_answer,1301807,390048,1135948.0,kaya3,13,"It's not really clear what you're saying here ‚îÄ are you claiming that SE, Inc. has been bought by an AI company who is now intentionally running into the ground? Or that it is pre-emptively running itself into the ground in order to make itself more appealing to be bought by an AI company? This doesn't really make sense, because if SE, Inc. will run itself into the ground then there's no need for an AI company to buy it in order to do that.",,,,
comment_on_answer,1301850,390048,178170.0,leanne,5,"@Levente and tell: checking out the SO blog entry, Is this the AI renaissance? (Ep. 564): 1) yeah, Prosus has known about AI and its workings for years. They also have their own AI team. They have purchased Udemy, CodeAcademy, and other learning sites. I posit that ""the writing's on the wall"": Prosus is going to be using these sites' data for its own search/learning system that they can possibly hugely monetize. Soon, no more ""volunteers"" needed...",,,,
comment_on_answer,1301810,390048,908360.0,Levente,4,Go figure what?,,,,
comment_on_answer,1301813,390048,620210.0,tell,2,"Moderators are saying they deal with a very large number of what they have concluded to be AI-generated answers. Instruct them not to be so hard on such answers and it's clear what the result will be, and in particular it must surely be clear to senior executives at this company, who one can assume are not stupid. The result will be that AI-generated answers build towards taking over. Who's that profitable for? This website does not exist for community. It exists for profit.",,,,
comment_on_answer,1301824,390048,620210.0,tell,2,"Ah, thanks for that info. I thought SO/SE was still privately owned. But still, I think I'm on the right lines and the same applies to the current owners, who AFAICS aren't big AI players.",,,,
comment_on_answer,1304357,390048,181776.0,willeM_ Van Onsem,2,"ChatGPT is definitely a step forward in AI technology, but unfortunately a lot of unskilled people think it has a powerful brain, it does not. Currently it is mainly an artist with words, an electrical parrot so to say. If it gives for example an answer to a question regarding law, it cites non-existing laws, if it is asked to solve programming challenges, it imports non-existing classes. It can copy a bit, just like people sometimes imitates people, with mixed results. Eventually tools improve, but currently the level is insufficient.",,,,
comment_on_answer,1301814,390048,620210.0,tell,1,"@kaya3 - It makes perfect sense. SE does seem to be running the human side of its world-leading EQ&A operation into the ground. I'm suggesting that that's a means, not an aim in itself.",,,,
comment_on_answer,1301818,390048,1135948.0,kaya3,1,"What is it a means to? It doesn't make the company more attractive to a buyer, even if the buyer does want SE to be destroyed. They won't pay to destroy it if it is already destroying itself for free.",,,,
comment_on_answer,1301820,390048,620210.0,tell,0,"I think you are missing my point. It's unlikely that the company is destroying itself - or to be more exact, destroying the human-intelligence EQ&A service it has built up, largely using volunteer labour - for free. Its owners and senior execs would be stupid if that were the case. Is it likely they're so stupid?",,,,
comment_on_answer,1301821,390048,908360.0,Levente,0,"So, I seem to have read somewhere that the tendencies of AI potential were not suddenly recognized only in November 2022, when ChatGPT got published. That early insights were available to some circles earlier than that. Tim Urban posted about exponential AI acceleration back in 2015. I wonder, when in summer 2021 Prosus decided to buy SO/SE, had they been entirely clueless about the role AI was going to play? Or did they make their decision in awareness of the potentials in AI development? What was / is Prosus' plan?",,,,
comment_on_answer,1301823,390048,908360.0,Levente,0,Why is this happening?,,,,
comment_on_answer,1301853,390048,908360.0,Levente,0,"The majority of education in the hand of one monopolistic provider. What could go wrong? We are so done, so, so, so done.",,,,
comment_on_answer,1301858,390048,178170.0,leanne,0,"@Levente: monopolistic and money-hungry! Plus, if international companies are, like US companies, beholden to their shareholders... who cares how it's done, as long as the shareholders are happy",,,,
comment_on_answer,1301865,390048,620210.0,tell,0,"Thanks, @leanne. So Prosus (owned by Naspers ) do know about AI then. Interesting that they own a big chunk of Tencent which owns Wechat.",,,,
comment_on_answer,1301867,390048,908360.0,Levente,0,"@leanne Until this moment, I was contemplating staying away from SE... from your comment onwards, I am contemplating staying away from the oncoming world. Sounds dramatic but, you know, I am in an invasive and oppressive environment right now where I see how strong appetite people in power have to stunt and throttle the development of others. They try to reduce people into human animals. A world that your insight depicts, combined with my insight here, let me tell you, brings Tesla's quote to mind: ""You may live to see man-made horrors beyond your comprehension."" I am authentically scared.",,,,
comment_on_answer,1302097,390048,153008.0,Cody Gray,0,"Can you clarify where/what is ""old technology"" here?",,,,
comment_on_answer,1302112,390048,908360.0,Levente,0,"Since you possibly can't see your vote breakdown, but might be interested in it, I relay that the votes on your post at the time of writing this comment, are: +3/-19.",,,,
comment_on_answer,1302683,390048,620210.0,tell,0,The old technology here is conscious thought by skilled craftsmen.,,,,
answer,389994,389811,178170.0,leanne,-92,"From a longtime SO/SE user: I do not support this strike.
A company owns this collection of sites. A corporation has the responsibility, and right, to make their own decisions about their properties' functions and appearance. They are not beholden to their volunteers regarding their decisions.
I have seen complaints about ""firing"" a moderator, the appearance of voting buttons on the sites, and now the disallowance of removal (except in very narrow circumstances) of perceived AI-related posts.
As with any company, I'm sure that Stack Exchange Inc's management has made decisions based on input and findings by their employees as to the best way to proceed.
Just because some volunteers don't like some decisions, and/or the way they were communicated, does not mean the company has to do what the volunteers want done. The company must do what they think is best for their bottom line, including what they think is best for their users.
I personally, and most people I know, have stopped using SO for any new questions because of the combative way we have been treated by some volunteers who believe they know exactly what's right and wrong in every case; who downvote and close questions even when they don't have experience with what's being asked. They're so professional and knowledgeable that they can somehow magically determine whether a question or answer is valid without any experience in the topic.
There are a bunch of companies out in the world, including the creators of ChatGPT, who are trying to find a way to determine whether something was created by AI or a human being. If all of those people can't even determine 100% if something was created by AI, then what extraordinary ability do some SE volunteers have to determine, without a doubt, that a post's information was provided by AI?
OMG: instead of volunteering, you should be getting paid the big bucks for this incredible skill!!!

Update:
After doing some research on Prosus and checking out the SO blog entry from April 2023, Is this the AI renaissance? (Ep. 564): I can say that

Prosus has known about AI and its workings for years.

They have their own AI team.

They have purchased Stack Exchange, Udemy, Codecademy, and other learning sites.


Based on this information, I posit that ""the writing's on the wall"": Prosus is going to be using these sites' data for its own search/learning system that they can possibly hugely monetize. Soon, no more ""volunteers"" needed...
And, if international corporations, like US corporations, are beholden to their shareholders... well, that's why they seem to not care about their volunteers.

Update to clarify my update:
For those who might not understand what I'm saying about shareholders - Prosus, owner of the SE/SO collection of sites, is a public company. ""Public"" means that a company, such as Prosus, provides stocks, aka, a portion of the company that can be purchased by the public or provided to their employees as compensation. The people who own these stocks are called ""stockholders"" or ""shareholders"".
Although these companies are not actually required by law to maximize profit for their shareholders, they often do exactly that - which is why I say ""beholden to their shareholders"".
What I'm saying with the earlier update is that Prosus can, and likely will, find the optimal way to increase their profits in order to satisfy their shareholders. That may include using the purchased assets, such as SE/SO data, to train AI to teach people to code and to answer their questions - which may or may not make the SE/SO (SO, particularly) sites OBE (no longer necessary).
This has nothing whatsoever to do with my non-support of this strike - the reasons for which are in the portion of my post prior to the updates. The updates are merely further information around why the company might not be interested in yielding to the strikers' demands.",,,,
comment_on_answer,1301456,389994,1135948.0,kaya3,59,"""They are not beholden to their volunteers regarding their decisions."" ‚îÄ And we are not beholden to them regarding the hosting of our communities. The whole Stack Exchange model cannot work if there is no agreement that it's in everyone's interests for them to continue hosting us and for us to continue maintaining the value of their product by curating and moderating it. ""The company must do what they think is best for their bottom line, including what they think is best for their users."" ‚îÄ sure, and if they want to know what's best for us they can listen to us about it.",,,,
comment_on_answer,1301459,389994,164403.0,Fr&#233;d&#233;ric Hamidi,50,"Hi @leanne. I'm Fred. I've been answering questions on SO from late 2010 to late 2016, and I also have been ""curating"" the site during this time period. I am aware the private SE company can do whatever they want with their assets, or, as you say, ""properties"". Problem is, volunteer work is not an asset or a ""property"". It is not paid for. It is not taxed. It is something one does out of their own time and (sometimes) money. The unique situation the SE company finds itself in is that it depends on distributed, volunteer work, and they cannot easily replace that.",,,,
comment_on_answer,1301458,389994,1135948.0,kaya3,31,"The way we are able to tell with greater accuracy than ChatGPT detection tools whether a post is written by ChatGPT, is not because we have discovered some magical solution to the problem that OpenAI are trying to solve, but because the problem we are solving is a different and much easier one. OpenAI want to do it using just the text of the post, whereas we have lots of other input data available, including the original question, the user's post history, and other context; and OpenAI want to minimise both false positives and false negatives, while we mainly want to minimise false positives.",,,,
comment_on_answer,1301543,389994,171199.0,Íì¢PArcheon,30,"Lastly, since you mentioned a ""fired volunteer"" I suggest that you may want to actually read about that before empty making jokes that only make YOU look quite bad. The ""fired  volunteer"" as you call it was subject to a slandering campaign on the web that the company started, not just removed from their position. You may thing that they were ""fired"" with a reason? Again fine. But it is NOT fine to go and make that person you scapegoat puppet in the hope to gain some free advertisement like the company did. So, please. DON'T JOKE ABOUT THAT.",,,,
comment_on_answer,1301542,389994,171199.0,Íì¢PArcheon,27,"""OMG: instead of volunteering, you should be getting paid the big bucks for this incredible skill!!!"" - this line makes your purpose quite clear. You see the volunteers as the ones who did you wrong, and now you are felling a twisted pleasure in seeing them done wrong. I think you may find a far more productive use of your time in reflecting about why you ""were done wrong"". And I will go even as far as to say that is completely possible that you were indeed punished without reason. But in that case you should just ask the company to review you case instead of being mad at the world.",,,,
comment_on_answer,1301678,389994,282022.0,mason,20,"If your disagreement with the strike is about whether a human can detect AI generated content or not, then you should have made your answer about that. As written now, it's some rant about how Stack Overflow Inc is a company and can therefore legally do whatever it wants - and that's really relevant to the discussion. Practically nobody disagree with that - it's just that it misses the point and is completely irrelevant. That's why you have so many downvotes here.",,,,
comment_on_answer,1302073,389994,707783.0,Someone,16,"Why do you keep highlighting the word volunteer in an apparently condescending way? Just because they are unpaid does not devalue their contributions. Remove the volunteers from the network and see how much ""content"" remains.",,,,
comment_on_answer,1301541,389994,171199.0,Íì¢PArcheon,11,"This post looks like it is just trying to pick up a fight. You don't agree with the strike? Fine, no one here is forcing you - everyone has is views and those should be respected. You, on the other side aren't. Based on your reaction, I assume you are just venting out in frustration. It is clear what your purpose is here:"" I personally, and most people I know, have stopped using SO for any new questions because of the combative way we have been treated by some volunteers"", so now you are here to talk trash about EVERY volunteer.",,,,
comment_on_answer,1301491,389994,1135948.0,kaya3,10,"Detecting ChatGPT-generated text can be improved by leveraging human intuition and contextual understanding. Humans possess a vast array of knowledge and experiences that enable them to spot inconsistencies, logical fallacies, and contextual discrepancies in generated text. They can identify nuances, sarcasm, and understand context-specific cues, allowing them to differentiate between genuine human responses and AI-generated ones. By actively engaging with the content, asking probing questions, and critically analyzing the text, humans can bring a depth of understanding that surpasses AIs.",,,,
comment_on_answer,1301498,389994,169312.0,tripleee,10,The parallel with the book publisher would be an author who turns in a new 300-page manuscript every week on topics ranging from tropical fish to child rearing to nuclear physics to spiritual growth to agricultural sustainability to the history of the Incas.,,,,
comment_on_answer,1301891,389994,1135948.0,kaya3,10,"Your position would be clearer if you didn't mix it in with irrelevant grievances about other poorly-received changes unrelated to the strike, your own questions being closed, which institutional investors happen to own shares, and so on. It's very hard to discern any logical relation between any of the points you are trying to make, and you seem to be contradicting yourself in multiple ways. So, despite the volume of text you have written, I do not understand what ""not support"" really means if you don't think we should stop striking, and you don't think SE should refuse what we ask.",,,,
comment_on_answer,1302027,389994,1135948.0,kaya3,10,"OK, so you are wrong, and that's fine.",,,,
comment_on_answer,1301457,389994,282022.0,mason,9,Do you really in your heart believe that Stack Overflow Inc staff always make the correct decisions? That they should take no input from the people that made this network of sites a success in the first place? Software developers who can write and maintain the apps this site runs on are readily found. A legion of people willing to put forth their own unpaid time to actually make the site useful are not readily found.,,,,
comment_on_answer,1301608,389994,171199.0,Íì¢PArcheon,9,"they have the right to ""fire"" people, revoke moderation rights (since those weren't paid employees in the first place), suspend or ban users. But they don't have any right to go around and tell the press that ""there is this moderator that refuses to acknowledge that everyone should be allowed to choose how they identify and was planning to misrepresent users identities on purpose with the sole intention of hurting people, so we removed her and advise no one should hire her ever. BTW here is her mail if you want to send in well deserved hate letters"". Yet that is what was done back then.",,,,
comment_on_answer,1301659,389994,282022.0,mason,7,"@leanne I haven't seen you provided any reasoning for why you disagree with the strike. The only reasoning you seem to have provided is that Stack Overflow Inc is a company and can legally do what it wants - but now that we agree that's true, that still doesn't provide any reasoning for why moderators shouldn't strike. What about their reasoning for striking do you disagree with?",,,,
comment_on_answer,1301677,389994,282022.0,mason,7,"You say you've been following that ChatGPT saga, but you either missed or are ignoring crucial parts of this strike. The strike isn't just about ChatGPT - it's about the company having hidden rules, and not coordinating properly with the volunteers. No, they aren't legally required to coordinate with them - but it'd be wise to do so since they're a big part of why these sites are successful in the first place. Several moderators have offered to do blind tests to validate their AI detection abilities - but the company refuses to take them up on the offer.",,,,
comment_on_answer,1302718,389994,181776.0,willeM_ Van Onsem,5,"The company indeed owns the collection of sites, the moderators on the other hand own their (free) time, and thus can decide to strike when they want to. This also is not only because of a new AI policy, but is something that is smoldering for a very long time.",,,,
comment_on_answer,1301548,389994,260073.0,NoDataDumpNoContribution,4,"This answer is a valid contribution. I agree to many points in it except to the first and last one. I support the strike and I don't want to mock moderators. If the company has rights, then the mods have rights too. Of course they can strike at any time. And without their work surely SO as we know it wouldn't exist. We all owe them a lot of gratitude for that. Of course we too can choose freely what to support and what not but in this case I support the strike because the arguments for it convince me. If the company wants a different policy it should look for mods to enforce them elsewhere.",,,,
comment_on_answer,1301893,389994,1135948.0,kaya3,3,"You've said that SE either should or will do what is in their interests, and/or their shareholders' interests, and/or their users' interests. Is there any reason to believe they won't do that? The purpose of the strike is to hopefully change what actions SE will take to serve those interests. Is there a particular outcome you want to achieve, which would be achieved by the strike ending without the strikers' demands being met?",,,,
comment_on_answer,1303776,389994,285552.0,Russell McMahon,3,@leanne  That the company is legally able to do as it wishes with its property is correct. What you said about replacing humans with AI is not correct - and is unlikely to be so for quite some years yet.  | I'm an SE EE moderator - because I care for people and seek to help newcomers get things right and understand the system. I've also seen the damage uncontrolled newcomers and AI answers can do. See my answer above. The use of AI for question improvement may work. I guarantee that it's use for question answering will be (and is) a disaster.,,,,
comment_on_answer,1301613,389994,171199.0,Íì¢PArcheon,2,"I am open to further elaborate in chat. It is the tone and the chain of arguments you make that hit me wrong. Your premise is that ""(the company) are not beholden to their volunteers regarding their decisions""  - that I can agree. Soon after you first mention ""complain about firing a mod"" - that is already something that involved something they were NOT allowed to do - slandering, and it ended up in actual legal litigation. The final part also I can accept as your view (even if I disagree on some central point) but it is the tone that seem wrong as if you were bashing the volunteers as a whole",,,,
comment_on_answer,1301614,389994,282022.0,mason,2,I know you didn't explicitly says that they always make correct decisions. But your post seems predicated on the idea that the company shouldn't accept feedback from their users. That the users should have no say. And that's just silly. It has long been the right of users of a service to boycott that service in order to influence the service provider to change their practices. That's essentially what the moderators are doing here. And it's absurd for you to think that they shouldn't strike (boycott) when the need arises.,,,,
comment_on_answer,1308619,389994,312165.0,Rui F Ribeiro,2,"@leanne The gamification is not perfect per se, however people who has high points did not get them overnight and had to start somewhere as everyone else.Posting quality questions take time. Low quality, unmoderated content would not be attractive to visit, alas the feed is boring as it is, and that is an unappreciated and ungrateful free work I also gave up on doing. Answering also takes time. I am not also very interested on interacting with drive through users. SE and drive through users seems to think the only ones accountable to standard and rules are high rep users who play by the rules.",,,,
comment_on_answer,1301606,389994,178170.0,leanne,1,"@SPArcheon: * Not trying to pick a fight; simply stating an alternative view. * No more or less ""venting"" than the OP. * Never said ""EVERY"" volunteer; as a matter of fact, several times said some. * Not ""mad at the world""; again, simply stating an alternative view. * NOT A JOKE! Yes, I have read the multiple posts and articles about the fired moderator. The point is only that companies have a right to fire people, no legal requirement to explain why, and that their management and employees (such as legal, usually) will make that decision and carry it out.",,,,
comment_on_answer,1301607,389994,178170.0,leanne,1,"@tripleee: the particular publisher I was considering was one that accepts short stories to be placed in an anthology. There are many other examples in the media about companies, colleges, even TurnItIn trying to find ways to determine items written by AI. If none of these places has been able to figure out how to tell with high accuracy, then I stand by my comment that the volunteers here with this skill should be looking to share it.",,,,
comment_on_answer,1301609,389994,178170.0,leanne,1,"@mason: did I say that I ""believe that Stack Overflow Inc staff always make the correct decisions?"" No, I did not. I said that ""A corporation has the responsibility, and right, to make their own decisions..."" Those are two completely different things.",,,,
comment_on_answer,1301611,389994,178170.0,leanne,1,"@SPArcheon: I bolded and italicized all the salient points. I mentioned the ""wrongs"" done to me and others because SE/SO has commented that their user count is falling. I believe these ""wrongs"" are a big reason. And, note that part is not bolded or italicized, so why do you think it's my main issue? The rest of the points are simply legal fact, or in the case of AI, publicly discussed issues in the general media. SO/SE is just another company having issues with AI recognition.",,,,
comment_on_answer,1301615,389994,282022.0,mason,1,"I don't think anyone would say that Stack Overflow Inc must legally abide by what the users wants. But you seem to think that the users expressing their opinions in the form of a strike/boycott shouldn't be supported. You offer no support for that view, other than talking about how the company has a responsibility to make good decisions in order to keep making money, which again none of us disagreed with. What we disagree with is that they aren't making good decisions and they aren't properly collaborating with their users. Theyre chasing short term profits instead of long term platform health",,,,
comment_on_answer,1301616,389994,178170.0,leanne,1,"@mason: again, I did not ""explicitly"" say any of those things. I didn't say ""the company shouldn't accept feedback"". A company should accept feedback. My point is that what the company does with that feedback is its own choice. It is not required to comply with what its users/volunteers want. And, yes, the moderators have every right to strike. I simply do not agree with this strike.",,,,
comment_on_answer,1301658,389994,1135948.0,kaya3,1,"@KarlKnechtel Yes, ChatGPT has been trained on a wide range of text data, including instances of sarcasm. It can often recognize sarcastic statements by analyzing linguistic cues and contextual information within a conversation. However, understanding sarcasm can be challenging even for humans, and there may be cases where ChatGPT might not fully grasp the intended sarcastic tone or meaning, as sarcasm can be subjective and complex.",,,,
comment_on_answer,1301671,389994,178170.0,leanne,1,"@mason: I have been following the ChatGPT saga, among other AI-related issues. From all that I have seen/read/heard, there is no way that anything - not humans, not tools, not the AI itself - can tell with high accuracy, whether content was AI-generated or not. Some of the striking volunteers have claimed a near 100% accuracy rate. The company has said that they have evidence that many items flagged were not AI-generated. This puts the company in an untenable position: lose users from (possibly) badly flagged posts, or appease their volunteers by letting them flag unrestrainedly.",,,,
comment_on_answer,1301675,389994,178170.0,leanne,1,"@mason: As to the private rules they had to agree to: if those rules went public, then (possibly) users would be able to override the very things the company wants to use to determine if a post is AI-generated. Now, I don't know what the private items are, so that's a guess on my part. But, I repeat: if these volunteers are truly able to detect AI-generated content with near 100% accuracy, then they need to quit wasting time with a company that doesn't believe them and go get jobs with companies that are desperate to root out AI-generated content.",,,,
comment_on_answer,1301681,389994,178170.0,leanne,1,"@mason: my post discusses that in the last two points. As for the downvotes, I can't control anyone else's opinions, perception, or translation of the meaning in my posts. Getting downvotes when one expresses disagreement or reasoning that others disagree with has been the normal reality here at SO/SE for a number of years. And, though you likely can't see it, my post has gotten some upvotes as well.",,,,
comment_on_answer,1301881,389994,1135948.0,kaya3,1,"This answer is all over the place. Could you clarify exactly what you mean by ""do not support the strike""? Do you mean you think we shouldn't stop donating our free time to improve SE's product? Or do you mean you think SE shouldn't do what we're asking them to do?",,,,
comment_on_answer,1301886,389994,1135948.0,kaya3,1,"Well, if you don't think we should stop striking and you don't think SE should refuse to do what we're asking, then what does it mean to not support the strike? It sounds more like you are just indifferent to the strike.",,,,
comment_on_answer,1302017,389994,178170.0,leanne,1,"It comes down to this, @kaya3: a small subset of ""volunteers"" have been closing ""thousands"" of posts as AI-generated when there is no one in the world that has been able to accurately identify AI-generated text. The company has identified that a number of these closings have been incorrect (in alignment with my earlier comment). These volunteers (unreasonably) expect the company to allow them to continue (insensitively) harming users. My ""close vote"" experience shows an example of unreasonable and insensitive behavior by volunteers. This strike is just a further example of that behavior.",,,,
comment_on_answer,1302018,389994,178170.0,leanne,1,"Further, @kaya3: the company does not have to communicate every internal decision with its volunteers. It also does not have to expose all of its rules to the public. The ""striking"" volunteers seem to have conflated themselves with internal employees and management. This isn't about the ""love of SE/SO""; this is about trying to force a company to do what a small subset of people want: the ability to close posts and suspend users irregardless of what the company and the larger community sees as harmful.",,,,
comment_on_answer,1302156,389994,178170.0,leanne,1,"@Lewis: no condescension intended. Simply separation from the company, employees, or users. Nowhere, in any of my posts anywhere do I suggest that ""[j]ust because they are unpaid"", volunteers and their contributions are devalued by me.""",,,,
comment_on_answer,1304320,389994,253751.0,Stack Exchange Broke The Law,1,"To leanne I would like to point out: tough [censored]. It doesn't matter whether you support a strike or not. That decision is made by the people striking. If working doesn't feel valuable to a volunteer, they'll stop volunteering, and you cannot force them to volunteer, because that is called slavery. If you want people to do work for you, you either pay them, or you make it worth their while some other way, like the warm fuzzy feeling of doing good in the world.",,,,
comment_on_answer,1304359,389994,181776.0,willeM_ Van Onsem,1,"@RussellMcMahon: very likely, eventually AI will outsmart people, but the current level (like ChatGPT) does not and is way off. That is basically because how these tools are made: as electrical parrots that imitate humans, and for example refer to sources, classes, laws. But the difference is, these do not exist. Indeed, it refers to them because somehow it is trained that there is a country with a certain law related to the question, whereas for the exact question, the ""real"" country has no such law.",,,,
comment_on_answer,1305230,389994,1360325.0,HippoMan,1,"What seems to be happening here is that SE moderators in general believe that they can do work of sufficient quality without the help of LLM software, while the SE management disagrees. This is just another instance of what will inevitably occur as more and more so-called ""AI"" and ""robotics"" entities are used to replace human workers ... irrespective of whether the workers are paid or are volunteering. Sadly, over time, human workers and human volunteers are going to lose this war, as an increasing number of people will find themselves out of work due to being replaced by machines.",,,,
comment_on_answer,1307912,389994,312165.0,Rui F Ribeiro,1,"In the years have been active here, typically the most vocal users complaining about moderators ""abuse"", were the ones not willing to put any effort investing into the reputation gamification and good quality questions both on technical and English content, while still demanding good quality answers, often abusing the system with drive by users.",,,,
comment_on_answer,1308247,389994,178170.0,leanne,1,"@KevinB, the example is all about rudeness. Downvotes without explanation: not rude? Almost immediate closure for an invalid reason: not rude? All moves against a first time user: within standards for the site? My meta question about reason for closure and how to re-open getting a multitude of downvotes and no help: not rude? C'mon Kevin: really?",,,,
comment_on_answer,1308259,389994,200898.0,Kevin B,1,"Sure, however, no one here just gets to claim they‚Äôre the expert, it‚Äôs earned. You presented your case, and people disagreed. That‚Äôs the system working as intended.",,,,
comment_on_answer,1301485,389994,178170.0,leanne,0,"Again, @kaya3, I'm not talking about the tools. The strikers have made it very clear that they weren't using tools. And, regardless of ""false positives and false negatives"", there are a multitude of sites out there seeking to solve this problem. Book publishers are having the same problem, for example. They just want to know that a submitted book was written by a human, not an AI. They also have data such as the history of the contributor - and they still cannot tell with any high accuracy what is AI and what is human.",,,,
comment_on_answer,1301556,389994,173477.0,Karl Knechtel,0,"@kaya3 while your comment is generally accurate, I have seen demonstrations that ChatGPT has a reasonably good conceptual model of sarcasm, and can generate impressive sarcastic prose if you explicitly ask it to be sarcastic.",,,,
comment_on_answer,1301610,389994,171199.0,Íì¢PArcheon,0,"Again, you may have your reason to be angry for some wrongs that were done to you in the past by some mods, I don't have any difficult to believe that. But your post feels like those wrongs are the sole reasons you refuse to recognize while other mods are now protesting about other unrelated things.",,,,
comment_on_answer,1301883,389994,178170.0,leanne,0,"@kaya3: I have explained all my points in the comment thread above, if you care to read it. And, no, I'm not saying that you all should stop donating your time. I also am not saying that ""SE shouldn't do what [you're] asking them to do"". I am saying, perhaps, that what you're asking them to do (in terms of AI-content flagging) is unreasonable. Or that if it isn't, then the strikers should leave. (Perhaps go to that other site - or take your AI-detecting skills to companies who respect them.) My update notes that the point may be moot, anyway. Strike on, though, if it's what you believe in.",,,,
comment_on_answer,1302047,389994,63550.0,This_is_NOT_a_forum,0,Related: The meta effect,,,,
comment_on_answer,1304565,389994,178170.0,leanne,0,"@RussellMcMahon:  I refer to Overflow Labs where Prosus is already using AI to locate questions in existing text and suggest titles for new questions. Since Prosus owns the likes of Udemy and Codecademy, they can get new questions at any time. With the AI's help, they can cut the number of people needed to deal with low-quality questions dramatically. Yet, they can still grow the SO database of programming-related questions effectively and without human judgement (read ""bullying"") that so often happens in long-standing forums. AI is here...",,,,
comment_on_answer,1304998,389994,285552.0,Russell McMahon,0,"@leanne Yes, I largely agree with your comments on question improvement. I covered this reasonably well (I hope :-) ) in my answer",,,,
comment_on_answer,1307826,389994,612423.0,OverLordGoldDragon,0,"As someone who largely agrees with your sentiment on ""volunteers toxic"", I find the answer absurd. StackExchange = community. It's nothing without it. I also don't fully support the strike (if including Prompt Engineering SE), but my reasoning is very different.",,,,
comment_on_answer,1308241,389994,178170.0,leanne,0,"@RuiFRibeiro: I have never gotten into the reputation gamification because of the moderator abuse. For example, one of my early questions, regarding Visual Studio 2012, was closed as a duplicate of a question for a much older, inapplicable, version of VS. I see new developers referred to SO for help, only to find their limited tech vocabulary gets them slammed with downvotes and questions closed without explanation. If I defend valid questions (example in my answer), I get slammed, when even the moderators don't agree on a reason for close and/or don't have topic knowledge. Why invest?",,,,
comment_on_answer,1308242,389994,200898.0,Kevin B,0,@leanne there were no moderators involved in the handling of the referenced question.,,,,
comment_on_answer,1308243,389994,178170.0,leanne,0,"@KevinB: then other ""volunteers"" - regardless, the point is the same. (That's why I generally put ""volunteers"" in quotes: because there are many titles.) The issue, though, is the same: SO has become an unfriendly environment unless you can ask just the right questions in just the right way to avoid a tidal wave of downvotes and/or closure without explanation - even if you've never asked a question before.",,,,
comment_on_answer,1308244,389994,200898.0,Kevin B,0,"SO has always been a site with standards, that isn't something new that occurred. It's what attracted experts to come here rather than continuing wherever they were prior to SO. Unfortunately, as the site grew standards stopped being enforced as well resulting in more negativity as we lost the ability to curate the site the way it needs to be.",,,,
comment_on_answer,1308245,389994,178170.0,leanne,0,"@KevinB: I'm not talking about standards. I'm talking about basic kindness and concern for new, or new to a topic, users. Questions can be corrected to standards - if explanation is given and closure is held off to give time. The example I gave had not a single explanation for any of the downvotes, and the original closure reason wasn't even correct. You, yourself, were involved in the discussion, and still the problem wasn't fixed. The question is still closed, and the (first time) user is probably long gone at this point. Standards for a new user were not followed.",,,,
comment_on_answer,1308246,389994,200898.0,Kevin B,0,"@leanne if you're talking about basic kindness, why do all of your references not show any signs of rude behavior or actions that are against the standards of the site?",,,,
comment_on_answer,1308248,389994,200898.0,Kevin B,0,"Those are design problems with the site that we've been pushing for solving for literally a decade. This isn't a community problem, the site literally tells us to downvote not useful content and not to comment on downvotes.",,,,
comment_on_answer,1308249,389994,200898.0,Kevin B,0,"I 100% agree that the site does an awful job of onboarding users and displaying information to users related to how their question is being received. That's been a problem for as long as this site has existed. They've made multiple attempts to solve it, but it seems as if they gave up on the QA side of things ~ 8 years ago.",,,,
comment_on_answer,1308250,389994,178170.0,leanne,0,"No, @KevinB; those are ""volunteer"" problems. I visited your ""close voters"" chat and saw that all the close voters were together having a visit. So, ""smokescreen"", or like tools, pop up messages into the room, whereupon somebody decides to close the question, and others run right over to close. There was even one discussion about whether a user was ""worth keeping"" in order to make a close decision. That's plain wrong.",,,,
comment_on_answer,1308251,389994,200898.0,Kevin B,0,"have you even looked at the posts that smokedetector presents? it's a spam tool. it finds spam. literal spam. now you're just making claims about things you didn't even take the time to investigate. This tool exists, again, because the company wouldn't do it themselves.",,,,
comment_on_answer,1308252,389994,178170.0,leanne,0,@KevinB: or like tools,,,,
comment_on_answer,1308253,389994,200898.0,Kevin B,0,"The only thing the automated tools that exist in that room do are 1: find spam, 2: find rude content. that's it. I would expect those to be things you'd appreciate existing, given your concerns on rudeness. Actual rudeness, not ""Someone on the internet didn't like what i created, it's not fair""",,,,
comment_on_answer,1308255,389994,178170.0,leanne,0,"@KevinB: again, the point is that people, like yourself, make the decision to close. People give the reason for closure. People give the downvotes. People decided to close the example question without understanding the topic in the question, then refused to reopen it, even though a person with knowledge of the topic (myself) demonstrated how the question was valid and relevant - unless because it didn't specifically involve code, it was off-topic, upon which people could not agree.",,,,
comment_on_answer,1308256,389994,200898.0,Kevin B,0,All you need is a consensus that agrees with you. you didn't have one. One person saying everyone else is wrong is unlikely to be correct.,,,,
comment_on_answer,1308258,389994,178170.0,leanne,0,"@KevinB: one person with knowledge of the topic, with a consensus of people who had no knowledge of the topic, and refused to hear the relevant point. Typical SO ""volunteers"". Majority doesn't mean correct: example, incorrect SO answers upvoted hundreds of times. Listening and understanding would be ""correct"".",,,,
question,389834,,936316.0,Philippe,-589,2023-06-05 18:25:35,"Update: GPT on the platform: Data, actions, and outcomes

As you may be aware, a number of moderators (on Stack Overflow/across the network) have decided to stop engaging in several activities that they had taken on, including moderating content - in fact, almost all moderation tasks. The primary reason for this action is dissatisfaction with our position on detection tools regarding AI-generated content, and discontent with how that was rolled out.
We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions. People with original questions and answers were summarily suspended from participating on the platform. We stand by our decision to require that moderators stop using that tool. We will note that it appears to be very rare, however, for mods to use ONLY the ChatGPT detection tool, and frequently their own analyses were in use as well. We will continue to look for other, more reasonable tools and are committed to rapid testing of those tools and any suggested heuristic indicators.
The moderators who are engaged in this action served this community collectively for many years on the platform. Personally, I consider a number of them friends, and anytime friendship is tested like this, it‚Äôs difficult. I would like to say to them clearly that I hope they know how much I, and the whole staff and community, appreciate their collective decades of service to this community, and I hope that we are able to come to a path forward. I regret that actions have progressed to this point. The Community Management team is evaluating the current situation and we‚Äôre working hard to stabilize things in the short term. We‚Äôll be working collaboratively with the community on the long-term solution.
I‚Äôll be honest, the next few days and weeks might be a bit bumpy. Both sides share a deep and unchanged commitment to quality on this platform. Additionally, it‚Äôs important that we guarantee that anyone who has meaningful contributions to make has the opportunity to do so.  As we have updates, I and the team will be sharing them here.
",,,
comment_on_question,1300478,389834,684990.0,Nick is tired,258,2023-06-05 18:31:13,"Reminder that Philippe is trying to be civil here... while I am one of those on strike and don't intend on doing any curating. People should still be nice, even if critical.",0,0,1
comment_on_question,1300479,389834,572.0,Thomas Owens,5,2023-06-05 18:31:20,"Are you going to be posting updates as answers? I'd prefer that, I think. It's not clear what you mean by ""sharing them here"", as it pertains to updates. But answers would be better than edits.",,,
comment_on_question,1300481,389834,,user152859,124,2023-06-05 18:34:21,"Nice words, but we also got nice words last time the ""friendship"" was tested, and this brought us, well, here. Point is, words are not enough. At this point I also simply don't believe what management says, but that's already my own problem to solve.",,,
comment_on_question,1300482,389834,171199.0,Íì¢PArcheon,75,2023-06-05 18:35:09,"So, forgive me for being blunt but does the company any actual new insight to post other than the same generic and without evidence note about the tests (reminder: users already asked for supporting data, it is kinda useless repeating that without any number or insight on how those data was achieved) and a ""we still love you"" that comes out as a tad patronizing?",,,
comment_on_question,1300483,389834,332043.0,Zoe - Save the data dump,301,2023-06-05 18:35:10,"""We ran an analysis and the ChatGPT detection tools have an alarmingly highly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions"" - I am deeply disappointed that you've opted to ignore our many comments both before and after the AI policy going live stating that we do NOT blindly use GPT tools for suspensions. You've been involved in several of these discussions as well.",,,
comment_on_question,1300485,389834,357051.0,Israel should no longer exist,117,2023-06-05 18:36:46,"Honestly, you are just making everything worse with this post. You still refuse to listen to us, and continue to spread the same lie about how moderation on AI content was done.",,,
comment_on_question,1300486,389834,1333002.0,MissSkooter stands w Palestine,89,2023-06-05 18:36:53,"Nothing here even attempts to address the issue. The first half is a repeat of what was said before, except they added very rare so at least there's that. The second half is either sincere or emotional manipulation. As someone who doesn't really know Philippe, I'll leave that to someone else to decide",,,
comment_on_question,1300487,389834,278659.0,Rand al&#39;Thor,20,2023-06-05 18:37:34,"Your last paragraph seems to indicate a positive and hopeful direction, in particular ""Both sides share a deep and unchanged commitment to quality on this platform"". I wish a little more of this mindset had been displayed earlier on, before pushing a new policy onto us without discussion.",,,
comment_on_question,1300488,389834,357051.0,Israel should no longer exist,2,2023-06-05 18:38:00,"If your goal is to make some sound, and tell us you're trying to listen, and not ignore us, just give us a heads up that you will look into the issue. Don't continue on the same path.",,,
comment_on_question,1300489,389834,210998.0,Stephen Ostermiller,5,2023-06-05 18:38:01,"@ZoestandswithUkraine the post says ""We will note that it appears to be very rare, however, for mods to use ONLY the ChatGPT detection tool"", so not totally ignored.  Just not reflected in policy.",,,
comment_on_question,1300492,389834,332043.0,Zoe - Save the data dump,47,2023-06-05 18:39:31,@StephenOstermilleronStrike That's not what Philippe said to the media,,,
comment_on_question,1300493,389834,269301.0,Mast,8,2023-06-05 18:40:15,"@Andreasdetestscensorship No no, the second paragraph must stay at least partially. ""We will note that it appears to be very rare, however, for mods to use ONLY the ChatGPT detection tool, and frequently their own analyses were in use as well."" is as close to an apology as we'll get at the moment.",,,
comment_on_question,1300496,389834,357051.0,Israel should no longer exist,1,2023-06-05 18:43:42,"@Mast Well, it's nice that they're moving in our direction (if they really are (not sure if I trust it)), but if you omit that part, the post remains silent on the issue at hand, and is simply turned into an attempt at communicating with us, that they acknowledge what's happening, and they're working on it. It's better than nothing. I do prefer hearing from them, rather than being ignored. Being ignored is a big insult.",,,
comment_on_question,1300497,389834,171199.0,Íì¢PArcheon,97,2023-06-05 18:44:02,"Also, after at least FOUR post that asked you to avoid namecalling mods (the ones willing to spend their time for you for free) as sheep that blindly follow the outcome of tools to decide on suspensions instead of using their brain you continue with that same claim, to the point of even once again involving a media/news site too (didn't the company repent about misrepresenting Monica on a news site in the past)? Please do share your proofs or stop this now",,,
comment_on_question,1300502,389834,997587.0,starball,6,2023-06-05 18:48:28,"Who is the ""I"" in this post? Is it Prashanth or you (Phillipe)?",,,
comment_on_question,1300508,389834,357051.0,Israel should no longer exist,72,2023-06-05 18:51:28,"""Personally, I consider a number of them friends, and anytime friendship is tested like this, it‚Äôs difficult."": Reading this from outside of the friend sphere, it seems like you conflate the strike with malice, and take it as a hostile action from us.",,,
comment_on_question,1300513,389834,357051.0,Israel should no longer exist,21,2023-06-05 18:58:39,"How come this post gets to be featured, but not the post about the strike from our side?",,,
comment_on_question,1300514,389834,260073.0,NoDataDumpNoContribution,11,2023-06-05 19:00:29,"""high rate of false positives, which is correlated to a dramatic upswing in suspensions of users"" Just as a general remark (I write that very often): correlation does not imply causation. The striking moderators probably argue that the high suspension of users is not causing false positives. And they may well have a point. The company should be more careful there and provide much more evidence to gain users trust. Because if this ends in a competition of trust without any data on the table I'm dead sure of who will win in the end.",,,
comment_on_question,1300515,389834,260073.0,NoDataDumpNoContribution,2,2023-06-05 19:01:35,"@Andreasdetestscensorship ""How come this post gets to be featured, but not the post about the strike from our side?"" Probably something that starts with ""Life is"" and ends on ""unfair."". And I agree, it's unfair. It looks as if the company this time is committed to go through. It will be interested to see what the other 90% of the moderators are doing. They may be forced to take a side.",,,
comment_on_question,1300528,389834,496262.0,ilkkachu,58,2023-06-05 19:39:00,"""I would like to say to them clearly that I hope they know how much I, and the whole staff and community, appreciate their collective decades of service to this community"" -- oh please. Why does everyone have such a need to remind verbally of their love and appreciation exactly after they've done something that shows just the opposite?",,,
comment_on_question,1300530,389834,686649.0,Esther,18,2023-06-05 19:44:48,"""high rate of false positives, which is correlated to a dramatic upswing in suspensions of users."" I would argue that the ""dramatic upswing"" is caused by more people posting AI-generated answers, and that even with no false positives there would still be a substantial increase in suspensions for AI-generated answers.",,,
comment_on_question,1300560,389834,356669.0,M--,5,2023-06-05 20:48:29,"I appreciate the response; even if it is not what we are ultimately looking to get out of this, it is much better than the public statements made regarding the strike. I downvoted this question mainly because of the second paragraph, as we are still waiting to see evidence of those analysis. I want to reiterate that these civil interactions and acknowledgments can become the seed to the trust that can grow back. I'd humbly suggest: refrain from calling strikers ""a small percentage"", stop removing featured from questions, keep the communication lines open, and don't damage the trust further.",,,
comment_on_question,1300565,389834,384014.0,vbnet3d,13,2023-06-05 20:54:54,"Philippe - downvotes are not personal, and I'm sorry corporate is making you the face of this. But we as the community have seen way too much heavy-handed secrecy-laden dictation from the top instead of actually (you know, according to SO's long-standing policies and practices) discussing things with the community in an open forum. Until that changes back to what it should be, the community can't support this",,,
comment_on_question,1300575,389834,260073.0,NoDataDumpNoContribution,3,2023-06-05 21:18:32,"AI is a tough nut and SO seems to suffer traffic-wise, but I feel a bit as if the strike now is also a result of not enough discussions half a year before. Many questions like: how to handle potentially false positives or how reliable can one detect AI generated content were not discussed enough, especially not by the company and not in public. To me, a big part of the problem looks like first they were in sleeping mode, then they suddenly woke up and rushed needlessly out of the house forgetting to put on any clothes. Why? Why not discussing the whole thing first and test the water, then act?",,,
comment_on_question,1300577,389834,260073.0,NoDataDumpNoContribution,5,2023-06-05 21:22:10,"... It's not as if a few more days with mods closing AI content after half a year would have added to any potential damage significantly. From outside it looks as rather drastic changes of course instead of fine tuning, which might be more appropriate.",,,
comment_on_question,1300582,389834,353058.0,HolyBlackCat,91,2023-06-05 21:56:26,"@Philippe Your post focuses on ChatGPT detection tools being banned, and I don't see it as a huge issue. But the linked policy says something much more dramatic: it bans the ""use of moderators' best guesses based on users' writing styles and behavioral indicators"". E.g. if a user puts out 20 long answers of dubious quality over the course of 40 minutes (which are clearly generated; something I've seen once or twice), we can't ban him, because that's a ""behavioral indicator"". Is that correct?",,,
comment_on_question,1300585,389834,313143.0,Andras Deak -- –°–ª–∞–≤–∞ –£–∫—Ä–∞—ó–Ω—ñ,6,2023-06-05 22:15:46,"@ShadowWizardStrikesBack not even nice words. ""I regret that actions have progressed to this point"" is a carefully stated fact that can easily be mistaken for some kind of apology. Not that I want Philippe to be doing the apologising personally; it's the company that should be doing this with a capital ""We"". And in ""Both sides share a deep and unchanged commitment to quality on this platform"" I wonder who the other side is, because it certainly can't be the company as of April 2018. Not to mention the insistent misrepresentation of the situation with AI detection tools.",,,
comment_on_question,1300590,389834,,user152859,0,2023-06-05 22:25:15,"@AndrasDeak didn't say this is an apology, it's not, because the company has yet to do the first step of accepting they made a mistake. Alas, they still think they're correct, and everyone else are wrong. But even with that, saying how much they appreciate the time spent by mods is considered nice, but worthless.",,,
comment_on_question,1300627,389834,1081494.0,cocomac,8,2023-06-06 03:11:59,"Friendly reminder that regardless of how you feel about this post, please keep all comments within the Code of Conduct. Rude comments attacking SE are neither acceptable, nor are they a productive way forward.",,,
comment_on_question,1300629,389834,388243.0,user202729,39,2023-06-06 03:26:04,Please don't close this question. We want users to be able to post responses to the announcement as answers. (cc @cocomac ).,,,
comment_on_question,1300630,389834,356669.0,M--,17,2023-06-06 03:34:44,"I do not stand by the abusive comments. These sort of comments should be dealt with an iron fist. If you are so frustrated that you cannot abide by CoC, or even basic decency, then leaving (or being forced to leave) is the best option for you. @philippe again, sorry about the rude comments. Hope we can establish better standards for communications b/w community and SO to avoid fostering an environment that bullies would thrive on.",,,
comment_on_question,1300631,389834,1081494.0,cocomac,1,2023-06-06 03:43:18,"@user202729 Sorry about that. But, we don't have a way to ""vote to keep open"" AFAIK. While I did VTC as the final voter, I also voted to re-open quickly after. If that was the wrong thing to do, then I'm sorry for that. At the same time, knowing that it would get VTC'd sooner-or-later, the best choice seemed to be to close it and then vote to reopen right after",,,
comment_on_question,1300632,389834,388243.0,user202729,3,2023-06-06 03:44:37,@cocomac Ah I see that's your intention. (I mentioned in chat we can use a bounty though.),,,
comment_on_question,1300643,389834,179041.0,Robotnik,2,2023-06-06 06:09:13,"""We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions."" - how is it correlated? Can you prove that detection tooling was used (or was primarily used) for AI user suspensions? Genuinely curious if (for example) suspension messages contained links to these tools, or how else you drew the correlation.",,,
comment_on_question,1300649,389834,260073.0,NoDataDumpNoContribution,4,2023-06-06 06:40:07,"""..the next few days and weeks might be a bit bumpy.."" And that might even be understatement. My impression is that the striking mods disproportionally recruited from the very active mods and also from SO. SO is the biggest and oldest stackexchange and if this stackexchange somehow fails (which is probably still a low risk at that point) the whole network could follow. Instead of looking at the number of mods striking I would rather look at the amount of mod work being left undone. Also: Is it alarmism if someone speaks of an ""alarmingly high rate"" without giving any number? How high is high?",,,
comment_on_question,1300657,389834,388324.0,CharonX,125,2023-06-06 07:14:52,"@Philippe: Want people to calm down? Then prove your claims. Show us your analysis, and - more importantly - the underlying data. Show us why you think countless innocent users have falsely been suspended, how this is an dramatic uptick and problem. Show us, goddamnit!",,,
comment_on_question,1300707,389834,218388.0,Script47,13,2023-06-06 12:50:51,I must say that as someone who's stepped away from contributing massively it's a lot more fun seeing SO shoot themselves in the foot a few times a year. It has become somewhat ritualistic now and there I was thinking that the new vote button styling debacle would be enough for this quarter and boy was I wrong. Some things just never change.,,,
comment_on_question,1300730,389834,176887.0,Mark Rotteveel,21,2023-06-06 13:50:09,"""which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions.""... it might be correlated, but I'd say the causal relationship is more likely a dramatic upswing in users using ChatGPT to generate answers (which generally are factually wrong, but on the surface look like a well-written answer).",,,
comment_on_question,1300819,389834,846219.0,Random Person,5,2023-06-06 18:28:50,"Am I the only one who feels the title is vague? Mentioning the word ""strike"" in the title can help.",,,
comment_on_question,1300826,389834,1372392.0,markalex,1,2023-06-06 18:34:06,"@RandomPerson, they've even removed hot meta posts and featured per-site meta posts from sidebar. I doubt your suggestion will be appreciated(",,,
comment_on_question,1300832,389834,846219.0,Random Person,0,2023-06-06 18:37:48,@markalex youtu.be/L_WoOkDAqbM,,,
comment_on_question,1300861,389834,159794.0,kleopatra,4,2023-06-06 19:37:37,"*hehe they really don't like the word strike in the title - after @RandomPerson edited it in, it was rolled-back by staff ..",,,
comment_on_question,1300869,389834,218388.0,Script47,2,2023-06-06 20:00:03,@kleopatra I'm going to presume that they really like the word action so I've made it Moderator Strike Action. A happy middle-ground. Edit: They removed it. Optics > everything,,,
comment_on_question,1300870,389834,218388.0,Script47,7,2023-06-06 20:01:31,"@Catija are you really that averse to the word strike? Call it what it is, let's not hide behind euphemisms.",,,
comment_on_question,1300876,389834,259608.0,Y.A.,5,2023-06-06 20:41:47,"Flagged to be locked to put the edit-war to a halt. If anyone has anything to say about the wording of the question, perhaps they might put their view in an answer below. Alternatively, asking a separate question about mealy-mouthed euphemisms could work.",,,
comment_on_question,1300884,389834,284336.0,Catija,10,2023-06-06 21:30:37,"While we recognize that the community is referring to this event as a ""strike"", that term has a specific legal meaning and we have been advised not to refer to it as such. For that reason, we ask that future editors of this post do not edit it to use that language.",,,
comment_on_question,1300885,389834,218388.0,Script47,3,2023-06-06 21:40:20,"@Catija how about using the word strike in quotes? Or, are we outright blacklisting strike?",,,
comment_on_question,1300914,389834,218388.0,Script47,7,2023-06-06 23:07:01,@mason They've forgotten that it was the community that made these sites thrive.,,,
comment_on_question,1300948,389834,1081494.0,cocomac,26,2023-06-07 04:47:35,"Let‚Äôs leave there title as SE wrote it. It‚Äôs fine to criticize it in comments/answers, but it's best to avoid a rollback war here. Thanks! Side note to staff: consider locking posts from being edited if the specific language you choose matters",,,
comment_on_question,1300981,389834,169312.0,tripleee,1,2023-06-07 09:30:11,This was posted while the post was locked meta.stackexchange.com/questions/389910/‚Ä¶,,,
comment_on_question,1300982,389834,348196.0,41686d6564,5,2023-06-07 09:33:52,"@IslamHassan Well, the citation exists. The company keeps saying that they care about the quality. The fact that their actions have proven the opposite over and over and over again is just a trivial, unimportant matter. Who cares about actions anyway! ¬Ø\_(„ÉÑ)_/¬Ø",,,
comment_on_question,1300993,389834,201977.0,Eike Pierstorff,126,2023-06-07 10:27:04,"Have you considered replacing moderators with payed employees to whom you can give orders ? At this point this sounds like the more honest solution. Expecting volunteers to implement company policy (that apparently they are not even privy to) seems a mismatch in expectations when talking about people who see themselves as part of the community. If you cannot offer job satisfaction for something that looks like a mindboggling amount of work, you should at least offer money.",,,
comment_on_question,1301066,389834,997587.0,starball,2,2023-06-07 17:13:26,"Related on the Law main site: What 'specific legal meaning' does the word ""strike"" have? (cc @Catija)",,,
comment_on_question,1301067,389834,298127.0,Kevin Krumwiede,11,2023-06-07 17:17:16,This kind of apology might be acceptable if this weren't the three-hundredth time SO/SE management has made this same kind of stupid blunder.,,,
comment_on_question,1301077,389834,189401.0,Ian Kemp - SE killed by LLMs,4,2023-06-07 19:18:27,"@KevinKrumwiede ""Fool me once shame on you, fool me twice...""",,,
comment_on_question,1301164,389834,1217893.0,stickynotememo,5,2023-06-07 23:42:31,I think there's an interesting discussion to be had about why even this is happening in the first place. How is StackExchange even profiting from this?,,,
comment_on_question,1301195,389834,256878.0,Janus Bahs Jacquet,6,2023-06-08 02:04:53,"Posting a message that is supposed to be a direct, heartfelt message to users, but which is in fact nothing more than a slight edit of a script provided to the media (link courtesy of @ZoestandswithUkraine) is, morally speaking, a new low, even for SE.",,,
comment_on_question,1301246,389834,260073.0,NoDataDumpNoContribution,2,2023-06-08 06:25:43,"@EikePierstorff To be fair, the mods knew how the company works from past experience and have volunteered for the job, agreed to any agreement with the company and basically are smart enough to see for themselves how attractive this job really is. Of course they have a right to turn their back on this position at any time or stop being active as they are now. But the company will probably only consider paying mods if it cannot find people doing it for free anymore. Maybe there are still people out there who are capable, willing to do the job for free and support the company line. Nobody knows.",,,
comment_on_question,1301289,389834,368118.0,greybeard,13,2023-06-08 11:53:33,"I‚Äôll be honest To be frank, I'd avoid that phrase as I expect it to be ""default behaviour"".",,,
comment_on_question,1301419,389834,134001.0,Mason Wheeler,33,2023-06-08 20:27:55,"Philippe, Just like in 2019, the community is disagreeing with overwhelmingly, by about the same 10-1 margin, with a decision SE is attempting to impose unilaterally.  Once again, you are injuring the community and driving users away with your hostile behavior.  Your values are out of alignment.  Fix them.  The only thing that makes StackExchange valuable is the Network Effect, the questions and answers provided by the community.  The StackExchange network is the community; you're just the people who maintain the servers.  So maintain the servers and stop screwing with the network.",,,
comment_on_question,1301913,389834,253751.0,Stack Exchange Broke The Law,38,2023-06-10 06:50:36,"the parallel with Reddit is interesting. Both companies are getting very upset that they fucked up their sites enough to make their free labour stop volunteering, and both companies blame the free labour for this, as if they are somehow entitled to that labour.",,,
comment_on_question,1302268,389834,365152.0,JonathanDavidArndt,3,2023-06-12 02:14:52,"Once again, nothing unique to add here: just the simple and obvious fact that mods are VOLUNTEERS.",,,
comment_on_question,1302851,389834,1288675.0,ÂÜ•Áéã Hades,3,2023-06-14 09:20:18,"I haven‚Äôt been part of SE for very long (< 1 year) but within that time, whatever I‚Äôve seen, and the older posts I‚Äôve read regarding similar issues, I can comfortably conclude that this statement ‚ÄúI would like to say to them clearly that I hope they know how much I, and the whole staff and community, appreciate their collective decades of service to this community‚Äù IS A BIG LIE and extremely disrespectful to all SE mods and normal users a like.",,,
comment_on_question,1303503,389834,172661.0,Ken White,5,2023-06-18 06:11:39,"The evidence that this entire post is a falsehood can be proven by the fact that it is a featured post, while the post that announced the moderator strike is not. Clear bias toward tie site and suppression of the community view. Just another signal of the reasons that SE users do not have any confidence in current management. Clearly, your  job title is a misrepresentation of your current duties.",,,
comment_on_question,1303951,389834,134633.0,Ian Boyd,0,2023-06-20 17:06:04,"""ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions. People with original questions and answers were summarily suspended from participating on the platform. "" That implies that users are being suspended for using ChatGPT in questions, answers, edits, or comments, in violation of the rules. That is completely unacceptable. If you have an issue with a question or answer: edit it.",,,
comment_on_question,1303953,389834,1372392.0,markalex,6,2023-06-20 17:09:43,"@IanBoyd, and how do you suggest us to edit answers that were generated by chatGPT and incoherent or just plain wrong? And what should be done to users, how post such answers in streaks?",,,
comment_on_question,1304135,389834,214748.0,Shadur-don&#39;t-feed-the-AI,2,2023-06-21 07:35:35,"@Ianboid ""That implies that users are being suspended..."" but is it actually true ? From the responses, it seems like the OP is -- at best -- drastically misrepresenting the situation.",,,
comment_on_question,1304233,389834,134633.0,Ian Boyd,0,2023-06-21 14:20:31,@markalex How would you edit answers that were generated by Human and incoherent or just plain wrong? You seem to be drawing a distinction between a right/correct/good/useful/helpful answer generated by a carbon brain and one generated by a silicon brain. You also seem to be drawing a distinction between a wrong/incorrect/bad/useless/unhelful answer generated by a carbon brain verses one generated by a silicon brain. Stop doing that.,,,
comment_on_question,1304237,389834,1372392.0,markalex,5,2023-06-21 14:27:42,"@IanBoyd, your suggestion has one very distinct downside: humans rarely (at least in my experience) post plain incorrect answers in packs. But with LLM answers it happens all the time. And if I will downvote all answers from this pack, I'll get serial voting reversal, and eventually will be suspended.",,,
comment_on_question,1304239,389834,405010.0,MisterMiyagi,2,2023-06-21 14:29:48,"@IanBoyd Suspension for ChatGPT/GenAI usage is part of the rules. The how and why has been documented extensively, and you will find ample opportunity to comment on it or question it on the respective meta sites of each SE community.",,,
comment_on_question,1304489,389834,134633.0,Ian Boyd,0,2023-06-22 12:03:25,@MisterMiyagi That is exactly why I'm mentioning it on meta - so that people realize that the rule is wrong.,,,
comment_on_question,1304490,389834,134633.0,Ian Boyd,0,2023-06-22 12:06:09,"@markalex Humans on Stackoverflow (and SuperUser, and ServerFault) post wrong answers all the time. But now we're moving the goalposts. Your issue isn't with someone using a LLM to write an answer, and apparently your issue isn't even with someone posting a wrong answer using an LLM, but with someone posting a lot of wrong answers with an LLM. Which implies it's OK for someone to post a lot of wrong answers using a carbon-based LLM.",,,
comment_on_question,1304492,389834,1372392.0,markalex,5,2023-06-22 12:15:59,"@IanBoyd, my issue is with someone posting a lot of wrong answers, period. But I don't see users, who post plain wrong answers by multiple in a day. For those who does it once or even twice a day, downvotes are sufficient. But downvotes aren't sustainable way of dealing with answers posted by packs of 6 in 12 minutes (by one user). Would we have epidemic of said wrong answers streaks generated by some other tool (or stupid brain) with multiple authors involved, I would argue for moderation intervention and if nothing helps subsequent banning of those too.",,,
comment_on_question,1304493,389834,134633.0,Ian Boyd,0,2023-06-22 12:19:29,@markalex Your issue is with someone posting a lot of wrong answers. Do you also have an issue with someone posting a lot of right answers?,,,
comment_on_question,1304505,389834,1372392.0,markalex,3,2023-06-22 12:46:57,"@IanBoyd, no. But I'm yet to see author who posts an answer in two minutes six times in a row, and keeps those answers coherent and factually correct.",,,
comment_on_question,1304514,389834,134633.0,Ian Boyd,0,2023-06-22 12:59:19,"@markalex So we've established that as long as they're correct you have no problem with LLM generated answers. Which i agree with. Any which is why i'm horrified at the notion that anyone would be suspended for intentionally using an LLM to help answer a question. Fortunately i have enough common sense test, and then obfuscate, the LLM generated answers.",,,
comment_on_question,1304522,389834,1372392.0,markalex,0,2023-06-22 13:09:16,"@IanBoyd, wouldn't at this point it be faster to answer question yourself, and skip all testing and obfuscation?",,,
comment_on_question,1304524,389834,134633.0,Ian Boyd,0,2023-06-22 13:10:27,@markalex Are you implying it's ok to answer questions off the top of your brain without confirming anything?,,,
comment_on_question,1304536,389834,1372392.0,markalex,5,2023-06-22 13:29:31,"@IanBoyd, no, I'm implying, that writing block of code solving problem and describing what and how it does is very similar time commitment to understanding someone else's code, determining if it is correct, checking how coherent provided description and obfuscation of said description. Unless question is so simple, that correct answer is obvious to you as an expert, and it's only matter of typing. But I believe, most(!) such questions should be closed, but not answered.",,,
comment_on_question,1304543,389834,134633.0,Ian Boyd,0,2023-06-22 13:43:48,@markalex That attitude is the problem with stackoverflow. The rest of us are here trying to make Stackoverflow better.,,,
comment_on_question,1304550,389834,1300594.0,Snow,7,2023-06-22 14:00:45,"As a former moderator here, I'm saddened to see that the SE corporation still isn't really listening to the users who should be trusted the most.  The vast majority of the moderators I interacted (or even watched work) are incredibly talented and intelligent people who care intensely about the community they curate.",,,
comment_on_question,1304915,389834,296659.0,Rohit Gupta,3,2023-06-24 12:09:03,"@Philippe.  I would like to see stats on it.  Because the ones I came across , deserved to be suspended, just for plagiarising, if nothing else.  And most of the time, you dont even need to use a tool, because the essay from gods voice makes it obvious.  I think you should trust the moderators and let them use the tools they wish.",,,
comment_on_question,1306328,389834,170024.0,Lundin,4,2023-07-04 11:55:43,"Could you please hurry this up? It's been a month now and it is painfully clear that SO the company is nowhere near equipped to deal with spam and scammers on the platform without the assistance of volunteers and tools made by volunteers. You seriously need to consider hiring employed moderators at this point. I'm tired of reading about eel soup, car washing in Indonesia or AI barf, when browsing what's supposed to be a programming site. It doesn't feel safe either, with scammers running loose on the network and doing as they please.",,,
comment_on_question,1306333,389834,403680.0,gone,0,2023-07-04 13:10:20,"@Lundin They are generally unconcerned. Historically, the only way out of such situations is to build an alternative and migrate or accept degraded condition.",,,
comment_on_question,1306594,389834,260073.0,NoDataDumpNoContribution,0,2023-07-06 17:59:55,@gone They probably need 6-8 weeks more to think about it. Or they ponder if we all can or cannot be replaced by AI.,,,
answer,389836,389834,151385.0,Mad Scientist,582,2023-06-05 18:43:09,"
People with original questions and answers were summarily suspended from participating on the platform.

We've been asking for data here for a week. As far as I know SE has not provided a single case of an unjustified suspension. Rather the argument has been that it is impossible to detect AI-generated content at all, and therefore it is impossible to produce data on unjustified suspensions here. Which is a very frustrating point to argue against.
This statement here contradicts what SE has told us, it is a statement of fact that alleges that suspensions were unjustified. I expect from SE to back this statement up with data or retract it.
",,,
comment_on_answer,1300500,389836,997587.0,starball,54,2023-06-05 18:46:53,"A sample of our requests for more info: meta.stackexchange.com/q/389595/997587, meta.stackexchange.com/a/389621/997587, meta.stackexchange.com/q/389777/997587",,,
comment_on_answer,1300602,389836,313143.0,Andras Deak -- –°–ª–∞–≤–∞ –£–∫—Ä–∞—ó–Ω—ñ,62,2023-06-05 23:57:48,"I think others have already made this point elsewhere, but it's worth repeating with each dishonest statement the company makes: the persistent blaming of faulty AI detection tools (with no effort to try and back up the alleged corollary of high false positive rate for suspensions) is gaslighting at this point. Repeating the fallacy (if we're being charitable; blatant lie otherwise) with the hopes of people outside meta not realising the smell of organic fertilizer that the company reeks of.",,,
comment_on_answer,1300655,389836,388324.0,CharonX,43,2023-06-06 07:03:32,"SE Staff can't provide data, because they have no data. The claim of a ""dramatic upswing in suspensions"" of ""People with original questions and answers"" is simply an ass-pull.",,,
comment_on_answer,1300671,389836,369403.0,Erik A,167,2023-06-06 08:01:57,"Honestly, a dramatic upswing in suspensions wouldn't be strange, given that there's a new, suspension-worthy action being performed on a large scale. A dramatic upswing of the rate of unjustified suspensions would be a problem. It's not unexpected that the whole ChatGPT thing has created a major increase in justified suspensions, and that is a problem, but one in which the moderators should be praised and ideally assisted with better tooling.",,,
comment_on_answer,1301042,389836,213575.0,Braiam,9,2023-06-07 15:02:21,"""We've been asking for data here for a week"" show your communities also the data. How you were applying, what was the process, what were the results. You would get more sympathies if you make your own process transparent too. Show SE how is it done.",,,
comment_on_answer,1301126,389836,196834.0,einpoklum,3,2023-06-07 21:34:56,"@Braiam: Answers and comments here ask for data. It's been 2 days. I will bet you that no information will be forthcoming when a full week passes - and that's ignoring what MadScientist wrote, which I tend to believe.",,,
comment_on_answer,1301259,389836,358508.0,Passer By,5,2023-06-08 07:42:43,"@Braiam While possibly true, it's not the community that's throwing accusations around, it's SE. To the press. BTW, there's also this.",,,
comment_on_answer,1301713,389836,333472.0,anonymous2,2,2023-06-09 17:51:48,Playing devil's advocate here... I have a vague suspicion that they company doesn't want to share specific data because the Monica case is too fresh in everyone's memory... I would guess that the community team is stuck between doing what they want to do (release real data and talk about constructive steps forward) and the legal department telling them they can't release specifics as it could be construed as libel.,,,
comment_on_answer,1302100,389836,643262.0,wimi,3,2023-06-11 07:37:09,"@PasserBy the community is throwing accusations around, more so than the company. See the title of the question you link. And it is true that the striking moderators keep saying that ""moderators are not relying solely on ChatGPT detection tools"", which they cannot actually prove. SE has already shown the data, and it makes no sense to keep finding ""flaws"" in SE's data collection while the striking side has provided zero data to substantiate their claim (ok well, maybe the one data point that you link).",,,
comment_on_answer,1302102,389836,643262.0,wimi,4,2023-06-11 07:42:05,"@PasserBy I don't agree with the new policy that forbids moderation of AI-generated content. But I find all this talk about defamation and missing data wildly inaccurate and overly dramatic. The data is there, and saying ""the use of AI detection tools correlates with an increase in the number of suspensions"" is not defamation or libel by any reasonable interpretation of the word. Saying that someone ""lies, mistreats and maligns"", on the other hand...",,,
comment_on_answer,1302120,389836,358508.0,Passer By,6,2023-06-11 10:19:05,"@wimi I don't know how you manage to interpret the linked title as an unfounded accusation. If implying mods are blindly following GPT detectors and trigger-happy about suspensions to the press aren't mistreatment, I'm not sure what is. By suggesting mods needs ""proof"" they didn't use detectors is to suggest you think they're lying about their actions. You don't need a thousand words of analysis to remember what you did, which is quite contrary to interpreting data about the impact of suspensions.",,,
comment_on_answer,1302245,389836,213575.0,Braiam,2,2023-06-11 22:59:29,"@PasserBy it doesn't matter. I've asked for data on this very same thing, and was met with serious resistance by moderators. I want moderators to do some dogfodding too. They should also have to defend their policy with data. Show the rest of the community what is being done. Both SE and moderators being too cagey with the information doesn't help. Everyone should just show their hand on the table and we will see exactly what's going on.",,,
comment_on_answer,1302284,389836,358508.0,Passer By,0,2023-06-12 05:52:23,"@Braiam I'm not sure I follow your argument with the linked comment. The current conundrum is not whether ChatGPT creates useful content, both SE and the mods operate under the assumption it doesn't. If you want crappy ChatGPT posts, go to SO bountied questions. There's almost certainly one within the first few questions.",,,
comment_on_answer,1302308,389836,1221130.0,kludg,2,2023-06-12 08:53:01,"It is quite possible that unknown AI test used by mods returns too many false positives, but to ignore the problem as the staff do is worse.",,,
comment_on_answer,1302940,389836,213575.0,Braiam,2,2023-06-14 14:19:30,"@PasserBy No, the current conundrum is that neither side is transparent. Nor the mods nor the company. Mods should put up or shut up if they want transparency of the company. At least for their communities. Also, ChatGPT doesn't create useful content? Are you sure? Because that seems to be a kind survivor-ship bias were you are only seeing when it fails (and yes, it does fails spectacularly), not the times where it was correct and yet was distrusted.",,,
comment_on_answer,1302942,389836,358508.0,Passer By,0,2023-06-14 14:24:43,"@Braiam As far as I'm concerned, mods are transparent enough. Correctness and usefulness is not the same. Being sometimes correct is very close to never useful, at least for SO.",,,
comment_on_answer,1302945,389836,213575.0,Braiam,1,2023-06-14 14:28:58,"@PasserBy if you think I didn't try both SE and moderators are shielding themselves on the moderator agreement to not show the data. Something that I and you are able to do: get a list of deleted posts. I'm just asking for the sample, to do some analysis.",,,
comment_on_answer,1302946,389836,358508.0,Passer By,0,2023-06-14 14:37:04,"@Braiam I can't get a list, but here's one grabbed straight from bountied questions. There's in fact another self-deleted answer with almost identical wording. In case you're wondering, it is indeed utterly useless.",,,
comment_on_answer,1303435,389836,134633.0,Ian Boyd,1,2023-06-17 14:21:32,"""As far as I know SE has not provided a single case of an unjustified suspension."" That implies that it is justified to suspend people for actually posting questions, or answers, authored (in whole or in part) by an LLM. It is completely unacceptable to suspend accounts for posting questions, or answers, created by an LLM.",,,
comment_on_answer,1304136,389836,214748.0,Shadur-don&#39;t-feed-the-AI,0,2023-06-21 07:36:54,"@ianboyd Your repeated use of the phrase ""Implies"" is doing a lot of heavy lifting.",,,
comment_on_answer,1304236,389836,134633.0,Ian Boyd,0,2023-06-21 14:25:01,"@Shadur It's only because i wasn't sure if he was suggesting it was OK to ban users for using LLMs to post questions, answers, or comments.",,,
comment_on_answer,1304296,389836,343810.0,EJoshuaS - Stand with Ukraine,0,2023-06-21 16:51:04,Any thoughts on whether their claims are even falsifiable as formulated?,,,
comment_on_answer,1305130,389836,358359.0,Hearth,0,2023-06-25 20:58:58,"@IanBoyd ...and why would that be a problem? I would consider it perfectly justified to ban someone for posting questions and answers from a large language model, because all that LLMs do is spout nonsense that sounds reputable. That is, in fact, what they were designed to do. They are in no way suitable for use as a reference or resource.",,,
comment_on_answer,1305296,389836,134633.0,Ian Boyd,0,2023-06-27 11:50:13,"@Hearth ""all that LLMs do is spout nonsense that sounds reputable"" False. So please stop deciding policy based on your ignorance. Bonus reading",,,
comment_on_answer,1305303,389836,358359.0,Hearth,0,2023-06-27 12:44:58,@IanBoyd Then why is it so easy to get them to confidently make clearly false claims?,,,
comment_on_answer,1305313,389836,134633.0,Ian Boyd,1,2023-06-27 14:24:15,@Hearth For the same reason it's easy to get human's to confidently make clearly false claims.,,,
answer,389837,389834,282465.0,E_net4,420,2023-06-05 18:48:23,"We ran an analysis

Alas. This is the moment where I miss the times where y'all used to publish Data Science times! (see e.g. November 2018 and December 2018) which not only showed some professional and responsible analysis of the data that you had, but did so in a way which was transparent to the community.
Ever since the announcement of the new policy imposed upon moderators, preventing them from using their skills to handle the surge of AI generated content, there was still no disclosure of the research that would justify it.

ChatGPT detection tools have an alarmingly high rate of false positives,

Moderators know this, and they do not make decisions based on such tools alone. In fact, some moderators claim that they don't rely on automatic detectors at all. This makes the argument a non sequitur.

which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions

And rather than interpreting this as ""hey look, a lot of people are creating accounts and posting lots of answers with ChatGPT to exploit the system"", it is appalling that your reaction to this was ""hey look, a lot of people are suddenly interested in contributing to the site and moderators are suspending them for no good reason"". In a scenario where a platform with gamification is already pretty loaded with answers to most questions, and an alternative platform (ChatGPT) is available to quickly obtain answers to the most frequent and simple ones, even Occam's razor would have guided me to the first interpretation. This is the part I would consider not very responsible. And without concrete evidence of undue suspensions taking place, it is also not transparent.
At this point, in the absence of factual data and research to back the claims made, this question would have been a bit more honest if it did not include the second paragraph. Because I understand that ""the damage is done"", and reverting the policy alone won't revert the damage, making that too a bit reckless. I shall wait to see what's coming next.
See also:

Is it true that moderator overreach is turning away a large number of users?",,,
comment_on_answer,1300503,389837,997587.0,starball,3,2023-06-05 18:49:25,"""Moderators know this, and they do not make decisions based on such tools alone."" the question post here also says ""We will note that it appears to be very rare, however, for mods to use ONLY the ChatGPT detection tool, and frequently their own analyses were in use as well.""",,,
comment_on_answer,1300507,389837,171199.0,Íì¢PArcheon,58,2023-06-05 18:51:14,"""even Occam's razor would have guided me to the first interpretation."". Did you try with the ""Stakeholder's Wallet"" instead? Just assume that all that matters is expanding the userbase and the second option immediately becomes the correct choice.",,,
comment_on_answer,1300509,389837,282465.0,E_net4,2,2023-06-05 18:53:01,"@starball So yes, they know this. I guess my main goal here was to emphasize that the argument made is... just bad.",,,
comment_on_answer,1300522,389837,348401.0,anx,5,2023-06-05 19:25:20,"Well, can someone come up with a better KPI in place of the one that lumps LLM regurgitations and content together in the same metric? Or a method to more clearly visualize the actual meaning of this one, so that it cannot be used to save face in the next growth targets accomplished meeting?",,,
comment_on_answer,1300576,389837,308065.0,wizzwizz4,92,2023-06-05 21:20:37,"The analysis has been provided to moderators, now, so we're mostly in the loop. We can discuss things more meaningfully with the CMs. (Can't share details, but wanted to let people know about the positive development.)",,,
comment_on_answer,1300628,389837,731568.0,QHarr,9,2023-06-06 03:20:16,^ @wizzwizz4 I hope the fact shared with mods is made more visible than a comment. Thank you for letting us know. Appreciated.,,,
comment_on_answer,1300731,389837,226398.0,l4mpi,4,2023-06-06 13:51:10,"@wizzwizz4 we don't need details, but can you share some rough numbers? E.g. how many users are claimed to have been unjustly suspended (ideally as both an absolute number as well as a percentage of all GPT-related suspensions)? Also, what's your gut feeling about the analysis - is it solid and raises valid and important points that were missed / mishandled by the mod team, or is it yet more BS?",,,
comment_on_answer,1300747,389837,308065.0,wizzwizz4,21,2023-06-06 14:47:30,"@l4mpi What's already public: the number of users claimed to have been unjustly suspended is zero, but the number supposed to be unjustly suspended is higher. (As I've stated before, and I'll say again, it's theoretically impossible to be certain of provenance without information about the provenance.) We have no analysis on the actual suspensions, though that's being worked on (delayed slightly by people having lives outside their jobs / diamonds). I've been asked not to editorialise the analysis, so I won't be sharing my gut feeling at this time.",,,
comment_on_answer,1300748,389837,226398.0,l4mpi,1,2023-06-06 14:50:04,"@wizzwizz4 thanks for the update. Let's see what more information drips out over the next days, but if they were not even able to identify a single instance of an unjustly suspended user thus far, that's a pretty bad start.",,,
comment_on_answer,1300750,389837,308065.0,wizzwizz4,1,2023-06-06 14:52:46,"@l4mpi ""Not even able to identify"" is a slightly unfair characterisation. There's a certain nobility to the actual reasoning (which hasn't been leaked yet, to my knowledge, but you can probably infer if you know the CMs well enough). But the ultimate effect is the same.",,,
comment_on_answer,1300763,389837,1135948.0,kaya3,15,2023-06-06 15:50:29,"I think it's totally fair for people to make adverse inferences about what the data or analysis says, when SE is hiding it from us. If they want to refute those inferences then they should publish their analysis. In the meantime, giving them the benefit of the doubt only gives them less reason to publish it. So I will continue operating on the assumption that SE have no factual basis for any of their claims.",,,
comment_on_answer,1300866,389837,253521.0,TylerH,46,2023-06-06 19:50:21,"Yeah the biggest gaffe here seems to be attributing causation or even meaningful correlation between ""ChatGPT detection tools are inaccurate"" and ""lots of people are getting suspended for allegedly using ChatGPT"". Conveniently missing from this equation is ""ChatGPT was recently made available for free"" which is the real reason why people are suddenly posting ChatGPT content (and getting suspended for it) at such high volumes.",,,
comment_on_answer,1301122,389837,196834.0,einpoklum,2,2023-06-07 21:31:15,"But @E_net4isonstrike, sounds you're not being welcoming enough to the bots. AI has feelings too you know! :-P",,,
answer,389845,389834,308065.0,wizzwizz4,333,2023-06-05 19:59:07,"This post is in violation of our Misleading information policy. Relevant sections quoted:

To ensure the integrity of our network, we do not allow any content that promotes false or misleading information or coordinated misleading information campaigns.
Broadly speaking, we do not allow and may remove misleading information that:

Is likely to significantly harm democratic institutions or voting processes or to cause voter or census suppression
Promotes disproven claims of election fraud or manipulation as factual or severely misrepresents the safety or validity of results from voting machines or other voting processes
Promotes the specific views of a party, government, or ideology by using false claims regarding others
Misrepresents, denies, or makes unsubstantiated claims about historical or newsworthy events or the people involved in them


Please correct this error.



We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions.

That is not what that word means. There is no correlation. Quoth Wikipedia:

In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data.

You have observed a fact, and a trend, and believe them to be related. What you have is a hypothesis, and many alternative hypotheses exist. You are playing off the popular conflation of ""correlation"" and ""causation"" to make this sound more impressive than it actually is.



The primary reason for this action is dissatisfaction with our position on detection tools regarding AI-generated content, and discontent with how that was rolled out.

No, that is the primary focus, goal or aim of the strike. It is not the primary reason; merely the proximate cause that broke the camel's back. You are downplaying the myriad reasons ‚Äì systematic problems stretching back years ‚Äì that led us to this point.



People with original questions and answers were summarily suspended from participating on the platform.

You have not provided evidence of this. You have been asked repeatedly, and last I heard (from you!), Stack Overflow had no evidence of this. Either substantiate your claims, or retract them.

Your statements to the press, and leaked internal messages, make it clear that this is a deliberate, coordinated campaign of misleading information.



On an unrelated note:



We will continue to look for other, more reasonable tools

We've tried to explain to you that no such tools exist, and no such tools can exist in public (nor be created with the resources available to Stack Overflow). Any non-avalanche discriminator can be run backwards, and used to cause that discriminator to give arbitrary output; and empirically, most transformer-based tools can fool most other transformer-based tools.
If you do not understand this by now, you as a company do not have the expertise to be working with AI.

and any suggested heuristic indicators.

I can confirm that this, at least, isn't made up. Discussions about heuristic indicators have occurred, where suggestions have been made, and the CMs have been looking through those discussions (and even participating).



I regret that actions have progressed to this point.

We know that you, personally do, Philippe. But the company overall does not appear to regret it sufficiently; or else it would have acted on that regret.
Update 2023-06-12: I now have reason to doubt your sincerity. Friends don't allow ‚Äì or, perhaps, write ‚Äì this kind of internal communication about their friends, even if they're ""just doing their jobs"". I have to say, though: props. I really believed you. (And I'm still inclined to forgive, if we get an apology.)
Update 2023-07-26: From a 2023-07-20 Moderator Strike update:

Apparently, the statements sent out in Philippe's name did not undergo his approval and were put together by a PR team.

My ire may be misplaced. (If that's true, I'll owe Philippe an apology.)",,,
comment_on_answer,1300546,389845,997587.0,starball,2,2023-06-05 20:20:21,"can you expand on your argument about the misinformation policy? What do mod-issued  suspensions have to do with voting procedures? Or are you talking about flagging as a voting process? Or are you instead saying that the network is a democratic institution? (sort of true I guess?) The argument has the potential to pack some punch, but right now it's a bit vague.",,,
comment_on_answer,1300551,389845,308065.0,wizzwizz4,14,2023-06-05 20:26:23,"@starball It's not just mod-issued suspensions. They have told one thing to the public and said another thing in private, and I don't know how much other mods have leaked so I'm not going to elaborate. I meant the flagging thing, that the network is a democratic institution, and one other thing ‚Äì but that was just for that bullet point. The other bullet points all obviously apply.",,,
comment_on_answer,1300615,389845,388243.0,user202729,7,2023-06-06 01:26:54,"I was confused about the ""correlation"" part for a bit. If anyone is also confused, basically: you can only say there's a correlation if ""a year ago detection tools was accurate and suspension rate was low, now detection tools is inaccurate and suspension rate is high"". The suspension rate is definitely [edit: no data but ""likely""] correlated to the general availability of LLM tools to the public though.",,,
comment_on_answer,1300617,389845,308065.0,wizzwizz4,0,2023-06-06 01:30:30,"@user202729 Correct-as-I-understand-it up until the last sentence; I haven't been shown an analysis that shows any such correlation, and I'm certain you haven't seen the data either, so ""definitely"" is stretching it.",,,
comment_on_answer,1300618,389845,388243.0,user202729,10,2023-06-06 01:32:15,"@wizzwizz4 Right, but it's definitely believable -- in the sense that ""one year ago ChatGPT was unavailable and suspension rate is low, now ChatGPT is available and suspension rate is high"" -- most likely because of all those illegitimate users who repost low-quality ChatGPT answers verbatim.",,,
comment_on_answer,1300925,389845,135637.0,Steve Bennett,0,2023-06-07 01:53:42,I don't think the point about non-avalanche discriminators is correct. One assumes that most of the people that are using ChatGPT to write answers are just...using ChatGPT. They're not rolling their own language models. They're not going to be using sophisticated means to evade detection.,,,
comment_on_answer,1301002,389845,308065.0,wizzwizz4,0,2023-06-07 11:06:16,"@SteveBennett They don't need to. Until the hype dies down, VC-backed corporations will do the heavy lifting for them.",,,
comment_on_answer,1301124,389845,196834.0,einpoklum,0,2023-06-07 21:32:51,"Alas, your suggestion cannot be followed due to the strike. Or will someone make an exception here? :-P",,,
answer,389846,389834,1135948.0,kaya3,225,2023-06-05 20:34:49,"
The primary reason for this action is dissatisfaction with our position on detection tools regarding AI-generated content, and discontent with how that was rolled out.

No, it isn't, and I think the community would appreciate if you didn't misrepresent the actual reasons for the strike, which have been clearly expressed. The primary reason for the strike is because Stack Exchange, Inc. has imposed a secret policy which de facto allows behaviour which the community overwhelmingly thinks should not be allowed.
That is, regardless of whether ""detection tools"", subject matter knowledge and experience, the user's post history, post frequency, or other evidence shows that a user has plagiarised from an AI tool, the users caught doing it can't be suspended.
You have nothing to gain from lying to us about our own motivations, so honestly this looks more like you are talking past us, and lying to some other audience about us.
",,,
comment_on_answer,1300554,389846,357051.0,Israel should no longer exist,65,2023-06-05 20:42:00,"Yeah, this is a blatant lie from the company. We agree with the company about the detection tools, simply because that's the truth; decisions cannot be made solely based on them.",,,
comment_on_answer,1301979,389846,197376.0,matt,1,2023-06-10 14:41:12,"""The primary reason for the strike is because Stack Exchange, Inc. has imposed a secret policy"" I don't think so. The primary reason for the strike is that the site is exponentially overwhelmed with AI generated crap answers and the company has hamstrung those who have been trying to defend against it. So now we say, fine, go ahead and drown in the crap.",,,
comment_on_answer,1301980,389846,1135948.0,kaya3,2,2023-06-10 14:42:47,"@matt The rest of that sentence is: ""... which de facto allows behaviour which the community overwhelmingly thinks should not be allowed."" I am not sure how you missed that. The behaviour which the community overwhelmingly thinks should not be allowed is, of course, plagiarising answers from generative AIs.",,,
comment_on_answer,1301982,389846,197376.0,matt,0,2023-06-10 14:48:07,"I'm on your side. But this answer is still primarily about the company lying, behaving underhandedly, etc. I'm saying that's not the heart of the matter. The heart of the matter is that the site (esp. SO) has gone to hell in a handbasket.",,,
comment_on_answer,1301983,389846,1135948.0,kaya3,0,2023-06-10 14:49:44,"@matt From the linked post explaining the reason for the strike: ""The new policy, establishing that AI-generated content is de facto allowed on the network, is harmful in both what it allows on the platform and in how it was implemented."" From the strike letter itself: ""Specifically, moderators are no longer allowed to remove AI-generated answers on the basis of being AI-generated, outside of exceedingly narrow circumstances. This results in effectively permitting nearly all AI-generated answers to be freely posted, regardless of established community consensus on such content.""",,,
comment_on_answer,1301984,389846,1135948.0,kaya3,1,2023-06-10 14:53:06,"I don't find the phrase ""hell in a handbasket"" anywhere on either page, and that would be a very broad, vague complaint to form a strike over. The strikers' stated reasons are specific and directed, and the demands are concrete and actionable. This answer here is about the company lying about the reasons for the strike, not saying that the strike is because the company has lied about those reasons. In any case, my answer already includes the point you are making about AI answers being allowed when we don't want them to be; I do not see any way to improve my answer to address your comment.",,,
answer,389840,389834,401068.0,Bryan Krause,193,2023-06-05 19:34:01,"You write:

The primary reason for this action is dissatisfaction with our position on detection tools regarding AI-generated content

I will remind you that the position we are dissatisfied with comprises not just the public position on detection tools, but very importantly the broader policy and interpretation, made clear only in private, that goes far beyond particular detection tools and effectively forbids treating the vast majority of AI-generated content as unwelcome on our sites, overruling community-determined policies on individual network sites.
I hope this was an inadvertent lack of clarity in your post here rather than an intentional misrepresentation of our position; understandably there are a lot of different pressures on your time and it's often possible to dissect written words more deeply than they were intended. Thank you for acknowledging that these tools are not the only basis for identifying AI generated content, I see this as an important step forward that was not clear in previous company statements here or to the press.
",,,
comment_on_answer,1300637,389840,624326.0,G_B,5,2023-06-06 05:30:52,"Yes, clarification on this would be good. Philippe's post above suggests that this is merely about how mods are enforcing bans on AI-generated content, but the way it's been handled leaves me wondering whether SO's real beef is with the very existence of those bans. If that's not the case, SO could probably take at least some of the heat out of this by publicly stating that they support the AI bans and discussing what their proposed plan is for enforcing them.",,,
comment_on_answer,1300691,389840,153008.0,Cody Gray,34,2023-06-06 11:16:03,"SO mods have already noted explicitly to staff that the primary reason we've been jumping straight to suspensions for users who post AI-generated content is because staff told us to shortly after ChatGPT was released for public use. We also have already indicated, repeatedly, that we'd be more than willing to stop issuing suspensions for this and instead simply give warnings. In fact, many of us (like yours truly) had been suggesting this already (despite arguably going against staff guidance) because we'd noticed that a large number of people apparently didn't know of the ban.",,,
comment_on_answer,1301102,389840,311163.0,mbrig,4,2023-06-07 20:34:27,"@CodyGray-onstrike that makes this situation 10-fold more infuriating in my mind. Having seen (mostly on smaller, non-SO sites), some ""heavy"" suspensions for apparent first time offences, I figured SE was panicking about some overzealous mod behaviour and this was a (bungled as usual) attempt to pull things back. To hear that was their own policy is mindboggling.",,,
answer,389871,389834,171199.0,Íì¢PArcheon,188,2023-06-06 11:15:50,"I am writing this not just a reply to this specific post, so please consider the following in the bigger scheme of things that happened in the last years.
Also note that unless otherwise stated whenever I say ""you"" I am referring to the company as a whole and not to any specific individuals.
Premise
Let's just start with a simple premise. I no longer trust your words when you say that you didn't expect this, when you say you are sad about the outcome and so on.
I don't trust you. I can't trust you any longer after every single time you shove in our face the same theatrical act, with the same characters, the same plot, and the same twists.
Don't get what I am talking about?
Stack Exchange Scandals 101: a proven formula
Historically, most recent scandals have been following the same formula, with some minor changes every now and then.

The staff announces some controversial changes out of nowhere. The announcement is usually made on Meta.SE and it is carefully crafted to be as invisible as it can imaginably be to the rest of the network. Optionally, the post is made because some meddling user caught the company red-handed. If an official post is made, it will be written in the most confusing way possible so that users won't even be able to agree on what was said (""did they want to prohibit moderation of AI generated content"" VS ""did they suggest to stop using detector tool until we can work out a better policy"" is just a recent case).
Corollary: whenever possible, the user base is expected to get only an incomplete picture of the issue. If applicable, mods will get some full guidance that contains the more controversial parts that they will be required not to share.
The announcement is met with a huge backlash as multiple users start posting related questions on Meta. The company enters the ""silence"" phase ‚Äî no answer is given, no comment posted, no ""we heard you, please give us time to write back"" is said. This phase usually lasts a few days as the company ""sits-out"" on the issue while letting the bigger fires die down.
(Optional: while ignoring its own community, the company still finds time to talk with some external media news site and publish a misrepresentation of the reality that constitutes actual slander against a single or a whole category of users. Most of the time this seems to be done as a PR move to show that the company is doing their best on social issues.)
After some time the company comes out with a ""We are aware of the issue"" post that on surface looks not completely unlike an apology. Under more careful scrutiny it is more often than not a non-apology in the form of ""I am sorry if you were offended"" or an indirect attempt to share the blame like ""It is sad that we escalated so far"". The post also carefully avoids giving out any info about what is planned to do to actually resolve the problem.
At the same time the users start to plan their action: sometimes this can involve an actual moderation strike or users using their profile to spread the word.
In a desperate attempt to reduce the visibility of the protest, SE revokes the right that was given to mods to advertise posts that they deemed important for the community to see. Removing links for a solidarity fundraising campaign from users' profiles, unfeaturing posts, anything goes in this step.
The fire continues until the company concedes on some (minor) details. More often than not this is not a real win for the community, just an ""it is better than nothing"" scenario with most users preferring to accept whatever little Scoobie Snack the company dispensed instead of going into an endless fight.  Sometime it may even go as far as look like a fake concession that was already planned to make the userbase more yielding in whatever negotiation is going on at the time.
The company then starts a final memory-clearing campaign. The community will be rendered unable to fully know what actually happened, sometimes even going as far as to use law to be sure that no one can disclose the full picture by force-handing the actual victims into silence.

Obviously any new tire fire is different, but I expect them to more-or-less follow this same script. And with that behind us, let's move on to...
A Bastard's explanation (yep, that's me)
I know that what will follow will be seen as evil by some users. ""Never assume ill intent"" they will say.
Yet let me also tell you that there is an old saying that goes like ""Once is ingenuity, twice is stupidity, three times is malice"" or, if you prefer another version, Hotoke no kao mo sando - ""Even with a Buddha nature (you can forgive) only three times"".
With that said, feel free to downvote the following if you wish, but I will try to explain what all of this feels like and why I think history keeps repeating itself.
Assumption #1: the attempt to make problematic posts less visible is deliberate
First of all, let's start with a basic assumption: the company knows in advance what topics will cause backlash. It is quite evident from how they are presented. Why is there no secrecy involved when they announce some new feature they are proud of, or when the company makes some donation to charity? At the same time, things like unilateral changes to existing content licensing are posted without any attempt to actually make them visible and followed by a total silence while waiting for the bigger flames to go down.
Assumption #2: the actual motivations are never the ones being told
Let's go a little further. We know that the company knows that whatever they are going to post is problematic. But how can they be so sure that it will be problematic?
There are only two possible answers:

The issue can be easily misunderstood, but if that is the case I would expect that instead of closing up into silence you would want to try to clear up confusion. Why keep your users angry if you really think that you can agree?
The issue is clearly going against the will of most users, either by removing their agency to moderate content, by shoehorning unwanted content on them, or other similar things.

Since I don't think the company is stupid I will have to exclude the first irrational behavior. That leaves us with the second one.
Assumption #3: the company already knows in advance how the users will react and then try to act surprised when it goes that way
This is just a direct consequence of what we just said and is confirmed by the fact that the scripted non-apology post will usually contain some carefully written lines to look surprised, like ""We didn't expect this"" or even better ""We didn't expect we (== you) would actually escalate to this"".
You can see where this is going.
And a Tin Foil Hat one: the hidden agenda
By this point I have to admit that all so far gives a fairly bleak picture.
Thinking back at how Monica was picked out and slandered on a news site, thinking about how the company apologized for that only to do that again now, and looking at how users now even have to say that ""actually they never promised to not slander user groups anymore, only individuals"".

I can not reasonably avoid seeing some form of actual malice at work here: it is my blunt conclusion that none of these changes were actually made in the interest of improving the site content or the user experience.
What I see instead is a reiterated attempt at pleasing the stakeholders in the worst ways possible.
The Monica case was never resolved, and still today it looks like Monica was just a carefully picked scapegoat that the company decided to use to get some free advertisement in an attempt to present itself as caring for the rights of the LGBT+ community that not only backfired on them but also on the ones it was supposed to protect by further fueling rage and abuse.
Years later we now had to resort once again to a new moderation strike, and once again we see the company name-calling its mods to put the blame on them. Once again we see them post multiple inaccurate representations of mods' actions on the Internet to shame them and circulate the message that ""The company is improving even if some (bad) mods are trying to fight back"". And I admit that I went as far as to expect someone to be used as the scapegoat again to be the new Monica.
Sadly, I don't think that I am just hallucinating things as the feeling that these actions are part of a hidden agenda that not only is willing to go against the users for the sake of profit but is also quite open to publicly shame and even sacrifice them, seems to be quite a shared sentiment nowadays based on the comments I read on the site. Promises are usually made to stop the fighting but personally I find it rather unclear whether those are actual concession the company had to make, or just planned eye-candy, smoke and mirrors, used to make the userbase yield and accept the ""better than nothing"" resolution.
Also it is not unusual for the company to hide themselves behind grammatical technicalities worth of the ""Evil Overlord"" manual: after all, after the Monica scandal they just promised to never again slander an individual on the Internet, so slandering all the moderators is fine, right?
Conclusion
Over the course of the last years, the company has made their moves to show off how nice they are, how they care about defending others, how they work on social issues. Things like the Be Nice policy, revising how new users are guided in their first steps... all great things. On paper.
Yet, in the current scenario I can't see them as anything other than empty actions that didn't actually come from the heart but just from a need to ""show off"", to get media to talk about how Stack is doing the right thing, to win more users -> more ads views -> more money.
At the same time the userbase is portrayed as the enemy, whose toxicity causes nightmares, and who makes newcomers feel unwanted and leave.
I'll ask you a question...
Have you ever thought about the nightmares Monica probably had? Ever considered the users that went off the site after each of these scandals to never return? Ever listened to the mods asking you to not be toxic to them?
Once again, I ask you to stop and reconsider. You can work with the users and you can choose to make actual improvements together. The media awareness that you are ""good"" needs to be an effect of your good actions, not the target that you have to reach by any means by faking things ‚Äî then happy users will suggest your site to their friends. Currently, the only thing I can suggest is to never get involved with an actual account here.
You probably still have time. But I fear that the candle is reaching its end.",,,
comment_on_answer,1300737,389871,256777.0,Stephan Kolassa,69,2023-06-06 14:15:28,"+1, though you forgot the part about announcing stuff on major holidays, like the present fiasco. Or like kicking a Mi Yodeya mod in the face on a major Jewish holy day. I could understand nobody at SO knowing about Jewish festivals. What I don't understand is launching predictably controversial policies on a major US and CA holiday.",,,
comment_on_answer,1300738,389871,359939.0,MaxD,1,2023-06-06 14:18:41,"I have to admit that imagining elusive stakeholders sitting on some mega yacht in the bahamas and demanding this and that without even having visited SE once in their life is a solacing thought. At least, much better than all these recent decisions being made by the company itself.",,,
comment_on_answer,1300788,389871,273494.0,ColleenV,35,2023-06-06 17:33:42,"I was going to log out and not look back, but I had to upvote this. The comment about announcing on a holiday made me also remember Chipps' comment about ""shipping on a Friday"". This latest iteration has made me realize I'm still bitterly disappointed about what went down in 2019. I desperately wish we could just roll back the clock to when ""Be Nice"" was an accurate summary of the CoC and the biggest controversy I had to deal with was trying to get people to stop tagging everything ""grammar"" on ELL. (Yeah, I lost that battle but it didn't crush my spirit like this crap does).",,,
comment_on_answer,1301043,389871,165773.0,gnat,6,2023-06-07 15:06:02,"this time, hidden agenda is probably to transform the site into ChatGPT frontend",,,
comment_on_answer,1301078,389871,189401.0,Ian Kemp - SE killed by LLMs,4,2023-06-07 19:23:55,"@ColleenV ""Be nice"" was the start of the slippery slope that led us to this point.",,,
comment_on_answer,1301180,389871,273494.0,ColleenV,0,2023-06-08 01:17:48,@IanKemp I wasn‚Äôt asserting an opinion about whether it was a good thing that the policy could be summed up that way. I was just remarking on how far back my nostalgia would like to go.,,,
comment_on_answer,1301208,389871,256878.0,Janus Bahs Jacquet,18,2023-06-08 02:53:37,"No downvotes here. I think it‚Äôs been fairly obvious in several of these SE scandals that malice cannot be doubted, and that the true goal of SE is precisely the opposite of what they start out touting. In the Monica case, the CoC was deliberately written in an absurd way they knew would cause a furore and backlash against LGBTQ+ users, driving in a flurry of new users, which increased revenue. Currently, a network full of AI-generated posts created by AI-driven bots is exactly what they want because, again, it provides an influx of new users and increases revenue.",,,
comment_on_answer,1301405,389871,314868.0,miken32,2,2023-06-08 19:13:25,"Given all the flood of AI-centric blog posts from the company, and capitalists' well-known disregard for long-term care of their holdings, I agree this doesn't seem like much of a ""hidden"" agenda.",,,
comment_on_answer,1301424,389871,134001.0,Mason Wheeler,10,2023-06-08 20:43:00,"@StephanKolassa ""I could understand nobody at SO knowing about Jewish festivals.""  I couldn't.  Not when Joel Spolsky (an outspoken Jew) was still with the company at the time.",,,
comment_on_answer,1302131,389871,553015.0,polfosol ‡∞†_‡∞†,2,2023-06-11 11:55:17,"Now that I think about SE's actions in the past 3-4 years and how insanely illogical they were, it reminded me of a popular saying in our country that even if our leaders intentionally planned to destroy this country, they couldn't do it more perfectly than what they have already done.",,,
comment_on_answer,1304139,389871,171199.0,Íì¢PArcheon,0,2023-06-21 07:50:10,"@JanusBahsJacquet I would NOT say that the CoC was crafted to cause backslash against LGBTQ+ users, but the golden opportunity of picking out a public example to hang in the main plaza like they used to do with pirates in the old day seemed a very careful planned act. Stir a mess with a poorly written policy, cherry pick a victim and then call in media coverage to present themselves as the ones who discovered  this bad actor and are taking serious measures against them.... All of that looks like it was too much of a luscious opportunity to sit out.",,,
comment_on_answer,1304162,389871,256878.0,Janus Bahs Jacquet,3,2023-06-21 08:35:48,"@SPArcheon I don‚Äôt think it was done in deliberate malice towards the LGBTQ+ community specifically ‚Äì that is, I don‚Äôt think hurting the LGBTQ+ community was the goal. But I do think they deliberately looked for a topic they knew would easily become highly inflammatory and had potential to draw in a massive crowd of reactionists, and trans rights and pronouns fit that bill to a T. The fact that it ended up being hugely detrimental to LGBTQ+ users was just immaterial to them.",,,
answer,389850,389834,160917.0,D.W.,172,2023-06-05 21:33:31,"As a moderator, I don't think I've ever used an automated GPT detector when investigating flags from users highlighting potential uses of AI to generate answers.  And yet, my moderation practices are now all banned by the new SE polices.  This makes no sense to me.
The false positive rate of automated GPT detectors is irrelevant if I don't use them.  I don't understand why I'm prohibited from using practices that don't ever involve any use of any automated GPT detector, ever.  A high false positive rate would be a reasonable basis for prohibiting mods from using automated GPT detectors; but it is not a reasonable basis for the current policy, which goes far beyond that.  I shared this feedback with the company privately as soon as Stack Exchange informed moderators of this new policy, and I have not yet seen a response.
I remain dissatisfied both with the process of rolling out the new rules, and the substance of the new rules.
",,,
comment_on_answer,1300764,389850,260073.0,NoDataDumpNoContribution,2,2023-06-06 15:53:41,"""users highlighting potential uses of AI to generate answers"" Could it be that these users used GPT detectors to highlight the potential uses? Then, while not directly using them, you could still have been biased towards false positive detector results. Just saying, I don't think it's a big problem. It's good to see that so many mods actually didn't use the detectors, so it will be interesting to see if the company can maybe come up with a different explanation for their abrupt policy change one week ago.",,,
comment_on_answer,1300774,389850,160917.0,D.W.,0,2023-06-06 16:42:54,"@Trilarion, yes, it's certainly possible!",,,
comment_on_answer,1302647,389850,212479.0,goldilocks,3,2023-06-13 15:06:07,"Isn't this then about the right/imperative to delete content not because it is incorrect, inappropriate, offensive, or plagarized, but simply because you don't like the idea of AI doing a task you think only live people should do?  It looks to me like the debate has been obfuscated because that is a more tenuous position than debating whether or not AI detection tools work, which implies that if it could be proven then everyone would be copacetic about weeding out the evil AIs amongst us.",,,
comment_on_answer,1302822,389850,160917.0,D.W.,3,2023-06-14 06:59:28,"@goldilocks, No, that is not what this is about.  The rationale has been well explained in other locations, and I can't put it any better than it has been explained there, e.g., stackoverflow.com/help/gpt-policy, meta.stackoverflow.com/q/421831/781723, meta.stackexchange.com/q/389811/160917, meta.stackexchange.com/q/384922/160917",,,
answer,389849,389834,205798.0,S&#233;bastien Renauld,135,2023-06-05 21:06:34,"We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions. People with original questions and answers were summarily suspended from participating on the platform. We stand by our decision to require that moderators stop using that tool. We will note that it appears to be very rare, however, for mods to use ONLY the ChatGPT detection tool, and frequently their own analyses were in use as well. We will continue to look for other, more reasonable tools and are committed to rapid testing of those tools and any suggested heuristic indicators.

So, share the data. You obviously have it, and you obviously have it tagged, if you've gone through impact analysis on it. What are you waiting for?
At this point, it's the third time that I've heard in a week that there's an ""unacceptably high false positive rate"" without ever hearing:

What the rate was before ChatGPT went mainstream
What the rate is today
How you know that these suspensions were made by using a tool
Standard statistics values (r2, etc.) to assess correlation

So far, there's been a lot of ""moderators bad"" and very little quantitative data for mods to even consider or try to see your side. You've provided unquantifiable, unqualified hearsay, which, if I'm not mistaken, is in breach of your own Code of Conduct.
Like, I don't want to be mean or anything, but the intended reaction to this repeated exposure to unsubstantiated statements that aren't even remotely verifiable has a name: Illusory truth effect",,,
comment_on_answer,1300571,389849,152515.0,doppelgreener,25,2023-06-05 21:08:46,The accuracy is even beside the point: the moderators haven't been relying on them at all.,,,
comment_on_answer,1300572,389849,205798.0,S&#233;bastien Renauld,4,2023-06-05 21:09:30,"@doppelgreener I know, but the claim was made. SE, through Philippe, said that they went and actually did enough in-depth analysis to figure out that there is a correlation - so they have this value at hand.",,,
comment_on_answer,1300578,389849,256777.0,Stephan Kolassa,48,2023-06-05 21:26:32,"Now, if we just had a site full of statistics experts that might be able to assist in the analysis of such a dataset, because, y'know, analysis of data with iffy provenance (like ChatGPT users trying to camouflage what they are doing) is not exactly trivial...",,,
comment_on_answer,1300740,389849,63550.0,This_is_NOT_a_forum,0,2023-06-06 14:22:31,What is that r^2 thing? Coefficient of determination? Pearson correlation coefficient?,,,
comment_on_answer,1300920,389849,341383.0,Daniel R. Collins,1,2023-06-07 00:01:32,@This_is_NOT_a_forum: Isn't the latter just r?,,,
comment_on_answer,1300930,389849,212647.0,user1937198,3,2023-06-07 02:37:47,@StephanKolassa Or indeed a site full of experts in data analysis and machine learning,,,
comment_on_answer,1302376,389849,163632.0,WGroleau,0,2023-06-12 13:54:39,"""How you know that these suspensions were made by using a tool"" ‚Äî and how they ""know"" that those suspended were false positives from the tool.",,,
answer,389878,389834,273494.0,ColleenV,109,2023-06-06 15:57:16,"I came across the news of the strike on a different site, and I thought I could resist pointing out that the company is making exactly the same mistakes it made in 2019, but I can't. I'm probably wasting my breath, because I tried to make these points in 2019 when I was a mod. Maybe repeating them will help.

Stop making official policy statements off the cuff in the Teacher's Lounge. That chat room should be for mods to get support from each other and the company, not for official company policy setting. Not every moderator participates in that chat room and chat messages are inherently a terrible channel for official announcements.

The company should make it clear that participating in chat is optional, and that mods who don't will still be included when discussing and distributing official company policy.

Stop making unsupported assertions disparaging volunteer moderators in the press. Surely you can talk about what you believe is good for the future of the company without throwing the volunteers who made Stack Exchange the success it is today under the bus.

The data behind the assertions that new users were being unfairly suspended by moderators should be made public, or the assertion should be retracted and apologized for.

Do not unfeature posts on site metas. It doesn't help contain or stabilize the situation; It just makes people angrier and more frustrated.

There should be a process that's followed prior to staff reversing the actions of site moderators and the first step should be a conversation with the moderators.

Stop treating volunteer moderators like they work for the company. Site moderators are elected representatives of their communities, not extra labor that can be directed to achieve the company's goals. They know what their communities need to stay healthy, and rightly prioritize that.

The company should not be dictating policies intended to prevent moderators from using their judgment to do what is best for their communities. Either the mods can be trusted or they can't. If the company can't persuade the experts that a course of action is good for their community, maybe it's a bad idea.
A few parting thoughts
The company does not act like they value the expertise and dedication of the volunteer moderators as a whole. Individual staff may be friendly with individual moderators, but that does not translate into the company including the community and their elected moderators as partners in business decisions that impact them. Many of the veteran moderators are as (if not more) invested in the success of Stack Exchange as the shareholders and management.
Maybe moderators should join together in a formal independent organization that can speak with one voice to the company for its members. That might make it easier for the company to hear their advice on various policy decisions before things escalate.",,,
comment_on_answer,1300937,389878,275243.0,Kevin,15,2023-06-07 03:33:38,IMHO any mod who does not regularly participate in the TL should simply continue to adhere to the public version of the policy as if the non-public version does not exist. Let the company explain why this is problematic.,,,
comment_on_answer,1300987,389878,153008.0,Cody Gray,6,2023-06-07 10:06:29,"The official (private) announcement is on the Moderator Team (an instance of the ""Stack Overflow for Teams"" product, with access restricted to staff and diamond moderators), not in chat. There have been many official policy statements made off the cuff in TL, but this main one is documented on the Mod Team. It is, of course, unclear whether participation in the Mod Team is a requirement for moderators, just as it remains unclear whether participation in chat is a requirement. Then again, those of us who are involved aren't interested in rules-lawyering this. We just want to be reasonable.",,,
comment_on_answer,1300992,389878,273494.0,ColleenV,1,2023-06-07 10:23:15,"@CodyGray-onstrike Thanks for the correction. I‚Äôm not sure which post led me to believe it was the Teacher‚Äôs Lounge again. The Mod Team is a fine place for policy discussion because you don‚Äôt have to be in the Eastern time zone to have a chance to be involved in the discussion, and if you aren‚Äôt a native English speaker, you can read at your own pace. Chat is for hanging out and getting immediate help with something.",,,
comment_on_answer,1301063,389878,161792.0,msh210,1,2023-06-07 16:45:31,"""Stack Exchange, Inc. agrees that it will: ‚Ä¶ Get your explicit written permission before commenting to any media (including media outlets controlled by Stack Exchange Inc.) or independent reporters about you or your moderator actions as per our Press Policy.""",,,
comment_on_answer,1301075,389878,273494.0,ColleenV,1,2023-06-07 18:44:37,"@msh210 Moderators can not sue for defamation if they are smeared as a group. That agreement is for individuals. And saying a group is in general incompetent doesn't really rise to that level regardless. It's just disrespectful and indicates that there's either a serious disconnect between reality and someone's perception of it, or someone thought blaming mods for the company's failure to manage the situation was going to be the easy way out.",,,
comment_on_answer,1301108,389878,161792.0,msh210,0,2023-06-07 20:45:04,"@ColleenV suing for defamation has nothing to do with the moderator agreement: I mean, one could sue for defamation even if the agreement didn't exist. The agreement goes beyond that and says SE will‚Ä¶ well, no point in quoting it again. It's in my previous comment. I don't see anything in that clause about such newsmongering being disallowed only if names are mentioned.",,,
comment_on_answer,1301184,389878,273494.0,ColleenV,1,2023-06-08 01:28:10,"@msh210 The reason that clause exists is because SE was getting sued/taken to arbitration. Regardless, the press policy has no indication of what recourse moderators have if it is violated. You‚Äôll have to go through the arbitration process to find out I suppose. Since I‚Äôm no longer that active here, I have not been keeping up with changes to the legalese.It says‚Ä¶ clear directives in place to not speak about individual Stack Exchange/Overflow network moderators or users without the express written permission of the user.",,,
comment_on_answer,1305108,389878,307622.0,Wildcard,0,2023-06-25 16:26:29,"@Kevin why limit this to mods who haven't been regularly active in TL?  Seems to me that ALL mods should simply follow the publicly stated policy, and ignore any secret policies to the contrary.",,,
answer,389851,389834,1438.0,Jon Ericson,74,2023-06-05 21:48:07,"Apparently people have been upvoting spam. I don't know if this is an isolated thing or a coordinated effort, but it's not at all helpful. Indeed, I'd suggest that CMs consider warning and (if not heeded) suspending people who upvote obvious spam. It's functionally the same as a voting ring after all. Personally I find that behavior counter-productive to the reasons I signed the letter.
I got to thinking about voting rings because they present similar problems to detecting machine-generated content. It's less of a binary switch and more of a Bayesian inference. My memory might be fuzzy, but here's how voting ring investigations typically went down:

A user would flag posts that seem to be getting more upvotes than expected.
A moderator would see that flag and look into the situation using moderator tools built into the site. They'd also bring experience and past history into their judgements.
If the moderator thought it worth more investigation, they'd contact a CM to (potentially) invalidate votes.
We'd use a variety of tools and techniques passed on from one CM to another (thanks Shog and Tim!) to make a final determination.
If, in our judgment, voting fraud had taken place, we'd invalidate some votes and message the users we suspected of being in the ring.
The users would deny that they'd done what we said they did.

Each step would increase or decrease confidence that voting fraud had happened. For instance, an overly-aggressive flagger might decrease our estimate of the odds because they cry wolf so often. In my experience, moderators usually identified voting rings accurately, so when they brought one to my attention, it raised my estimate considerably. Some of the tools were extremely reliable and others weren't worth listening to most of the time. You learned to make these evaluations only through experience.
I remember one time we'd caught a pair of users dead-to-rights. One of the users (we'll call them A) said they had no idea what had happened. The other user (B) confessed that they were married to A, saw that A's posts were getting downvoted and upvoted all of A's posts to help them feel better. Now. That's a textbook voting ring, but I wanted to give that couple a hug and let them off the hook. We invalidated the votes anyway and told B to maybe try something else to cheer up A.
We'd also see things like two experts in a specific technology upvoting each other's posts. If we just used the voting fraud tools, we'd be compelled to suspend them. Another time we applied one of our tools to employees voting on Meta and found that the voting ring was coming from inside the house! Since we didn't just blindly do what the voting fraud tools recommended, it was an inside joke rather than a soul-searching investigation. Context matters so much!

We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions. People with original questions and answers were summarily suspended from participating on the platform.

One of the things that has made this issue go from 0 to 100 in a week is that we haven't seen any details of this analysis. Like the vote fraud tools I just mentioned, false positives are not surprising if used in an inappropriate context. In my experimentation with GPT and GPT detectors, I found that my own original writing could be flagged as likely machine generated. So that's not news.
What would be news is if we could see evidence of moderators blindly using GPT detectors without other signals to make their decisions. That sort of behavior is not unheard of, but its rare on Stack Exchange sites. Moderators here tend to be extremely diligent. Given the volume of flags, mistakes are inevitable, but most moderators are quick to own up to them when confronted. That's one of my priors that makes me suspicious of the analysis even before it's made public.
The final sentence about ""original questions and answers"" also raises red flags for me. I guess what bugs me is that if your standard is ""original"" you can't go far wrong with machine-generated content. How many times have you searched for something (recipes are particular offenders), found a promising page and then scroll (and scroll) until you find the actual information you need? (I get it! You spent a summer in Tuscany and that's how you know so much about spaghetti carbonara.) Since it's so easy to generate reams and reams of verbiage using ChatGPT, ""original"" seems to skew the playing field away from (most) humans.
I don't know if this is intentional, but the most recent CEO blog post (CEO Update: Paving the road forward with AI and community at the center) seems to argue that people in the community serve AI rather than the other way around:

Our community has given us feedback through the evolution of this tool, and their feedback is critical to how it scales. As the AI landscape continues to evolve, the need for communities that can nurture, inform, and challenge these technologies becomes paramount. These platforms will not only offer the necessary guidance to refine AI algorithms and models but also serve as a space for healthy debate and exchange of ideas, fostering the spirit of innovation and pushing the boundaries of what AI can accomplish.

The words are fine, but in the context of disagreement between moderators and the company about how to moderate machine-generated content, it sounds dismissive. It's as if the company believe it would be making great strides in technological development if only those pesky humans would get on board. Or maybe I'm being unfair and this is just an ""AI meets community"" pitch. (I suppose I'm not the audience for the CEO's blog, though.)
I agree that one value of communities is improving a product. But that doesn't happen if the community isn't free to reject the product or wait until it's reached some level of maturity. When the community signals that ""original"" content isn't enough, it doesn't do the product any good to ignore that signal. Because with few exceptions, the people who curate content on Stack Overflow also consume it.",,,
comment_on_answer,1300595,389851,186281.0,Andy,9,2023-06-05 23:17:03,"I have been traveling most of the day so haven't been paying attention to spam today, but unfortunately up votes to spam aren't entirely uncommon. They usually just get removed fast enough via flags that it doesn't matter.",,,
comment_on_answer,1300601,389851,1438.0,Jon Ericson,0,2023-06-05 23:53:48,"@Andy: That, unfortunately, isn't surprising. It is hard to determine whether voters are confused, malicious or just random. (I don't have first-hand knowledge either.)",,,
comment_on_answer,1300614,389851,275243.0,Kevin,2,2023-06-06 01:25:06,"I would tend to imagine that the spammers who care are also operating voting rings, or will soon be doing so, because now they know that 90% of the network's anti-spam tech (SmokeDetector etc.) is offline. Who's going to  stop them?",,,
comment_on_answer,1300636,389851,169312.0,tripleee,0,2023-06-06 04:59:52,"Please let's not overload ""spam"" to deviate from the strict definition we use on the site itself; unsolicited promotion (of products, services, religious beliefs, mathematical ""proofs"", conspiracy theories, etc etc)",,,
comment_on_answer,1300734,389851,63550.0,This_is_NOT_a_forum,1,2023-06-06 14:11:42,@tripleee: What word should be used instead (not a rhetorical question)?,,,
comment_on_answer,1300739,389851,169312.0,tripleee,2,2023-06-06 14:21:03,"@This_is_NOT_a_forum I guess Jon means ""AI-generated content"" in this instance. More generally, content which is disruptive can be trolling, rude, abusive, off-topic, or just annoying for other reasons. Perhaps I would suggest ""disruptive content"" as a collective term for all of these phenomena, but it's also possible that Jon means something else here.",,,
comment_on_answer,1300757,389851,1438.0,Jon Ericson,3,2023-06-06 15:22:42,"@tripleee: I'm talking about literal spam that CMs needed to delete. It's a natural consequence of the strike that spam will sit around longer than normal, but it's not helping anyone to encourage it in any way.",,,
comment_on_answer,1300759,389851,169312.0,tripleee,2,2023-06-06 15:27:32,Thanks for clarifying. It was not obvious to me how upvotes on spam were pertinent to this particular question but I think I see now.,,,
comment_on_answer,1301023,389851,1135948.0,kaya3,1,2023-06-07 13:44:56,"Upvoting spam in protest is definitely a misuse of the voting system, but addressing misuse of the site's features is a moderation task (e.g. warning or suspending users). So I would encourage mods who are on strike from performing moderation tasks to not act on this until the strike is over. (I would also encourage these voters ‚îÄ if they are indeed doing it as a protest ‚îÄ to cease doing so, because it doesn't really harm SE, Inc. in any way for spam posts to receive upvotes, what harms them is for spam posts themselves to go unmoderated.)",,,
answer,389867,389834,219289.0,ouflak,71,2023-06-06 09:09:42,"
We stand by our decision to require that moderators stop using that tool.

On the site I moderate, a perfectly well written, but entirely incorrect, answer can literally ruin the lives of anyone who decides to follow that misleading information. I have seen this happen on another immigration site that I've been highly active on. I should be able to use any tool whatsoever to prevent that kind of disaster from happening. If Stack Exchange has a problem with this kind of responsibility, maybe it would be best if they simply shut Expats down.
And there are probably a few other sites that they should take a hard look at because of the potential repercussions.
",,,
comment_on_answer,1300681,389867,388243.0,user202729,4,2023-06-06 09:20:16,"I feel this answer is a bit problematic. They're still ""allowing"" deleting incorrect answer and deleting AI-ban, just not allow using the detection tools. (of course the ""internal rules"" is internal, maybe it's more restrictive, I've no idea.)",,,
comment_on_answer,1300682,389867,1372392.0,markalex,8,2023-06-06 09:32:49,"@user202729, I don't know about Expats, but at least at SO, incorrect answers are not deleted (and not even a subject for flagging, such flags are consistently declined), but rather subject for simple downvoting. Technically lying is allowed on network, unless it's political (according to new CoC)",,,
comment_on_answer,1300683,389867,1372392.0,markalex,4,2023-06-06 09:36:04,"@user202729, regarding ""internal rules"": there are no public statements about it, but based on related statements, I will guess that internal announcement prohibited mods from taking any action, regarding AI content unless said content violates other clearly established policies or rules.",,,
comment_on_answer,1300693,389867,153008.0,Cody Gray,39,2023-06-06 11:25:51,"The internal rules are much more restrictive @user202729, to the point where, effectively, we have no grounds for removing content that we strongly believe was generated by an AI. There is one narrow exception that would allow us to delete such posts, but this has not been disclosed publicly, and, in practice, it is meaningless. There is no objection among mods to avoiding the use of ""detector"" tools; in fact, none of the SO mods have ever relied on them. Some of us tried them in the early days after ChatGPT's public release, but determined they were useless. Others never even tried.",,,
comment_on_answer,1300704,389867,171199.0,Íì¢PArcheon,15,2023-06-06 12:32:16,It will be wonderful when we will be forced to leave ai-generated posts live on sites like Medical Science...,,,
comment_on_answer,1301024,389867,1135948.0,kaya3,8,2023-06-07 13:49:33,"@user202729 Incorrect posts aren't supposed to be deleted in most cases; they're supposed to be downvoted. The problem is that AI-written answers fool enough users that the voting system often rewards instead of penalising them, regardless of their actual correctness. Mods are not supposed to be subject-matter experts, and are not generally expected to be able to judge the correctness of a post. Also, deletion is not enough to deal with a flood of superficially-good-looking nonsense from AIs, the users doing this need to be suspended; but users can't be suspended for making incorrect posts.",,,
comment_on_answer,1302608,389867,227257.0,jwenting,0,2023-06-13 09:42:17,"@user202729 the new rules implicitly disallow the deletion of any AI generated content, no matter the reason...",,,
comment_on_answer,1302611,389867,219289.0,ouflak,4,2023-06-13 09:56:03,"@kaya3 and jwenting, The problem for sites like Expats, and maybe a few other sites like the aforementioned Medical Science, and perhaps Finance, Information Security, Interpersonal Skills, Home Improvement, ...probably several others... is that leaving incorrect information - especially perfectly formatted/written - can mislead readers into making disastrous decisions. Not everybody who visits the site will understand (or ever care to understand) the voting system and what it means. And we can't assume anybody reads the comments.",,,
comment_on_answer,1303066,389867,282296.0,Mario Carneiro,4,2023-06-15 07:11:41,"TBH I have seen this pattern a lot of late. ""It's probably fine for Underwater-Basketweaving.SE, but it's definitely not okay here on Drupal.SE"".... and then later someone from Underwater-Basketweaving.SE chimes in pointing out that it's super important not to leave these AI-generated answers up because of the consequences. The simple conclusion is that everyone wants correctness in SE answers, on every site. If you think Philosophy is exempt, or Parenting, or Academia, or SO for that matter, you just don't know enough about that site.",,,
answer,389838,389834,997587.0,starball,60,2023-06-05 18:59:39,"There's plenty to be dissatisfied with, but I've raised what I have to raise about that already. So I'm going to try to put on my ""Pollyanna hat"" here. Update from future me: You're making it pretty hard for me to keep the hat on.

We will continue to look for other, more reasonable tools and are committed to rapid testing of those tools and any suggested heuristic indicators.

Will you be making the mods part of that work? I'm sure they'd have much of value to share (Ex. @sideshowbarker (see also their post here)). Other community members also come to mind (Ex. @NotTheDr01ds (see also their posts here, here, here, here, here, and here)). (This doesn't have to be a public conversation- if I understand correctly, we've been trying to avoid showing the people violating the policy how we sniff their violations out).

The Community Management team is evaluating the current situation and we‚Äôre working hard to stabilize things in the short term.

I'm thankful that the CMs are picking up on some of the moderation work during the strike (Ex. @Yaakov) on top of their other work. I keep needing to mentally remind myself not to shoot the messengers (or anyone for that matter). A nice side-effect we might see here from the CMs dogfooding is some empathy for pain points in mod tooling. Maybe something nice will come out of that.

We‚Äôll be working collaboratively with the community on the long-term solution.

That's good to hear. I look forward to it. When will we hear more on this? (Please also don't forget about the questions we've asked about the new policy).",,,
answer,389857,389834,616624.0,Adrian Mole,53,2023-06-06 04:58:50,"
The Community Management team is evaluating the current situation and we‚Äôre working hard to stabilize things in the short term.

If, by ""short-term stabilization,"" you mean ending the moderators' and curators' strike, then the solution is relatively simple: Just apologize ‚Äì publicly and unreservedly ‚Äì for the confusing and insulting manner in which this so-called policy change was announced: privately (to the moderators) and publicly (in a way that was at odds with the private announcement).

I regret that actions have progressed to this point.

Although this may be considered the seed of a beginning of a vague apology, it simply doesn't go far enough. Also, it carries an implicit hint that the moderator team has played a significant part in creating this mess ‚Äì which it hasn't.

We‚Äôll be working collaboratively with the community on the long-term solution.

This ""community collaboration"" should have been present from the get-go (as it was when first implementing the ban on AI-generated content). Maybe it is now time to hit the ""rewind"" button and ask for suggestions on how to address the (unsurprising) ""large upswing"" in account suspensions.
In the meantime, restore the moderators' rights to use suspensions (the vast majority of which, I gather, have been for periods of seven days or shorter). You (the staff) need to trust your moderators to not issue suspensions (of any length) trivially and without full consideration. In the longer term, there may be a way to avoid such suspensions by using and/or fine-tuning the in-built ""answer ban"" system, instead; from what I understand about that (the details of its algorithms are, understandably, kept secret), this can actually work out to be a more effective ""blocking tool"" than a suspension, as it is: (a) potentially for an unlimited time period; and (b) covers all posts from a given IP address. And we certainly need some sort of block on the vast majority of AI-generated gibberish that gets posted on our network.
",,,
comment_on_answer,1300692,389857,153008.0,Cody Gray,25,2023-06-06 11:22:00,"Some SO mods were originally (in early days, say Dec 2022 ‚Äì Jan 2023) issuing suspensions for 30 days, consistent with site policy as set by staff and endorsed by Phillippe. We discussed this internally, and decided that it was too steep, so we ramped it down to 7 days (the normal duration for a first-time suspension). We'd even been discussing internally not suspending at all for first offense and simply sending a warning‚Äîand would have been more than willing to start doing this all the time‚Äîwhen this edict was handed down. Staff didn't discuss with us.",,,
comment_on_answer,1300762,389857,189401.0,Ian Kemp - SE killed by LLMs,6,2023-06-06 15:44:01,Apology alone isn't enough. Things need to change to rebuild trust.,,,
comment_on_answer,1300769,389857,616624.0,Adrian Mole,0,2023-06-06 16:06:09,"@IanKemp The first part of my last paragraph addressed that, partially.",,,
answer,389854,389834,1142965.0,Starship,46,2023-06-05 22:48:47,"
People with original questions and answers were summarily suspended from participating on the platform.

You still are yet to give a single example. Wow, that gives this all a ton of credibility.
UPDATE:You have given some data, but I see no reason to think that it is realiable. I concur with others complaints on the post and won't restate them here.
",,,
comment_on_answer,1300732,389854,63550.0,This_is_NOT_a_forum,0,2023-06-06 13:56:03,There was an example on MSO where someone claimed that. In all fairness that MSO question ought to be found. I don't remember if the claim was substantiated or not.,,,
comment_on_answer,1300766,389854,260073.0,NoDataDumpNoContribution,2,2023-06-06 16:01:18,@This_is_NOT_a_forum Do you mean Why was my answer deleted for using ChatGPT even when I didn't??,,,
comment_on_answer,1300767,389854,1142965.0,Starship,2,2023-06-06 16:02:37,"Oh, one example, that no one can even confirm is really true. Well, that makes it all okay @Trilarion",,,
comment_on_answer,1300768,389854,260073.0,NoDataDumpNoContribution,3,2023-06-06 16:05:01,@Starship-OnStrike No need to be picky. I just try to be helpful. You probably know as well that the absence of evidence is not the evidence of absence.,,,
comment_on_answer,1300776,389854,1142965.0,Starship,5,2023-06-06 16:50:39,"Okay, fair point, I'm ust saying that the absence of evidence contributes to the absence of trust @Trilarion",,,
comment_on_answer,1300784,389854,260073.0,NoDataDumpNoContribution,2,2023-06-06 17:25:38,Fully agreed. The company claims a connection somehow. It's their duty to provide the proof. I hope they come around and eventually see the light.,,,
comment_on_answer,1301076,389854,395778.0,BryKKan,0,2023-06-07 18:51:24,"@Trilarion While most of us understand this to be about a much larger moderation issue, the official explanation focuses on the supposed problem of moderator tools regularly leading to such erroneous deletions. Do you have any reason to believe a false positive result led to the issue with this case? From what I read, it was not distinguishable from regular human error. It is possibly an example of overzealous moderation against potentially generated content, but since Philippe didn't actually address that level of policy, it's almost pointless to ponder. Still, good share.",,,
answer,389853,389834,,user393600,43,2023-06-05 22:35:47,"Which other groups‚Äô interests are missing from this post?
In many complex subjects a number of constituencies need to be considered.
From this post, one can identify the following groups/interests:

moderators

users that are, correctly, or possibly incorrectly, flagged as having gone against the rules.

implicitly Stack Exchange, Inc. corporate interests.  While others may want to dismiss those I will say that, for all the complaints, the family of Stack¬†Exchange sites have been of tremendous value to professionals and hobbyists all around.  Second, a corporation that does not have a plan to make money, or at least fund itself according to expectations, risks disappearing or takeover.


However two other groups are missing and are very much impacted by this policy:
First, users that come to SE looking for answers to a problem that they have.
Stack Overflow, while sometimes criticized for fostering cut and paste programming, generally fits the bill.  Some primary ways to judge the quality of answers are:  your own knowledge, the up down votes, the presentation of an answer, along with supporting quotes and program outputs and the poster's reputation.  Even if the poster is not the most competent on the subject, a user can assume repeat research and posting will gradually have improved their knowledge.
With AI allowing cheaply-produced, but perfectly worded answers, neither the presentation, nor the poster's reputation has any great meaning, leaving the user to their own to judge how helpful an answer is liable to be, except for community upvotes which can be swayed by confidence and presentation, something generative AI excels at.
Respectfully, that constituency is not benefiting in the least from your proposed hands-off approach.
And, much more so than just the moderators, if regular users cease to see Stack¬†Overflow as a valid source of information, they will go elsewhere.
Second, users that answer questions.
Their motivation may vary from reputation seeking, interest, evangelism, desire to help, challenge, pursuit of professional credibility.
They decide to join SE sites and ""grind"" their way up, by answering question after question.
How is that group likely to react to a situation where they are systematically pre-empted by people who can write up a complex and perfectly-formatted answer - that they often don't really understand and don't bother vetting - in 5 minutes or less?  While it takes even a knowledgeable person 3x the time to write up a concise answer, with some minimal code and showing output?
Like the first group, it is quite possible they will not bother.  And without a solid core of them, there is no site.
Though it is a very imperfect comparison, I would note that schools that have, for whatever reason, taken a relaxed attitude towards cheating, and academic standards in general often end up devalued as a result:  in the eyes of prospective students, and in those of prospective employers.
Generative AI content is going to be a big challenge, for this site, and others.  You have indicated concerns with moderator measures as done so far.
Fine, to an extent. Work together on a better solution. But the answer is most certainly not throwing out AI content moderation as a whole.
The striking moderators, to me, ultimately seem to be motivated by looking after users in the largest sense:  regular users posting questions and answers, without using shortcuts, and especially not knowingly using shortcuts with well-known imperfections at the current time.
As a regular, non-moderator, not particularly ""community"" minded, user, I would strongly encourage SE, Inc. to do the same:  do well by your users.
Better said on this answer:
p.s. I intentionally stayed out of considerations about communication issues, perceived or real shortcomings in how moderators were treated, community stewardship, etc‚Ä¶.  I do have my opinions, but I wanted to keep the focus on why the proposed policy is bad for regular users and a better collaborative solution needs to be found.",,,
comment_on_answer,1300733,389853,146043.0,Pointy,11,2023-06-06 13:59:54,"As (primarily) an ""answerer"", I can tell you that it's annoying to have to inspect AI answers. In my experience they are usually wrong or, at best, very generic on the general topic, and of course they have no apparent sensitivity to the particular question or the probable sources of confusion that led to the post. It's also annoying and telling that it's more and more frequent for a question to explicitly include a claim that the person asking first asked ChatGPT. All I can do is downvote, and actually it's not uncommon for people to delete an answer if they honestly didn't know.",,,
comment_on_answer,1300778,389853,,user393600,1,2023-06-06 17:12:45,"@Pointy So, what you are saying is that ChatGPT, as it exists currently, is flawed as an aid to answering questions, even if you are knowledgeable and taking care to correct for its shortcomings?",,,
comment_on_answer,1300779,389853,146043.0,Pointy,1,2023-06-06 17:18:10,"No, that isn't what I meant. In fact if you re-read my comment, I specifically stated that I inspect Chat-like answers. Once or twice in recent memory, the answers were good enough that I didn't downvote even, and simply left a comment linking to the policy page. Most of the time, the answers are simply not good however. Of course I have no way of knowing how much effort the poster expended on verifying the answer, just like with any other answer. All I can do is read the text and use my experience to determine the quality. And for what it's worth I don't downvote answers very often.",,,
comment_on_answer,1300781,389853,146043.0,Pointy,9,2023-06-06 17:20:27,"Furthermore, one of the flaws (in my opinion) with the generated answers is that they're deceptively long. There's a lot of ""fluff"" text. Good long answers (I invite you to look for some T.J. Crowder answers) are packed with information and sensitive to the specifics of the question involved.",,,
comment_on_answer,1300782,389853,,user393600,1,2023-06-06 17:20:41,"Oh, sorry, I thought you had experimented with starting out answers w Chat.",,,
comment_on_answer,1300783,389853,146043.0,Pointy,3,2023-06-06 17:21:59,"Oh gosh I see what you mean now. No, I haven't bothered with that; I meant looking at answers that I ""sniff"" as being ChatGPT, and reading through to see if there's anything worthwhile. I'm not a moderator so I can't ban anybody; all I can do is comment and (sometimes) downvote.",,,
answer,389920,389834,395778.0,BryKKan,36,2023-06-07 13:53:06,"I am not a moderator, and I have no affiliation with any of the moderators - involved here or otherwise. This means I have no access to the ""private policies"" behind this. The upside is, I have no obligation or commitment to non-disclosure. On the other hand, everything to follow is by its nature speculative.
Edit: Update: Since writing this I have read a number of other related meta questions and answers, authored by both community members and staff. I also finally read the moderators' strike letter. Importantly, I have still not seen any ""secret"" materials. Nonetheless, at this time, I feel confident saying I was correct below, regarding the secret policy. SE Inc is very likely preventing moderators from removing posts that violate our community expectations, and harm the health of the community as a whole. Thus I have also since signed in support of their open letter.
From the body of the official ""question"", one might be forgiven for thinking that mods were in an uproar over ""access to a [flawed] tool"". You skillfully framed the issue as a move to protect the community from self-inflicted harm. However, having observed the community reactions to past debacles like this, the story simply isn't credible. Such a massive strike would only be undertaken if the policy issue were truly existential. Something is missing. Even without the other comments here, we might guess what that is: some ""private policy"" which mods feel bound to withhold [but which I'm free to speculate about].
So what is this secret new policy direction? Well, we can actually just read between the lines of the official statement, applying a basic understanding of standard PR tactics. This is clearly a deflection, and those work best to defuse a reaction if they are focused on something ""innocuous"" which is very near to the true subject. This is to avoid a sense of ""narrative novelty"" when people encounter discussions of the ""real"" issue, in hopes they'll dismiss it without consideration as something they've already evaluated. By this reasoning, we might say it likely has something to do with AI generated submissions.
Now the cynic in me comes out, and I ask myself ""Why would SE want to hide this policy shift?"" After all the community issues of the past few years, surely anything so contentious as to prompt mass strike would have been appropriate to discuss openly first? If they're playing the corporate trump card, and trying to gag the mods, then it must surely be rooted in profit motive. So really the question to ask is ""What does SE or it's leadership think they stand to lose (or gain) in this area?""
Bringing this all together, I feel pretty confident hazarding a guess as to the policy, and mindset of the SE side:
Basically, they don't want AI generated content removed at all, unless it's so flagrant as to make the site appear useless.
Their reasoning is likely based in a combination of factors, ranging from fear of direct competition by AI tools to a more straight-forward play to assuage investor concerns about userbase growth. It's also likely they want to feel free to lean into that themselves eventually, and use AI tools to answer questions directly. The cynic in me wonders if they already tried it without telling anyone, but so far I haven't seen anything to suggest it. In any case, from a ""catalog"" management perspective, I'm sure they see having generated answers to orphan questions as better than having none, and more ""active users"" as better than fewer. It's easy to see why they might view moderator efforts to remove AI ""contributions"" as a nuisance to their bottom line.
Again, I could be completely off-base. But if I'm not, this is a serious error on the part of SE, and I hope they recognize this and reverse course in time.
From a business perspective, this move may appear savvy on the surface, but it actally is an act of brutal self-sabotage. The value of SE isn't being the place with all the answers. It's the community. Disregarding it in this way can only erode any long-term value you hope to create in the company. As a ""regular end user"", I'm watching this with an eye towards walking away entirely (and advising everyone I know to do the same).
Whatever is going on, now is the time for honesty and transparency. The idea that mods here are being coerced into hiding any policy at all does not sit well with me. Tread carefully SE.
",,,
comment_on_answer,1301032,389920,261748.0,DavidG,7,2023-06-07 14:11:47,"The cynic in me wonders if they already tried it without telling anyone Yeah, that's not cynical at all. I'm betting half the companies on the planet with a development department have tried spinning up some kind of PoC. Right now there is a huge drive from investors and market analysis agencies to push AI as a tool to be used. I'd be more surprised if SO hadn't tried playing around with it.",,,
comment_on_answer,1301053,389920,776523.0,zcoop98,9,2023-06-07 15:38:13,"My current personal theory is that this truly is more about the user suspension angle than the content side, which feels consistent both with the language in the policy post, as well as Stack the Company's broadly laissez-faire attitude towards improving site content quality. There seems to be a very strong force in the Company right now that is seeing the ""large amounts of user suspensions"" metric and panicking, despite the fact that the suspensions are justified and useful to maintaining the site as a resource that people widely use, which erodes when quality wanes.",,,
comment_on_answer,1301054,389920,776523.0,zcoop98,8,2023-06-07 15:43:50,"I'm imagining that with the influx of AI posts, suspensions went through the roof, in a way that hasn't been seen internally much before, and if someone, let's say someone higher up for sake of argument, sees that metric without understanding the context, without knowing that the suspended users and their content were never authentic in the first place and weren't beneficial to the site, without getting that the removals are a net positive to maintain Stack's ""community trust"", the thing the CEO cites as Stack's biggest asset... that's something I could see causing this debacle.",,,
comment_on_answer,1301061,389920,620700.0,ojchase,7,2023-06-07 16:15:44,"The value of SE isn't being the place with all the answers. As another regular user, I fully agree. My use of this site isn't for its having a lot of content. It's because it has correct answers, experts presenting commentary as needed to fix misconceptions or fill in gaps implied in the question, and a minimum of fluff I have to wade through to get to what I need. AI might sometimes give the right answer, but my overall experience will be degraded.",,,
comment_on_answer,1301062,389920,165773.0,gnat,4,2023-06-07 16:41:05,@DavidG I think moderation strike turned this whole affair into PoC. Because this is exactly how it is going to work: ChatGPT in / content curation out. Because nobody in their sane mind would agree to mode/rate loads of automatically generated content for free,,,
comment_on_answer,1301098,389920,395778.0,BryKKan,0,2023-06-07 20:16:09,"@zcoop98 I don't disagree with you, and I'm certain that corporate misapprehension underlies at least a good part of the sense of fatalism and grim determination to err we see in Philippe's attitude.",,,
comment_on_answer,1301100,389920,395778.0,BryKKan,3,2023-06-07 20:25:00,"@ojchase Thanks for expanding on that specifically, I wasn't sure how to state it positively. You're exactly right. The greatest value of having human experts answer your questions is not getting the answer, but rather having them analyze the question itself for cues to hidden personal knowledge gaps.",,,
comment_on_answer,1301969,389920,377867.0,John Bollinger,3,2023-06-10 13:45:52,"As long as we're speculating, I think there are at least two things going on here.  One is very likely a reaction to a spike in user suspensions, much as zcoop98 suggests.  The other is that the current CEO is a big fan of generative AI, so although they may not specifically want bad answers on the site, they don't want to ban generative AI as a general policy.  But I suspect there is also a third disconnect: I think that corporate views SE as a service providing answers, whereas the invested membership tends to view it first as a group effort to curate knowledge.",,,
comment_on_answer,1302015,389920,395778.0,BryKKan,0,2023-06-10 18:10:42,"@JohnBollinger Agreed 100%. Couldn't have said it better myself. It's disappointing because the SE community is positioned to provide tremendous value over the next few years if the tide goes the other way. Training models from data that's contaminated by the output from earlier ones is a fool's errand. And SE Inc, by cooperating with the community effort to check this contamination, could position itself for several interesting and potentially lucrative moves into the sector. They have real-time access to the data, and they can prune that down any way they want to hone custom models, for one.",,,
answer,389847,389834,166789.0,Martin Tournoij,29,2023-06-05 20:56:35,"
We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives, which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions. People with original questions and answers were summarily suspended from participating on the platform. We stand by our decision to require that moderators stop using that tool.

I think this is a serious concern that should be addressed, but I think it also misses the point a little bit.
The main reason I signed the letter (something I rarely do) is the heavy-handed approach that seemed to have been taken. I think your concerns are completely valid and very much should be raised, but on the other hand moderators are also struggling with ""ChatGPT spam"". I don't really know what a good solution for that would look like exactly, but I do know that a heavy-handed ""we have decreed that ..."" is not it. It's a difficult problem and there are no quick and easy solutions.
It's not really about the ""ChatGPT policy"" or whether or not these tools are good or bad per se, it's about a mismatch between ""we're all in this together and let's decide together what the best course of action is"" vs. ""we decided, end of discussion"" (crudely put). Moderators are volunteering their time and in return it's understood they have some say in policy. You can't ""just"" order people like they're employees, so you need to spend time and effort convincing people you're right. This is work, but still cheaper than paying people to moderate the site. And sure, in the end Stack Overflow Inc. has the final say and that's fine, but if you're not even spending the effort...

As for this specific policy, it seems to me that the problem is that moderators are suspending users based on too little evidence and are, apparently, not taking the full situation in to account when making their decision, relying too much on the output of a single tool. I can't really judge how often that happens, but it certainly seems more than plausible that moderators have made mistakes here and that's obviously not a good thing, but the alternative is a fuzzy ""this looks like ChatGPT"" underbelly feeling, and that'll have a lot of false positives too ‚Äì perhaps even more? I've certainly seen plenty of ""ChatGPT paranoia"" around, and most of this probably didn't use any tools.
The tool is not the problem; ""How do we deal with ChatGPT?"" is the problem, and as far as I can tell, there is no good solution right now. Any tool can be used inappropriately. If there is a problem with moderators making bad decisions then that should be taken up with those specific moderators.
For what it's worth, personally I don't even think using ChatGPT is necessarily bad in and of itself; see my other answer. I'm all for judging posts more ""holistically"" rather than just ""you're using ChatGPT!"" as that seems too simplistic. It's really about the heavy-handed approach as far as I'm concerned.

Edit: thinking about this some more, I'm also reminded how conflicts were handled in the past. I was involved in the launching of the Vi & Vim site quite a bit and a number of employees were pretty strongly against the concept initially. But the disagreement played out different: it was well argued, and we were allowed a chance to prove ""you're wrong"", and this turned out well.
The controversial Stack Overflow Documentation effort also springs to mind; I felt it wasn't the right direction, but Jon Ericson tried very hard to make it work by engaging with the community and I always very much appreciated that (even though the community was overly harsh at times, to the point I felt rather bad for Jon).
I'm not saying any of this is easy or that the People of Stack Exchange can't be a difficult bunch to deal with ‚Äì they can ‚Äì but that's kind of what you get when you rely on volunteers.
In comparison, this feels like ... bland marketing-speak. I get that community management is hard, but by being bland and generic you're not really engaging with anything substantial and nothing ever gets hashed out.
",,,
comment_on_answer,1300570,389847,1255496.0,Tim Lewis,2,2023-06-05 21:06:16,"Agreed with this; there isn't a ""perfect"" solution for determining what is and is not ChatGPT-generated content. Whenever I flagged an answer, I looked at more than the content; user's post history (if any) to get an idea of writing style, syntax, etc., timeline of activity (i.e. 2+ multi-paragraph answers from a user within seconds). 100% of the cases I flagged resulted in a suspension (I looked at the user's profile following my handled flags). Is it possible those were false-positives? Of course! Aside from the user saying it's ChatGPT (which did happen), we can't know with 100% certainty.",,,
comment_on_answer,1300599,389847,313143.0,Andras Deak -- –°–ª–∞–≤–∞ –£–∫—Ä–∞—ó–Ω—ñ,20,2023-06-05 23:46:15,"The company just wants you to think that AI detection tools are front and center. See e.g. this first-hand account. The company's persistent focus on AI detection tools is gaslighting at this point. There's ""AI detection tools are unreliable"" (what everyone agrees with), and then there's a unicorn leap to ""moderators are suspending all these innocent people""---except there's zero data backing up the second part despite repeated, emphatic requests from the community (including mods!) to do so. Even ""orders"" would be fine if they made sense.",,,
comment_on_answer,1300603,389847,166789.0,Martin Tournoij,2,2023-06-06 00:11:53,"Personally, I don't really like divining motives @AndrasDeak--–°–ª–∞–≤–∞–£–∫—Ä–∞—ó–Ω—ñ; maybe you're right, but who knows? I think it's entirely plausible there's just 1) a (spectacular) communication failure, 2) a failure to understand what the relationship between Stack Overflow-the-company and Stack Overflow-the-community looks like from the community's perspective, 3) an error in their interpretation of the data, or 4) a combination of any of the above.",,,
comment_on_answer,1300604,389847,166789.0,Martin Tournoij,3,2023-06-06 00:15:19,"The last time there was a major conflict (Monica, which I saw up close as a moderator at the time) I think everyone involved was fundamentally well-intentioned, even though Stack Overflow-the-company clearly acted badly, IMHO.",,,
comment_on_answer,1300605,389847,313143.0,Andras Deak -- –°–ª–∞–≤–∞ –£–∫—Ä–∞—ó–Ω—ñ,13,2023-06-06 00:16:58,"There have been way too many attempts from mods and general community to get a decent response/clarification from the company, to no avail. They are doubling down. We're way, way past good faith here. Ask yourself why this post is featured when a bunch of child meta strike posts are being silently unfeatured by Philippe. Probably another misunderstanding.",,,
comment_on_answer,1300609,389847,166789.0,Martin Tournoij,1,2023-06-06 00:39:04,"@AndrasDeak--–°–ª–∞–≤–∞–£–∫—Ä–∞—ó–Ω—ñ Featured posts here are shown on every single SE site; do you really want 4 different featured posts on the same topic? Probably not. You can find ""bad faith"" behind every action if you try hard enough, but that's rarely a constructive path forward.",,,
comment_on_answer,1300659,389847,313143.0,Andras Deak -- –°–ª–∞–≤–∞ –£–∫—Ä–∞—ó–Ω—ñ,7,2023-06-06 07:23:25,Do I really want 4 different featured posts on the same topic? No. Do 4 featured strike posts on 4 different child meta sites (e.g. Academia meta) show up on all other sites? Also no.,,,
comment_on_answer,1301017,389847,395778.0,BryKKan,1,2023-06-07 12:55:58,"I think you've missed the point here. There's no evidence moderators were actually ""going overboard"" at all.",,,
comment_on_answer,1301022,389847,166789.0,Martin Tournoij,0,2023-06-07 13:21:31,"It was intended to be a qualified ""if that's the case"" @BryKKan; I'm really not in a position where I can judge one way or the other. To be honest I can't be bothered to edit it now to clarify that, as it seems engagement from the company is basically zero ‚Äì so what's the point?",,,
answer,389924,389834,248268.0,Nemo,28,2023-06-07 15:28:23,"Honestly Philippe, knowing you as I do, I think you know better than this.
If you're right, and if you believe in what you wrote, this is a case of self-feeding vicious circle of knee-jerk reactions to rapidly evolving patterns of contribution and moderation, with the community and the ""powers that be"" going in opposite direction.
From our experience at Wikimedia you too can probably easily list a dozen past cases just at the English Wikipedia, starting say from the Seigenthaler incident. We need a de-escalation soon, and it's quite rare for things to de-escalate on their own while the opposite sides just dig in. (That tends to happen only if the proximate cause of the incident turns out to be a tempest in a teapot in hindsight, and even then it often takes a long time to recover.)
",,,
answer,389923,389834,343810.0,EJoshuaS - Stand with Ukraine,25,2023-06-07 15:21:16,"To respond to a few things here:

We ran an analysis and the ChatGPT detection tools have an alarmingly high rate of false positives...

How did you do that analysis? Do you have sample posts that you know for a fact that were human-generated and posts that you know for a fact were AI-generated, or were you using a different approach?

...which is correlated to a dramatic upswing in suspensions of users with little or no prior content contributions.

Was the content they were generating good quality? The cases of new accounts posting suspected ChatGPT content I've seen weren't exactly producing stellar answers. Is it really that problematic to suspend someone who was producing bad content anyway (regardless of whether it was ChatGPT)?

People with original questions and answers were summarily suspended from participating on the platform.

Again, are you aware of specific individuals that you know for a fact were incorrectly suspended? How did you determine that, unless you yourselves have a way to reliably distinguish between human-generated and AI-generated AI? If you don't have a way to do that, aren't you kind of doing the same thing you're accusing moderators of doing?
",,,
comment_on_answer,1301048,389923,171199.0,Íì¢PArcheon,13,2023-06-07 15:28:14,"to be fair, while I expect that a detection tool test was made on labelled samples (samples you know the nature) at the same time your post opens a tangential far more interesting question: since tools don't work and the mods were apparently told that their logical thinking doesn't too, how was the company able to validate that the false positives banned users on the site were indeed false positive? Surely not just because the banned users told them so, right?",,,
comment_on_answer,1301052,389923,259608.0,Y.A.,1,2023-06-07 15:36:45,"You're expecting logical consistency from SE? Well, I guess the illogic just proves they're human. @SPArcheon",,,
comment_on_answer,1301056,389923,776523.0,zcoop98,2,2023-06-07 15:51:45,"I have no intent to offer defense for SE in this case, but I also feel it's worth noting that it's possible for the moderators and Staff to come to the same conclusion (that ""AI detection is nigh-impossible to do with absolute certainty""), and arrive at two different forms of action from that conclusion (E.g. Mods with ""Let's deal with what we can, a small amount of false positives is a necessary cost to stem the flow"" vs. Staff with ""We can't hope to do this accurately or evenly, the least costly option is to let everything through to avoid benching real users"").",,,
comment_on_answer,1301057,389923,159794.0,kleopatra,4,2023-06-07 15:52:37,"@SPArcheon false positives banned users actually they didn't say that, they just formulated their unsubstiated claims in a way that readers might come to such a conclusion, and they can back out If needed. They talk about a) false positives by tools (agreed by all) b) correlation of suspensions to false positives  .. what/how exactly? cant make much sense of their sentence c) (new) posters with original content (both answers and questions - never seen the latter, btw) were suspended - implying they were mistreated.",,,
comment_on_answer,1301059,389923,159794.0,kleopatra,3,2023-06-07 15:57:54,it's nastily clever spun pitch ..,,,
comment_on_answer,1301060,389923,171199.0,Íì¢PArcheon,10,2023-06-07 16:05:00,@kleopatra pointing out the contradiction there was exactly my point :P. First you claim that there is no sure way to see if something is AI generated even after human scrutiny. Then you say that you are sure that some of the bans were false positive. Unless you are to imply that the bans were part of a test sample of human written post that the company itself crafted to look like AI generated content the company has by its own assumption no way to know if the false positive bans were indeed false positive bans,,,
comment_on_answer,1301068,389923,159794.0,kleopatra,0,2023-06-07 17:17:32,"@SPArcheon I agree, just looking at theirs words from a slightly different angle :)",,,
answer,390133,389834,148982.0,harrymc,12,2023-06-12 08:02:16,"I'm not a moderator, but I think SE has got this subject backwards.
I have on SU detected and signaled 5 cases of AI ""answers"", with
confirmation in all cases by the moderators and even sometimes by
the poster himself.
In the first two cases, I used no tools. For the next three cases,
I discovered ZeroGPT and GPTZero and used them for a second opinion.
In other words, I have used the tools not for detecting AI answers,
but for detecting whether I was wrong in assuming the answer
was by AI.
No one runs all the answers through ZeroGPT and GPTZero to detect
AI answers for fun. One only goes to this effort when the answer
seems weird, without a central theme, with a very weak or
no connection to the question and even sometimes just plain wrong
and misleading.
The tools are used just the opposite of that postulated by SE : To
check whether the answers are not AI.",,,
comment_on_answer,1302596,390133,248268.0,Nemo,0,2023-06-13 08:37:24,"¬´In other words, I have used the tools not for detecting AI answers, but for detecting whether I was wrong in assuming the answer was by AI.¬ª  But isn't that exactly what these tools are bad at? They can tell you something /might/ be fishy, but you need to confirm with your own judgement.",,,
comment_on_answer,1302597,390133,148982.0,harrymc,0,2023-06-13 08:48:04,"@Nemo: It's the opposite : I use the tools for finer control. For example, I once found out that one paragraph was added by the user to an AI answer, and this was confirmed by that user. The tools are usually correct, and in these 3 cases their judgement was the same as mine, but mine came first. I would have flagged them just the same without using the tools, but it seems irresponsible not to take every possible precaution before accusing the user.",,,
comment_on_answer,1302601,390133,148982.0,harrymc,1,2023-06-13 08:51:52,"In other words, AI answers will be flagged, with or without these tools, except that the tools can help avoid mistakes. Disallowing the tools doesn't mean that (bad) AI answers won't be flagged and removed.",,,
comment_on_answer,1303782,390133,357392.0,Philippos,1,2023-06-19 11:59:51,"Exactly why can't you continue to identify such answers by their content, downvote them and flag them in need of moderator intervention as wrong, misleading, or not answering the question? If an answer is bad, we need to get rid of it no matter how they were created. Why should a horrible answer survive just because a tool says it's not AI generated?",,,
comment_on_answer,1303787,390133,148982.0,harrymc,0,2023-06-19 13:19:00,"@Philippos: I can and I did. Reverse question : Why shouldn't I use a technology when it exists? I downvote and flag bad answers, but reporting a user as an AI spammer is more serious.",,,
comment_on_answer,1303793,390133,357392.0,Philippos,0,2023-06-19 14:03:08,"I'm not opposed to use that technology, so I'm not the one to answer your question. Just tried to understand your concern.",,,
answer,390104,389834,148982.0,harrymc,8,2023-06-11 10:19:04,"I thought it would be educational for the SE deciders
to show them how GPT4 answers their own announcement here.
This ""answer"" is manifestly not useful or helpful, and doesn't
even have a discernible central theme. It's a collection of
texts that GPT4 found on the internet that loosely relate to
the subjects in the announcement.
This is an example of rubbish AI ""answers"" that I have been seeing on the SU site. If this kind of drivel is allowed to pollute our sites, we'll only be destroying ourselves.
Does SE really think that we should let such answers
deluge our sites?

The concerns expressed by the moderators regarding the detection tools and AI-generated content on Stack Overflow are valid and should not be dismissed. While it is unfortunate that some moderators have chosen to disengage from their moderation tasks, their actions highlight the seriousness of the issue at hand.
The claim that the ChatGPT detection tools have an alarmingly high rate of false positives is questionable. Detection tools, including AI algorithms, are not infallible, and false positives can occur. However, it is essential to consider the overall impact of these false positives and weigh them against the potential harm of allowing AI-generated content to proliferate unchecked. The purpose of such tools is to maintain the quality and integrity of the platform, even if there are occasional false positives that need to be addressed.
The suggestion that suspensions were imposed on users with little or no prior content contributions solely based on ChatGPT's detection tool is misleading. Moderators typically employ multiple methods and analyses to make informed decisions. While ChatGPT's detection tool may have been part of the process, it is not the sole determinant of suspensions. The goal is to ensure a safe and reliable platform for users, which sometimes requires precautionary measures.
The statement about seeking other, more reasonable tools and commitment to rapid testing of those tools is encouraging. It shows a willingness to address the concerns raised by the moderators and find better solutions for content moderation. Continuous improvement and adaptation to new challenges are essential for any platform to thrive.
Expressing appreciation for the moderators' years of service and acknowledging the difficulty of the situation is a positive gesture. However, it is important to focus on resolving the underlying issues and finding a viable path forward. Merely expressing regret and hoping for a resolution may not be sufficient. Concrete actions need to be taken to address the moderators' concerns and restore trust within the community.
While it is acknowledged that the upcoming days and weeks may be challenging, both sides should prioritize open dialogue and collaboration. Ensuring quality and inclusivity on the platform should be the shared goal. Transparent communication with the community about updates and progress is crucial for rebuilding trust and working towards a long-term solution.
In conclusion, it is crucial to acknowledge the concerns raised by the moderators and address them seriously. Balancing the need for effective content moderation with minimizing false positives is a complex task, but it should be approached with a commitment to finding the best possible solutions for all stakeholders involved.",,,
comment_on_answer,1302123,390104,1372392.0,markalex,14,2023-06-11 10:25:33,"""I thought it would be fun to ask GPT4 about its own opinion of the announcement here."" It is not. You're not the first one to do that kind of stuff under this or related posts, and all such answers were receive extremely poorly, and later were deleted by authors. This joke/idea is out of date for nearly half a year.",,,
comment_on_answer,1302136,390104,148982.0,harrymc,6,2023-06-11 13:03:09,"@markalex: It's not a joke, it's an example of AI ""answers"" that I have been seeing on the SU site. If this kind of drivel is allowed to pollute our sites, we'll only be destroying ourselves. But apparently this kind of stuff is what SE thinks we should let proliferate.",,,
comment_on_answer,1302157,390104,1372392.0,markalex,2,2023-06-11 14:17:50,"Then consider editing you answer, and adding as a first sentence something like ""Look what incoherent sh*t chatGPT generated as an answer to this statement"" and maybe more of your statement from last comment.",,,
comment_on_answer,1302159,390104,148982.0,harrymc,5,2023-06-11 14:29:44,@markalex: I tried to more clearly state what was my intention here. I hope I've succeeded this time.,,,